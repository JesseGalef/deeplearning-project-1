{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bnN-_dUfAj85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# All Includes\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential, load_model, clone_model\n",
        "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras import models, layers, optimizers, utils\n",
        "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw, PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AS1clr6Av2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Child Model ===**"
      ]
    },
    {
      "metadata": {
        "id": "WJ96_u3_AuHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_model(trainX, n_classes):\n",
        "    # https://stats.stackexchange.com/questions/272607/cifar-10-cant-get-above-60-accuracy-keras-with-tensorflow-backend\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(input_shape=trainX[0,:,:,:].shape, filters=96, kernel_size=(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(filters=96, kernel_size=(3,3), strides=2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Convolution2D(filters=192, kernel_size=(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(filters=192, kernel_size=(3,3), strides=2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
        "    optimizer = optimizers.Adadelta(lr=0.05, rho=0.95, epsilon=None, decay=0.0)\n",
        "    model.compile(optimizer, 'categorical_crossentropy', ['accuracy'])\n",
        "    return model\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "def model_cond_accuracy(model, X, y):\n",
        "    y_prob = model.predict(X)\n",
        "    y_classes = y_prob.argmax(axis=-1).tolist()\n",
        "    y_test = y.argmax(axis=-1).tolist()\n",
        "    total = [0] * 10\n",
        "    counts = [0] * 10\n",
        "    for i in range(len(y_classes)):\n",
        "      if y_classes[i] == y_test[i]:\n",
        "        total[y_test[i]] += 1\n",
        "      counts[y_test[i]] += 1\n",
        "    acc = [0.0] * 10\n",
        "    for i in range(10):\n",
        "      if 0 != counts[i]:\n",
        "        acc[i] = total[i] / counts[i]\n",
        "    return acc\n",
        "\n",
        "def model_fit(model, gen, val_data, nbatches, epochs):\n",
        "    history = model.fit_generator(\n",
        "      gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n",
        "    return history\n",
        "\n",
        "def model_evaluate(model, X, y):\n",
        "  return model.evaluate(X, y, verbose=0)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qop7WrPVBZ2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Transforms ===**"
      ]
    },
    {
      "metadata": {
        "id": "K6NncO3YBeH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code below adapted from augmentation_transforms.py\n",
        "# Modified to support transforms at the image class level\n",
        "# Original copywright below:\n",
        "\n",
        "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "MEANS = [0.49139968, 0.48215841, 0.44653091]\n",
        "STDS = [0.24703223, 0.24348513, 0.26158784]\n",
        "PARAMETER_MAX = 10  # What is the max 'level' a transform could be predicted\n",
        "\n",
        "def pil_wrap(img):\n",
        "  \"\"\"Convert the `img` numpy tensor to a PIL Image.\"\"\"\n",
        "  return PIL.Image.fromarray(\n",
        "      np.uint8((img * STDS + MEANS) * 255.0)).convert('RGBA')\n",
        "\n",
        "\n",
        "def pil_unwrap(pil_img):\n",
        "  \"\"\"Converts the PIL img to a numpy array.\"\"\"\n",
        "  pic_array = (np.array(pil_img.getdata()).reshape((32, 32, 4)) / 255.0)\n",
        "  i1, i2 = np.where(pic_array[:, :, 3] == 0)\n",
        "  pic_array = (pic_array[:, :, :3] - MEANS) / STDS\n",
        "  pic_array[i1, i2] = [0, 0, 0]\n",
        "  return pic_array\n",
        "\n",
        "class Operation:\n",
        "    def __init__(self, t, p = 0.5):\n",
        "\n",
        "        self.prob = p\n",
        "        self.magnitude = t[1]\n",
        "        self.transformation = t[0]\n",
        "\n",
        "    def __call__(self, X, Y):\n",
        "        _X = []\n",
        "        #self.magnitude = random.randint(0,9)\n",
        "        for x,y in zip(X,Y):\n",
        "            if np.random.rand() < self.prob:\n",
        "                x = pil_wrap(x)\n",
        "                x = self.transformation[np.argmax(y)](x, self.magnitude)\n",
        "                x = pil_unwrap(x)\n",
        "            _X.append(np.array(x))\n",
        "        return np.array(_X)\n",
        "    \n",
        "\n",
        "class Transform:\n",
        "    def __init__(self, *operations):\n",
        "        self.operations = operations\n",
        "\n",
        "    def __call__(self, X, Y):\n",
        "        for op in self.operations:\n",
        "            X = op(X, Y)\n",
        "        return X\n",
        "\n",
        "\n",
        "def autoaugment(transforms, X, y, batch_size):\n",
        "    while True:\n",
        "        ix = np.arange(len(X))\n",
        "        np.random.shuffle(ix)\n",
        "        for i in range(len(X) // batch_size):\n",
        "            _ix = ix[i*batch_size:(i+1)*batch_size]\n",
        "            _X = X[_ix]\n",
        "            _y = y[_ix]\n",
        "            if 0 != len(transforms):\n",
        "              transform = np.random.choice(transforms)\n",
        "              _X = transform(_X, _y)\n",
        "            yield _X, _y\n",
        "\n",
        "# modified from https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\n",
        "def create_cutout_mask(img_height, img_width, num_channels, size):\n",
        "  \"\"\"Creates a zero mask used for cutout of shape `img_height` x `img_width`.\n",
        "\n",
        "  Args:\n",
        "    img_height: Height of image cutout mask will be applied to.\n",
        "    img_width: Width of image cutout mask will be applied to.\n",
        "    num_channels: Number of channels in the image.\n",
        "    size: Size of the zeros mask.\n",
        "\n",
        "  Returns:\n",
        "    A mask of shape `img_height` x `img_width` with all ones except for a\n",
        "    square of zeros of shape `size` x `size`. This mask is meant to be\n",
        "    elementwise multiplied with the original image. Additionally returns\n",
        "    the `upper_coord` and `lower_coord` which specify where the cutout mask\n",
        "    will be applied.\n",
        "  \"\"\"\n",
        "  assert img_height == img_width\n",
        "\n",
        "  # Sample center where cutout mask will be applied\n",
        "  height_loc = np.random.randint(low=0, high=img_height)\n",
        "  width_loc = np.random.randint(low=0, high=img_width)\n",
        "\n",
        "  # Determine upper right and lower left corners of patch\n",
        "  upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "  lower_coord = (min(img_height, height_loc + size // 2),\n",
        "                 min(img_width, width_loc + size // 2))\n",
        "  mask_height = lower_coord[0] - upper_coord[0]\n",
        "  mask_width = lower_coord[1] - upper_coord[1]\n",
        "  assert mask_height > 0\n",
        "  assert mask_width > 0\n",
        "\n",
        "  mask = np.ones((img_height, img_width, num_channels))\n",
        "  zeros = np.zeros((mask_height, mask_width, num_channels))\n",
        "  mask[upper_coord[0]:lower_coord[0], upper_coord[1]:lower_coord[1], :] = (\n",
        "      zeros)\n",
        "  return mask, upper_coord, lower_coord\n",
        "\n",
        "def cutout_numpy(img, size=16):\n",
        "  \"\"\"Apply cutout with mask of shape `size` x `size` to `img`.\n",
        "\n",
        "  The cutout operation is from the paper https://arxiv.org/abs/1708.04552.\n",
        "  This operation applies a `size`x`size` mask of zeros to a random location\n",
        "  within `img`.\n",
        "\n",
        "  Args:\n",
        "    img: Numpy image that cutout will be applied to.\n",
        "    size: Height/width of the cutout mask that will be\n",
        "\n",
        "  Returns:\n",
        "    A numpy tensor that is the result of applying the cutout mask to `img`.\n",
        "  \"\"\"\n",
        "  img_height, img_width, num_channels = (img.shape[0], img.shape[1],\n",
        "                                         img.shape[2])\n",
        "  assert len(img.shape) == 3\n",
        "  mask, _, _ = create_cutout_mask(img_height, img_width, num_channels, size)\n",
        "  return img * mask\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled\n",
        "      to level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    A float that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return float(level) * maxval / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled\n",
        "      to level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    An int that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return int(level * maxval / PARAMETER_MAX)\n",
        "\n",
        "def _cutout_pil_impl(pil_img, level):\n",
        "  \"\"\"Apply cutout to pil_img at the specified level.\"\"\"\n",
        "  size = int_parameter(level, 20)\n",
        "  if size <= 0:\n",
        "    return pil_img\n",
        "  img_height, img_width, num_channels = (32, 32, 3)\n",
        "  _, upper_coord, lower_coord = (\n",
        "      create_cutout_mask(img_height, img_width, num_channels, size))\n",
        "  pixels = pil_img.load()  # create the pixel map\n",
        "  for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "    for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "      pixels[i, j] = (125, 122, 113, 0)  # set the colour accordingly\n",
        "  return pil_img\n",
        "\n",
        "def _enhancer_impl(enhancer):\n",
        "  \"\"\"Sets level to be between 0.1 and 1.8 for ImageEnhance transforms of PIL.\"\"\"\n",
        "  def impl(pil_img, level):\n",
        "    v = float_parameter(level, 1.8) + .1  # going to 0 just destroys it\n",
        "    return enhancer(pil_img).enhance(v)\n",
        "  return impl\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "def ShearX(img, v):  # [-0.3, 0.3]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "  \n",
        "def ShearY(img, v):  # [-0.3, 0.3]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))  \n",
        "  \n",
        "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform((32, 32), PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform((32, 32), PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "def Rotate(img, v):  # [-30, 30]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "def AutoContrast(img, _):\n",
        "    return PIL.ImageOps.autocontrast(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Invert(img, _):\n",
        "    return PIL.ImageOps.invert(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Equalize(img, _):\n",
        "    return PIL.ImageOps.equalize(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Flip_LR(img, _):  # not from the paper\n",
        "    return img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "def Flip_UD(img, _):\n",
        "    return img.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  \n",
        "def Solarize(img, v):  # [0, 256]\n",
        "    v = int_parameter(v, 256)\n",
        "    return PIL.ImageOps.solarize(img.convert('RGB'), 256 - v).convert('RGBA')\n",
        "\n",
        "def Posterize(img, v):  # [4, 8]\n",
        "    v = int_parameter(v, 4)\n",
        "    return PIL.ImageOps.posterize(img.convert('RGB'), 4 - v).convert('RGBA')\n",
        "\n",
        "def Contrast(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Contrast)(img, v)\n",
        "\n",
        "def Blur(img, v):\n",
        "    return img.filter(PIL.ImageFilter.BLUR)\n",
        "  \n",
        "def Color(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Color)(img, v)\n",
        "\n",
        "def Smooth(img, v):\n",
        "    return img.filter(PIL.ImageFilter.SMOOTH)\n",
        "  \n",
        "def Brightness(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Brightness)(img, v)\n",
        "\n",
        "def Sharpness(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Sharpness)(img, v)\n",
        "\n",
        "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
        "    return _cutout_pil_impl(img, v)\n",
        "\n",
        "def Crop(img, v, interpolation=PIL.Image.BILINEAR):\n",
        "    cropped = img.crop((v, v, IMAGE_SIZE - v, IMAGE_SIZE - v))\n",
        "    resized = cropped.resize((IMAGE_SIZE, IMAGE_SIZE), interpolation)\n",
        "    return resized\n",
        "\n",
        "def Identity(img, v):\n",
        "  return img\n",
        "\n",
        "  \n",
        "opmap = {\n",
        "    'Flip_LR' : Flip_LR,\n",
        "    'Flip_UD' : Flip_UD,\n",
        "    'AutoContrast' : AutoContrast,\n",
        "    'Equalize' : Equalize,\n",
        "    'Invert' : Invert,\n",
        "    'Rotate' : Rotate,\n",
        "    'Poserize' : Posterize,\n",
        "    'Crop' : Crop,\n",
        "    'Solarize' : Solarize,\n",
        "    'Color' : Color,\n",
        "    'Contrast' : Contrast,\n",
        "    'Brightness' : Brightness,\n",
        "    'Sharpness' : Sharpness,\n",
        "    'ShearX' : ShearX,\n",
        "    'ShearY' : ShearY,\n",
        "    'TranslateX' : TranslateX,\n",
        "    'TranslateY' : TranslateY,\n",
        "    'Cutout' : Cutout,\n",
        "    'Blur' : Blur,\n",
        "    'Smooth' : Smooth\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzpINrgRB2uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Get Ready... ===**"
      ]
    },
    {
      "metadata": {
        "id": "fE1On7L-B7Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e7640479-208c-4cfb-e525-d5a024f3ad42"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10\n",
        "from keras.datasets import cifar10\n",
        "(X, y), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Create the Reduced CIFAR-10 dataset\n",
        "#ix = np.random.choice(len(X), 4000, False)\n",
        "#x_reduced_train = X[ix]\n",
        "#y_reduced_train = y[ix]\n",
        "\n",
        "# Shuffle the training data\n",
        "shuffling = np.random.permutation(X.shape[0])   \n",
        "X = X[shuffling, :]\n",
        "y = y[shuffling]\n",
        "\n",
        "# Split Training --> Training + Validation\n",
        "nTrain = int(0.9 * X.shape[0])\n",
        "X_train = X[0:nTrain, :, :, :]\n",
        "y_train = y[:nTrain]\n",
        "\n",
        "X_validation = X[nTrain:, :, :, :]\n",
        "y_validation = y[nTrain:]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_validation.shape)\n",
        "\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_validation = utils.to_categorical(y_validation)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "categories = ['airplane', 'auto', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 33s 0us/step\n",
            "(45000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R60JBZnAFtsK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 250\n",
        "\n",
        "def train_model(model, aug, epochs):\n",
        "\n",
        "  tic = time.clock()\n",
        "  model_fit(model, aug, (X_validation, y_validation), len(X_train) // batch_size, epochs)\n",
        "  toc = time.clock()\n",
        "  \n",
        "  accuracy = model_evaluate(model, X_test, y_test)\n",
        "  \n",
        "  print('Test accuracy: %.3f (elaspsed time: %ds)' % (accuracy, (toc-tic)))\n",
        "  acc = model_cond_accuracy(model, X_test, y_test)\n",
        "  \n",
        "  print(\"Accuracy\")\n",
        "  for cat, a in zip(categories, acc):\n",
        "    print(cat, a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rvEYCZ0FSc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Baseline Training Without Data Augmentation**"
      ]
    },
    {
      "metadata": {
        "id": "CaqB-oyIGiek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2074
        },
        "outputId": "5256ef71-bef8-4413-995d-5b1157ccefcd"
      },
      "cell_type": "code",
      "source": [
        "ops = [Operation(([Identity] * 10, 0), 0)]\n",
        "transform1 = Transform(*ops)\n",
        "\n",
        "transforms = [transform1]\n",
        "aug = autoaugment(transforms, X_train, y_train, batch_size) \n",
        "\n",
        "model0 = create_model(X_train, 10)\n",
        "\n",
        "history0 = train_model(model0, aug, 50)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "180/180 [==============================] - 19s 107ms/step - loss: 2.3150 - acc: 0.2157 - val_loss: 1.9072 - val_acc: 0.3130\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.9128 - acc: 0.3246 - val_loss: 1.6609 - val_acc: 0.4032\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.7215 - acc: 0.3860 - val_loss: 1.6090 - val_acc: 0.4246\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.5929 - acc: 0.4275 - val_loss: 1.4410 - val_acc: 0.4826\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.5025 - acc: 0.4597 - val_loss: 1.3629 - val_acc: 0.5158\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.4435 - acc: 0.4834 - val_loss: 1.3087 - val_acc: 0.5280\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.3849 - acc: 0.5032 - val_loss: 1.2902 - val_acc: 0.5464\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.3344 - acc: 0.5220 - val_loss: 1.2782 - val_acc: 0.5480\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.2898 - acc: 0.5406 - val_loss: 1.2018 - val_acc: 0.5720\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.2501 - acc: 0.5557 - val_loss: 1.1615 - val_acc: 0.5810\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.2083 - acc: 0.5708 - val_loss: 1.1508 - val_acc: 0.5942\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1789 - acc: 0.5790 - val_loss: 1.1337 - val_acc: 0.6010\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1453 - acc: 0.5930 - val_loss: 1.1505 - val_acc: 0.5938\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1116 - acc: 0.6074 - val_loss: 1.0766 - val_acc: 0.6178\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.0900 - acc: 0.6140 - val_loss: 1.0477 - val_acc: 0.6288\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.0635 - acc: 0.6237 - val_loss: 1.0395 - val_acc: 0.6348\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.0331 - acc: 0.6321 - val_loss: 1.0257 - val_acc: 0.6414\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.0089 - acc: 0.6453 - val_loss: 1.0067 - val_acc: 0.6410\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9806 - acc: 0.6522 - val_loss: 0.9656 - val_acc: 0.6598\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9578 - acc: 0.6627 - val_loss: 0.9530 - val_acc: 0.6666\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 0.9358 - acc: 0.6701 - val_loss: 0.9439 - val_acc: 0.6700\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9225 - acc: 0.6758 - val_loss: 0.9317 - val_acc: 0.6722\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8991 - acc: 0.6840 - val_loss: 0.9635 - val_acc: 0.6708\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8805 - acc: 0.6892 - val_loss: 0.9416 - val_acc: 0.6712\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8608 - acc: 0.6998 - val_loss: 0.9110 - val_acc: 0.6844\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8418 - acc: 0.7046 - val_loss: 0.8633 - val_acc: 0.6990\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8271 - acc: 0.7096 - val_loss: 0.8758 - val_acc: 0.6986\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8083 - acc: 0.7178 - val_loss: 0.8852 - val_acc: 0.6930\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7924 - acc: 0.7196 - val_loss: 0.8795 - val_acc: 0.6906\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 17s 95ms/step - loss: 0.7792 - acc: 0.7270 - val_loss: 0.8430 - val_acc: 0.7056\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 17s 95ms/step - loss: 0.7621 - acc: 0.7336 - val_loss: 0.8695 - val_acc: 0.6978\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7502 - acc: 0.7379 - val_loss: 0.8353 - val_acc: 0.7112\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7354 - acc: 0.7430 - val_loss: 0.8359 - val_acc: 0.7134\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7235 - acc: 0.7454 - val_loss: 0.8330 - val_acc: 0.7118\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7082 - acc: 0.7502 - val_loss: 0.8219 - val_acc: 0.7142\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 0.6935 - acc: 0.7565 - val_loss: 0.8084 - val_acc: 0.7196\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6832 - acc: 0.7593 - val_loss: 0.9269 - val_acc: 0.6852\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6749 - acc: 0.7609 - val_loss: 0.8189 - val_acc: 0.7238\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 0.6587 - acc: 0.7704 - val_loss: 0.7826 - val_acc: 0.7236\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6506 - acc: 0.7715 - val_loss: 0.8731 - val_acc: 0.7040\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6431 - acc: 0.7734 - val_loss: 0.7932 - val_acc: 0.7336\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6305 - acc: 0.7777 - val_loss: 0.7834 - val_acc: 0.7298\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.6196 - acc: 0.7839 - val_loss: 0.7800 - val_acc: 0.7320\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6041 - acc: 0.7888 - val_loss: 0.7767 - val_acc: 0.7300\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5970 - acc: 0.7895 - val_loss: 0.7969 - val_acc: 0.7260\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5857 - acc: 0.7956 - val_loss: 0.7754 - val_acc: 0.7356\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5751 - acc: 0.7981 - val_loss: 0.7692 - val_acc: 0.7362\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 18s 99ms/step - loss: 0.5615 - acc: 0.8014 - val_loss: 0.7742 - val_acc: 0.7336\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5570 - acc: 0.8054 - val_loss: 0.7603 - val_acc: 0.7434\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5480 - acc: 0.8068 - val_loss: 0.7450 - val_acc: 0.7418\n",
            "Test accuracy: 0.745 (elaspsed time: 722s)\n",
            "Accuracy\n",
            "airplane 0.742\n",
            "auto 0.86\n",
            "bird 0.63\n",
            "cat 0.583\n",
            "deer 0.681\n",
            "dog 0.701\n",
            "frog 0.823\n",
            "horse 0.792\n",
            "ship 0.835\n",
            "truck 0.798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xbBRcjrgODS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train for each individual image transform**\n",
        "Do transforms have significantly different effects for each image class?"
      ]
    },
    {
      "metadata": {
        "id": "aRR1t1pmgOab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        },
        "outputId": "e179bf9a-0754-4034-a9e2-35ec463812c6"
      },
      "cell_type": "code",
      "source": [
        "# Try one to see how many epochs to try... 100 seems to work well; need lots of extra training!\n",
        "op = opmap['Flip_LR']\n",
        "print('=========================================================')\n",
        "print('=========================================================')\n",
        "print('=== ', 'Flip_LR', ' ===')\n",
        "\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug = autoaugment(transform, X_train, y_train, batch_size) \n",
        "\n",
        "model = create_model(X_train, 10)\n",
        "\n",
        "history = train_model(model, aug, 100)\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "=========================================================\n",
            "===  Flip_LR  ===\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2195, in fromarray\n    mode, rawmode = _fromarray_typemap[typekey]\nKeyError: ((1, 1, 32, 3), '|u1')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"<ipython-input-14-9aaebf33287a>\", line 63, in autoaugment\n    _X = transform(_X, _y)\n  File \"<ipython-input-14-9aaebf33287a>\", line 47, in __call__\n    X = pil_wrap(X)\n  File \"<ipython-input-14-9aaebf33287a>\", line 12, in pil_wrap\n    np.uint8((img * STDS + MEANS) * 255.0)).convert('RGBA')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2198, in fromarray\n    raise TypeError(\"Cannot handle this data type\")\nTypeError: Cannot handle this data type\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-887411ebe145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-698a4fa13395>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, aug, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fbaf30ece83c>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, gen, val_data, nbatches, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     history = model.fit_generator(\n\u001b[0;32m---> 46\u001b[0;31m       gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PFfqv5A5qNcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        },
        "outputId": "1bd2c8c9-eb18-4ede-d873-c835a8f58d5b"
      },
      "cell_type": "code",
      "source": [
        "for name, op in opmap.items():\n",
        "  print('=========================================================')\n",
        "  print('=========================================================')\n",
        "  print('=== ', name, ' ===')\n",
        "\n",
        "  # 50% prob of transform\n",
        "  ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "  transform = [Transform(*ops)]\n",
        "\n",
        "  aug = autoaugment(transform, X_train, y_train, batch_size) \n",
        "  \n",
        "  model = create_model(X_train, 10)\n",
        "\n",
        "  history = train_model(model, aug, 100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "=========================================================\n",
            "===  Flip_LR  ===\n",
            "Epoch 1/100\n",
            " 74/180 [===========>..................] - ETA: 20s - loss: 2.5491 - acc: 0.1252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-23:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
            "    return six.next(_SHARED_SEQUENCES[uid])\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 62, in autoaugment\n",
            "    _X = transform(_X, _y)\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 48, in __call__\n",
            "    X = op(X, Y)\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 37, in __call__\n",
            "    x = pil_unwrap(x)\n",
            "KeyboardInterrupt\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 19, in pil_unwrap\n",
            "    pic_array = (pic_array[:, :, :3] - MEANS) / STDS\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1ecb09e7bf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-698a4fa13395>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, aug, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fbaf30ece83c>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, gen, val_data, nbatches, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     history = model.fit_generator(\n\u001b[0;32m---> 46\u001b[0;31m       gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qvhbTUSMG50q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**AutoAugment Policy**"
      ]
    },
    {
      "metadata": {
        "id": "F3L2JdSGHhE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3621
        },
        "outputId": "dec4199a-3c2b-40b8-fc74-e66e37e9feaa"
      },
      "cell_type": "code",
      "source": [
        "# Utility function to create policy, tform, below\n",
        "def mk_op2(op1, p1, v1, op2, p2, v2):\n",
        "  ops = [Operation(([op1] * 10, v1), p1), Operation(([op2] * 10, v2), p2)]\n",
        "  return Transform(*ops)\n",
        "\n",
        "# Duplicate the AutoAugment CIFAR-10 policy selected by concatenations of AutoAugment\n",
        "tform = [\n",
        "    #0_0\n",
        "    mk_op2(Invert, 0.1, 7, Contrast, 0.2, 6),\n",
        "    mk_op2(Rotate, 0.7, 2, TranslateX, 0.3, 9),\n",
        "    mk_op2(Sharpness, 0.8, 1, Sharpness, 0.9, 3),\n",
        "    mk_op2(ShearY, 0.5, 8, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.5, 8, Equalize, 0.9, 2),\n",
        "    \n",
        "    #0_1\n",
        "    mk_op2(Solarize, 0.4, 5, AutoContrast, 0.9, 3),\n",
        "    mk_op2(TranslateY, 0.9, 9, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.9, 2, Solarize, 0.8, 3),\n",
        "    mk_op2(Equalize, 0.8, 8, Invert, 0.1, 3),\n",
        "    mk_op2(TranslateY, 0.7, 9, AutoContrast, 0.9, 1),\n",
        "    \n",
        "    #0_2\n",
        "    mk_op2(Solarize, 0.4, 5, AutoContrast, 0.0, 2),\n",
        "    mk_op2(TranslateY, 0.7, 9, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.9, 0, Solarize, 0.4, 3),\n",
        "    mk_op2(Equalize, 0.7, 5, Invert, 0.1, 3),\n",
        "    mk_op2(TranslateY, 0.7, 9, TranslateY, 0.7, 9),\n",
        "\n",
        "    #0_3\n",
        "    mk_op2(Solarize, 0.4, 5, AutoContrast, 0.9, 1),\n",
        "    mk_op2(TranslateY, 0.8, 9, TranslateY, 0.9, 9),\n",
        "    mk_op2(AutoContrast, 0.8, 0, TranslateY, 0.7, 9),\n",
        "    mk_op2(TranslateY, 0.2, 7, Color, 0.9, 6),\n",
        "    mk_op2(Equalize, 0.7, 6, Color, 0.4, 9),\n",
        "    \n",
        "    #1_0\n",
        "    mk_op2(ShearY, 0.2, 7, Posterize, 0.3, 7),\n",
        "    mk_op2(Color, 0.4, 3, Brightness, 0.6, 7),\n",
        "    mk_op2(Sharpness, 0.3, 9, Brightness, 0.7, 9),\n",
        "    mk_op2(Equalize, 0.6, 5, Equalize, 0.5, 1),\n",
        "    mk_op2(Contrast, 0.6, 7, Sharpness, 0.6, 5),\n",
        "    \n",
        "    #1_1\n",
        "    mk_op2(Brightness, 0.3, 7, AutoContrast, 0.5, 8),\n",
        "    mk_op2(AutoContrast, 0.9, 4, AutoContrast, 0.5, 6),\n",
        "    mk_op2(Solarize, 0.3, 5, Equalize, 0.6, 5),\n",
        "    mk_op2(TranslateY, 0.2, 4, Sharpness, 0.3, 3),\n",
        "    mk_op2(Brightness, 0.0, 8, Color, 0.8, 8),\n",
        "    \n",
        "    #1_2\n",
        "    mk_op2(Solarize, 0.2, 6, Color, 0.8, 6),\n",
        "    mk_op2(Solarize, 0.2, 6, AutoContrast, 0.8, 1),\n",
        "    mk_op2(Solarize, 0.4, 1, Equalize, 0.6, 5),\n",
        "    mk_op2(Brightness, 0.0, 0, Solarize, 0.5, 2),\n",
        "    mk_op2(AutoContrast, 0.9, 5, Brightness, 0.5, 3),\n",
        "    \n",
        "    #1_3\n",
        "    mk_op2(Contrast, 0.7, 5, Brightness, 0.0, 2),\n",
        "    mk_op2(Solarize, 0.2, 8, Solarize, 0.1, 5),\n",
        "    mk_op2(Contrast, 0.5, 1, TranslateY, 0.2, 9),\n",
        "    mk_op2(AutoContrast, 0.6, 5, TranslateY, 0.0, 9),\n",
        "    mk_op2(AutoContrast, 0.9, 4, Equalize, 0.8, 4),\n",
        "    \n",
        "    #1_4\n",
        "    mk_op2(Brightness, 0.0, 7, Equalize, 0.4, 7),\n",
        "    mk_op2(Solarize, 0.2, 5, Equalize, 0.7, 5),\n",
        "    mk_op2(Equalize, 0.6, 8, Color, 0.6, 2),\n",
        "    mk_op2(Color, 0.3, 7, Color, 0.2, 4),\n",
        "    mk_op2(AutoContrast, 0.5, 2, Solarize, 0.7, 2),\n",
        "    \n",
        "    #1_5\n",
        "    mk_op2(AutoContrast, 0.2, 0, Equalize, 0.1, 0),\n",
        "    mk_op2(ShearY, 0.6, 5, Equalize, 0.6, 5),\n",
        "    mk_op2(Brightness, 0.9, 3, AutoContrast, 0.4, 1),\n",
        "    mk_op2(Equalize, 0.8, 8, Equalize, 0.7, 7),\n",
        "    mk_op2(Equalize, 0.7, 7, Solarize, 0.5, 0),\n",
        "    \n",
        "    #1_6\n",
        "    mk_op2(Equalize, 0.8, 4, TranslateY, 0.8, 9),\n",
        "    mk_op2(TranslateY, 0.8, 9, TranslateY, 0.6, 9),\n",
        "    mk_op2(TranslateY, 0.9, 0, TranslateY, 0.5, 9),\n",
        "    mk_op2(AutoContrast, 0.5, 3, Solarize, 0.3, 4),\n",
        "    mk_op2(Solarize, 0.5, 3, Equalize, 0.4, 4),\n",
        "    \n",
        "    #2_0\n",
        "    mk_op2(Color, 0.7, 7, TranslateX, 0.5, 8),\n",
        "    mk_op2(Equalize, 0.3, 7, AutoContrast, 0.4, 8),\n",
        "    mk_op2(TranslateY, 0.4, 3, Sharpness, 0.2, 6),\n",
        "    mk_op2(Brightness, 0.9, 6, Color, 0.2, 8),\n",
        "    mk_op2(Solarize, 0.5, 2, Invert, 0.0, 3),\n",
        "    \n",
        "    #2_1\n",
        "    mk_op2(AutoContrast, 0.1, 5, Brightness, 0.0, 0),\n",
        "    mk_op2(Cutout, 0.2, 4, Equalize, 0.1, 1),\n",
        "    mk_op2(Equalize, 0.7, 7, AutoContrast, 0.6, 4),\n",
        "    mk_op2(Color, 0.1, 8, ShearY, 0.2, 3),\n",
        "    mk_op2(ShearY, 0.4, 2, Rotate, 0.7, 0),\n",
        "    \n",
        "    #2_2\n",
        "    mk_op2(ShearY, 0.1, 3, AutoContrast, 0.9, 5),\n",
        "    mk_op2(TranslateY, 0.3, 6, Cutout, 0.3, 3),\n",
        "    mk_op2(Equalize, 0.5, 0, Solarize, 0.6, 6),\n",
        "    mk_op2(AutoContrast, 0.3, 5, Rotate, 0.2, 7),\n",
        "    mk_op2(Equalize, 0.8, 2, Invert, 0.4, 0),\n",
        "    \n",
        "    #2_3\n",
        "    mk_op2(Equalize, 0.9, 5, Color, 0.7, 0),\n",
        "    mk_op2(Equalize, 0.1, 1, ShearY, 0.1, 3),\n",
        "    mk_op2(AutoContrast, 0.7, 3, Equalize, 0.7, 0),\n",
        "    mk_op2(Brightness, 0.5, 1, Contrast, 0.1, 7),\n",
        "    mk_op2(Contrast, 0.1, 4, Solarize, 0.6, 5),\n",
        "    \n",
        "    #2_4\n",
        "    mk_op2(Solarize, 0.2, 3, ShearX, 0.0, 0),\n",
        "    mk_op2(TranslateX, 0.3, 0, TranslateX, 0.6, 0),\n",
        "    mk_op2(Equalize, 0.5, 9, TranslateY, 0.6, 7),\n",
        "    mk_op2(ShearX, 0.1, 0, Sharpness, 0.5, 1),\n",
        "    mk_op2(Equalize, 0.8, 6, Invert, 0.3, 6),\n",
        "    \n",
        "    #2_5\n",
        "    mk_op2(AutoContrast, 0.3, 9, Cutout, 0.5, 3),\n",
        "    mk_op2(ShearX, 0.4, 4, AutoContrast, 0.9, 2),\n",
        "    mk_op2(ShearX, 0.0, 3, Posterize, 0.0, 3),\n",
        "    mk_op2(Solarize, 0.4, 3, Color, 0.2, 4),\n",
        "    mk_op2(Equalize, 0.1, 4, Equalize, 0.7, 6),\n",
        "    \n",
        "    #2_6\n",
        "    mk_op2(Equalize, 0.3, 8, AutoContrast, 0.4, 3),\n",
        "    mk_op2(Solarize, 0.6, 4, AutoContrast, 0.7, 6),\n",
        "    mk_op2(AutoContrast, 0.2, 9, Brightness, 0.4, 8),\n",
        "    mk_op2(Equalize, 0.1, 0, Equalize, 0.0, 6),\n",
        "    mk_op2(Equalize, 0.8, 4, Equalize, 0.0, 4),\n",
        "    \n",
        "    #2_7\n",
        "    mk_op2(Equalize, 0.5, 5, AutoContrast, 0.1, 2),\n",
        "    mk_op2(Solarize, 0.5, 5, AutoContrast, 0.9, 5),\n",
        "    mk_op2(AutoContrast, 0.6, 1, AutoContrast, 0.7, 8),\n",
        "    mk_op2(Equalize, 0.2, 0, AutoContrast, 0.1, 2),\n",
        "    mk_op2(Equalize, 0.6, 9, Equalize, 0.4, 4)\n",
        "]\n",
        "\n",
        "\n",
        "aug = autoaugment(tform, X_train, y_train, batch_size) \n",
        "\n",
        "model = create_model(X_train, 10)\n",
        "\n",
        "train_model(model, aug, 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "180/180 [==============================] - 70s 389ms/step - loss: 2.4581 - acc: 0.1135 - val_loss: 2.0783 - val_acc: 0.2264\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 62s 347ms/step - loss: 2.3042 - acc: 0.1370 - val_loss: 2.0000 - val_acc: 0.2642\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 68s 375ms/step - loss: 2.2584 - acc: 0.1450 - val_loss: 1.9712 - val_acc: 0.2750\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 2.2337 - acc: 0.1486 - val_loss: 1.9056 - val_acc: 0.3208\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.2156 - acc: 0.1559 - val_loss: 1.8762 - val_acc: 0.3032\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 68s 378ms/step - loss: 2.2049 - acc: 0.1587 - val_loss: 1.8288 - val_acc: 0.3308\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 2.1869 - acc: 0.1678 - val_loss: 1.7608 - val_acc: 0.3702\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 67s 375ms/step - loss: 2.1714 - acc: 0.1717 - val_loss: 1.7209 - val_acc: 0.3732\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 2.1470 - acc: 0.1825 - val_loss: 1.6758 - val_acc: 0.4020\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 2.1354 - acc: 0.1852 - val_loss: 1.6279 - val_acc: 0.4164\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 2.1316 - acc: 0.1875 - val_loss: 1.6464 - val_acc: 0.4086\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 2.1344 - acc: 0.1842 - val_loss: 1.5842 - val_acc: 0.4190\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 2.1024 - acc: 0.1966 - val_loss: 1.5608 - val_acc: 0.4320\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 2.0866 - acc: 0.2037 - val_loss: 1.5420 - val_acc: 0.4472\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 2.1065 - acc: 0.1953 - val_loss: 1.5680 - val_acc: 0.4376\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 64s 357ms/step - loss: 2.0803 - acc: 0.2078 - val_loss: 1.5026 - val_acc: 0.4690\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0890 - acc: 0.1996 - val_loss: 1.4499 - val_acc: 0.4712\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 2.0933 - acc: 0.2008 - val_loss: 1.4525 - val_acc: 0.4832\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 2.0842 - acc: 0.2043 - val_loss: 1.4330 - val_acc: 0.4910\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 64s 356ms/step - loss: 2.0475 - acc: 0.2183 - val_loss: 1.4205 - val_acc: 0.4894\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 2.0843 - acc: 0.2055 - val_loss: 1.3996 - val_acc: 0.5004\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.0645 - acc: 0.2125 - val_loss: 1.3825 - val_acc: 0.5146\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 63s 350ms/step - loss: 2.0443 - acc: 0.2192 - val_loss: 1.4155 - val_acc: 0.4976\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0555 - acc: 0.2165 - val_loss: 1.3528 - val_acc: 0.5186\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 2.0687 - acc: 0.2084 - val_loss: 1.4760 - val_acc: 0.4900\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 2.0482 - acc: 0.2177 - val_loss: 1.3961 - val_acc: 0.5000\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 65s 359ms/step - loss: 2.0304 - acc: 0.2254 - val_loss: 1.3364 - val_acc: 0.5238\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 71s 394ms/step - loss: 2.0781 - acc: 0.2073 - val_loss: 1.3414 - val_acc: 0.5248\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 2.0301 - acc: 0.2228 - val_loss: 1.3325 - val_acc: 0.5340\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 2.0290 - acc: 0.2266 - val_loss: 1.2848 - val_acc: 0.5422\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.0373 - acc: 0.2237 - val_loss: 1.3027 - val_acc: 0.5442\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 2.0153 - acc: 0.2348 - val_loss: 1.2776 - val_acc: 0.5466\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 2.0155 - acc: 0.2346 - val_loss: 1.3076 - val_acc: 0.5332\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 68s 378ms/step - loss: 2.0233 - acc: 0.2325 - val_loss: 1.3098 - val_acc: 0.5416\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 1.9817 - acc: 0.2511 - val_loss: 1.2796 - val_acc: 0.5558\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 63s 348ms/step - loss: 1.9703 - acc: 0.2582 - val_loss: 1.2877 - val_acc: 0.5488\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0013 - acc: 0.2425 - val_loss: 1.2378 - val_acc: 0.5628\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 66s 368ms/step - loss: 1.9952 - acc: 0.2447 - val_loss: 1.2930 - val_acc: 0.5476\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 1.9813 - acc: 0.2504 - val_loss: 1.2377 - val_acc: 0.5612\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.9804 - acc: 0.2511 - val_loss: 1.2380 - val_acc: 0.5576\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 70s 387ms/step - loss: 2.0130 - acc: 0.2384 - val_loss: 1.2108 - val_acc: 0.5712\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.9719 - acc: 0.2582 - val_loss: 1.2144 - val_acc: 0.5732\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 1.9579 - acc: 0.2649 - val_loss: 1.2328 - val_acc: 0.5664\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 1.9350 - acc: 0.2746 - val_loss: 1.1986 - val_acc: 0.5752\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9695 - acc: 0.2552 - val_loss: 1.1667 - val_acc: 0.5826\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 1.9479 - acc: 0.2664 - val_loss: 1.1524 - val_acc: 0.5970\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9599 - acc: 0.2621 - val_loss: 1.1439 - val_acc: 0.5962\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 63s 349ms/step - loss: 1.9072 - acc: 0.2814 - val_loss: 1.1597 - val_acc: 0.5852\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.9430 - acc: 0.2700 - val_loss: 1.1410 - val_acc: 0.5974\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.9719 - acc: 0.2554 - val_loss: 1.1700 - val_acc: 0.5924\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 63s 347ms/step - loss: 1.9000 - acc: 0.2839 - val_loss: 1.1190 - val_acc: 0.6070\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.9446 - acc: 0.2660 - val_loss: 1.2358 - val_acc: 0.5702\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.9251 - acc: 0.2751 - val_loss: 1.0975 - val_acc: 0.6092\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.9517 - acc: 0.2659 - val_loss: 1.0998 - val_acc: 0.6086\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.9214 - acc: 0.2763 - val_loss: 1.1052 - val_acc: 0.6086\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.9337 - acc: 0.2715 - val_loss: 1.1069 - val_acc: 0.6166\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 64s 354ms/step - loss: 1.8890 - acc: 0.2905 - val_loss: 1.1112 - val_acc: 0.6052\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9202 - acc: 0.2763 - val_loss: 1.1707 - val_acc: 0.5994\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9228 - acc: 0.2761 - val_loss: 1.0660 - val_acc: 0.6222\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.9284 - acc: 0.2751 - val_loss: 1.0778 - val_acc: 0.6180\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.8998 - acc: 0.2859 - val_loss: 1.0466 - val_acc: 0.6318\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 75s 415ms/step - loss: 1.9458 - acc: 0.2679 - val_loss: 1.0571 - val_acc: 0.6362\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 71s 394ms/step - loss: 1.9246 - acc: 0.2729 - val_loss: 1.0988 - val_acc: 0.6108\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.9039 - acc: 0.2846 - val_loss: 1.0448 - val_acc: 0.6310\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 70s 391ms/step - loss: 1.8959 - acc: 0.2867 - val_loss: 1.0474 - val_acc: 0.6390\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.8907 - acc: 0.2868 - val_loss: 1.0847 - val_acc: 0.6236\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 65s 364ms/step - loss: 1.8992 - acc: 0.2841 - val_loss: 1.0059 - val_acc: 0.6508\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 1.8748 - acc: 0.2968 - val_loss: 0.9927 - val_acc: 0.6522\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 66s 368ms/step - loss: 1.8993 - acc: 0.2842 - val_loss: 1.0137 - val_acc: 0.6456\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 71s 395ms/step - loss: 1.9511 - acc: 0.2662 - val_loss: 1.0267 - val_acc: 0.6450\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 68s 375ms/step - loss: 1.9072 - acc: 0.2828 - val_loss: 0.9953 - val_acc: 0.6552\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.9159 - acc: 0.2782 - val_loss: 1.0712 - val_acc: 0.6268\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 65s 360ms/step - loss: 1.8567 - acc: 0.3028 - val_loss: 1.0347 - val_acc: 0.6466\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 68s 380ms/step - loss: 1.8536 - acc: 0.3040 - val_loss: 0.9703 - val_acc: 0.6614\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8652 - acc: 0.2988 - val_loss: 1.0010 - val_acc: 0.6538\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 1.8849 - acc: 0.2907 - val_loss: 0.9867 - val_acc: 0.6604\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.8530 - acc: 0.3038 - val_loss: 1.0046 - val_acc: 0.6546\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 1.8830 - acc: 0.2907 - val_loss: 0.9751 - val_acc: 0.6612\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 61s 341ms/step - loss: 1.8062 - acc: 0.3216 - val_loss: 0.9885 - val_acc: 0.6538\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.8773 - acc: 0.2938 - val_loss: 1.0141 - val_acc: 0.6454\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.8573 - acc: 0.3029 - val_loss: 1.0418 - val_acc: 0.6526\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.8669 - acc: 0.2982 - val_loss: 0.9502 - val_acc: 0.6676\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 71s 393ms/step - loss: 1.8802 - acc: 0.2915 - val_loss: 0.9768 - val_acc: 0.6590\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 72s 399ms/step - loss: 1.9005 - acc: 0.2884 - val_loss: 0.9602 - val_acc: 0.6738\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 69s 385ms/step - loss: 1.8387 - acc: 0.3067 - val_loss: 0.9688 - val_acc: 0.6742\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.8420 - acc: 0.3086 - val_loss: 0.9800 - val_acc: 0.6614\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.8345 - acc: 0.3106 - val_loss: 0.9437 - val_acc: 0.6768\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.8505 - acc: 0.3046 - val_loss: 0.9312 - val_acc: 0.6800\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.8718 - acc: 0.2969 - val_loss: 0.9579 - val_acc: 0.6766\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 70s 387ms/step - loss: 1.8890 - acc: 0.2927 - val_loss: 0.9951 - val_acc: 0.6570\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 1.8556 - acc: 0.3048 - val_loss: 0.9219 - val_acc: 0.6824\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.8285 - acc: 0.3156 - val_loss: 0.9142 - val_acc: 0.6830\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.8405 - acc: 0.3081 - val_loss: 0.9215 - val_acc: 0.6824\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.8286 - acc: 0.3160 - val_loss: 0.9301 - val_acc: 0.6802\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 1.8249 - acc: 0.3155 - val_loss: 0.9071 - val_acc: 0.6844\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8395 - acc: 0.3111 - val_loss: 0.8897 - val_acc: 0.6970\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.8648 - acc: 0.2995 - val_loss: 0.9256 - val_acc: 0.6808\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 63s 351ms/step - loss: 1.8023 - acc: 0.3253 - val_loss: 0.8898 - val_acc: 0.6960\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8484 - acc: 0.3056 - val_loss: 0.8882 - val_acc: 0.6974\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.8521 - acc: 0.3060 - val_loss: 0.9415 - val_acc: 0.6788\n",
            "Test accuracy: 0.683 (elaspsed time: 1507s)\n",
            "Accuracy\n",
            "airplane 0.763\n",
            "auto 0.856\n",
            "bird 0.545\n",
            "cat 0.519\n",
            "deer 0.511\n",
            "dog 0.68\n",
            "frog 0.873\n",
            "horse 0.691\n",
            "ship 0.704\n",
            "truck 0.687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9cYbn-1fYXG4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train some more!\n",
        "train_model(model, aug, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}