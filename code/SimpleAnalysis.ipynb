{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bnN-_dUfAj85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# All Includes\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential, load_model, clone_model\n",
        "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras import models, layers, optimizers, utils\n",
        "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw, PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AS1clr6Av2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Child Model ===**"
      ]
    },
    {
      "metadata": {
        "id": "WJ96_u3_AuHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_model(trainX, n_classes):\n",
        "    # https://stats.stackexchange.com/questions/272607/cifar-10-cant-get-above-60-accuracy-keras-with-tensorflow-backend\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(input_shape=trainX[0,:,:,:].shape, filters=96, kernel_size=(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(filters=96, kernel_size=(3,3), strides=2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Convolution2D(filters=192, kernel_size=(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(filters=192, kernel_size=(3,3), strides=2))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
        "    optimizer = optimizers.Adadelta(lr=0.05, rho=0.95, epsilon=None, decay=0.0)\n",
        "    model.compile(optimizer, 'categorical_crossentropy', ['accuracy'])\n",
        "    return model\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "def model_cond_accuracy(model, X, y):\n",
        "    y_prob = model.predict(X)\n",
        "    y_classes = y_prob.argmax(axis=-1).tolist()\n",
        "    y_test = y.argmax(axis=-1).tolist()\n",
        "    total = [0] * 10\n",
        "    counts = [0] * 10\n",
        "    for i in range(len(y_classes)):\n",
        "      if y_classes[i] == y_test[i]:\n",
        "        total[y_test[i]] += 1\n",
        "      counts[y_test[i]] += 1\n",
        "    acc = [0.0] * 10\n",
        "    for i in range(10):\n",
        "      if 0 != counts[i]:\n",
        "        acc[i] = total[i] / counts[i]\n",
        "    return acc\n",
        "\n",
        "def model_fit(model, gen, val_data, nbatches, epochs):\n",
        "    history = model.fit_generator(\n",
        "      gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n",
        "    return history\n",
        "\n",
        "def model_evaluate(model, X, y):\n",
        "  return model.evaluate(X, y, verbose=0)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qop7WrPVBZ2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Transforms ===**"
      ]
    },
    {
      "metadata": {
        "id": "K6NncO3YBeH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code below adapted from augmentation_transforms.py\n",
        "# Modified to support transforms at the image class level\n",
        "# Original copywright below:\n",
        "\n",
        "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "MEANS = [0.49139968, 0.48215841, 0.44653091]\n",
        "STDS = [0.24703223, 0.24348513, 0.26158784]\n",
        "PARAMETER_MAX = 10  # What is the max 'level' a transform could be predicted\n",
        "\n",
        "def pil_wrap(img):\n",
        "  \"\"\"Convert the `img` numpy tensor to a PIL Image.\"\"\"\n",
        "  return PIL.Image.fromarray(\n",
        "      np.uint8((img * STDS + MEANS) * 255.0)).convert('RGBA')\n",
        "\n",
        "\n",
        "def pil_unwrap(pil_img):\n",
        "  \"\"\"Converts the PIL img to a numpy array.\"\"\"\n",
        "  pic_array = (np.array(pil_img.getdata()).reshape((32, 32, 4)) / 255.0)\n",
        "  i1, i2 = np.where(pic_array[:, :, 3] == 0)\n",
        "  pic_array = (pic_array[:, :, :3] - MEANS) / STDS\n",
        "  pic_array[i1, i2] = [0, 0, 0]\n",
        "  return pic_array\n",
        "\n",
        "class Operation:\n",
        "    def __init__(self, t, p = 0.5):\n",
        "\n",
        "        self.prob = p\n",
        "        self.magnitude = t[1]\n",
        "        self.transformation = t[0]\n",
        "\n",
        "    def __call__(self, X, Y):\n",
        "        _X = []\n",
        "        #self.magnitude = random.randint(0,9)\n",
        "        for x,y in zip(X,Y):\n",
        "            if np.random.rand() < self.prob:\n",
        "                x = pil_wrap(x)\n",
        "                x = self.transformation[np.argmax(y)](x, self.magnitude)\n",
        "                x = pil_unwrap(x)\n",
        "            _X.append(np.array(x))\n",
        "        return np.array(_X)\n",
        "    \n",
        "\n",
        "class Transform:\n",
        "    def __init__(self, *operations):\n",
        "        self.operations = operations\n",
        "\n",
        "    def __call__(self, X, Y):\n",
        "        for op in self.operations:\n",
        "            X = op(X, Y)\n",
        "        return X\n",
        "\n",
        "\n",
        "def autoaugment(transforms, X, y, batch_size):\n",
        "    while True:\n",
        "        ix = np.arange(len(X))\n",
        "        np.random.shuffle(ix)\n",
        "        for i in range(len(X) // batch_size):\n",
        "            _ix = ix[i*batch_size:(i+1)*batch_size]\n",
        "            _X = X[_ix]\n",
        "            _y = y[_ix]\n",
        "            if 0 != len(transforms):\n",
        "              transform = np.random.choice(transforms)\n",
        "              _X = transform(_X, _y)\n",
        "            yield _X, _y\n",
        "\n",
        "# modified from https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\n",
        "def create_cutout_mask(img_height, img_width, num_channels, size):\n",
        "  \"\"\"Creates a zero mask used for cutout of shape `img_height` x `img_width`.\n",
        "\n",
        "  Args:\n",
        "    img_height: Height of image cutout mask will be applied to.\n",
        "    img_width: Width of image cutout mask will be applied to.\n",
        "    num_channels: Number of channels in the image.\n",
        "    size: Size of the zeros mask.\n",
        "\n",
        "  Returns:\n",
        "    A mask of shape `img_height` x `img_width` with all ones except for a\n",
        "    square of zeros of shape `size` x `size`. This mask is meant to be\n",
        "    elementwise multiplied with the original image. Additionally returns\n",
        "    the `upper_coord` and `lower_coord` which specify where the cutout mask\n",
        "    will be applied.\n",
        "  \"\"\"\n",
        "  assert img_height == img_width\n",
        "\n",
        "  # Sample center where cutout mask will be applied\n",
        "  height_loc = np.random.randint(low=0, high=img_height)\n",
        "  width_loc = np.random.randint(low=0, high=img_width)\n",
        "\n",
        "  # Determine upper right and lower left corners of patch\n",
        "  upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "  lower_coord = (min(img_height, height_loc + size // 2),\n",
        "                 min(img_width, width_loc + size // 2))\n",
        "  mask_height = lower_coord[0] - upper_coord[0]\n",
        "  mask_width = lower_coord[1] - upper_coord[1]\n",
        "  assert mask_height > 0\n",
        "  assert mask_width > 0\n",
        "\n",
        "  mask = np.ones((img_height, img_width, num_channels))\n",
        "  zeros = np.zeros((mask_height, mask_width, num_channels))\n",
        "  mask[upper_coord[0]:lower_coord[0], upper_coord[1]:lower_coord[1], :] = (\n",
        "      zeros)\n",
        "  return mask, upper_coord, lower_coord\n",
        "\n",
        "def cutout_numpy(img, size=16):\n",
        "  \"\"\"Apply cutout with mask of shape `size` x `size` to `img`.\n",
        "\n",
        "  The cutout operation is from the paper https://arxiv.org/abs/1708.04552.\n",
        "  This operation applies a `size`x`size` mask of zeros to a random location\n",
        "  within `img`.\n",
        "\n",
        "  Args:\n",
        "    img: Numpy image that cutout will be applied to.\n",
        "    size: Height/width of the cutout mask that will be\n",
        "\n",
        "  Returns:\n",
        "    A numpy tensor that is the result of applying the cutout mask to `img`.\n",
        "  \"\"\"\n",
        "  img_height, img_width, num_channels = (img.shape[0], img.shape[1],\n",
        "                                         img.shape[2])\n",
        "  assert len(img.shape) == 3\n",
        "  mask, _, _ = create_cutout_mask(img_height, img_width, num_channels, size)\n",
        "  return img * mask\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled\n",
        "      to level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    A float that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return float(level) * maxval / PARAMETER_MAX\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled\n",
        "      to level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    An int that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return int(level * maxval / PARAMETER_MAX)\n",
        "\n",
        "def _cutout_pil_impl(pil_img, level):\n",
        "  \"\"\"Apply cutout to pil_img at the specified level.\"\"\"\n",
        "  size = int_parameter(level, 20)\n",
        "  if size <= 0:\n",
        "    return pil_img\n",
        "  img_height, img_width, num_channels = (32, 32, 3)\n",
        "  _, upper_coord, lower_coord = (\n",
        "      create_cutout_mask(img_height, img_width, num_channels, size))\n",
        "  pixels = pil_img.load()  # create the pixel map\n",
        "  for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "    for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "      pixels[i, j] = (125, 122, 113, 0)  # set the colour accordingly\n",
        "  return pil_img\n",
        "\n",
        "def _enhancer_impl(enhancer):\n",
        "  \"\"\"Sets level to be between 0.1 and 1.8 for ImageEnhance transforms of PIL.\"\"\"\n",
        "  def impl(pil_img, level):\n",
        "    v = float_parameter(level, 1.8) + .1  # going to 0 just destroys it\n",
        "    return enhancer(pil_img).enhance(v)\n",
        "  return impl\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "def ShearX(img, v):  # [-0.3, 0.3]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "  \n",
        "def ShearY(img, v):  # [-0.3, 0.3]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))  \n",
        "  \n",
        "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform((32, 32), PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.transform((32, 32), PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "def Rotate(img, v):  # [-30, 30]\n",
        "    if random.random() > 0.5:\n",
        "      v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "def AutoContrast(img, _):\n",
        "    return PIL.ImageOps.autocontrast(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Invert(img, _):\n",
        "    return PIL.ImageOps.invert(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Equalize(img, _):\n",
        "    return PIL.ImageOps.equalize(img.convert('RGB')).convert('RGBA')\n",
        "\n",
        "def Flip_LR(img, _):  # not from the paper\n",
        "    return img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "def Flip_UD(img, _):\n",
        "    return img.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  \n",
        "def Solarize(img, v):  # [0, 256]\n",
        "    v = int_parameter(v, 256)\n",
        "    return PIL.ImageOps.solarize(img.convert('RGB'), 256 - v).convert('RGBA')\n",
        "\n",
        "def Posterize(img, v):  # [4, 8]\n",
        "    v = int_parameter(v, 4)\n",
        "    return PIL.ImageOps.posterize(img.convert('RGB'), 4 - v).convert('RGBA')\n",
        "\n",
        "def Contrast(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Contrast)(img, v)\n",
        "\n",
        "def Blur(img, v):\n",
        "    return img.filter(PIL.ImageFilter.BLUR)\n",
        "  \n",
        "def Color(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Color)(img, v)\n",
        "\n",
        "def Smooth(img, v):\n",
        "    return img.filter(PIL.ImageFilter.SMOOTH)\n",
        "  \n",
        "def Brightness(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Brightness)(img, v)\n",
        "\n",
        "def Sharpness(img, v):  # [0.1,1.9]\n",
        "    return _enhancer_impl(PIL.ImageEnhance.Sharpness)(img, v)\n",
        "\n",
        "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
        "    return _cutout_pil_impl(img, v)\n",
        "\n",
        "def Crop(img, v, interpolation=PIL.Image.BILINEAR):\n",
        "    cropped = img.crop((v, v, IMAGE_SIZE - v, IMAGE_SIZE - v))\n",
        "    resized = cropped.resize((IMAGE_SIZE, IMAGE_SIZE), interpolation)\n",
        "    return resized\n",
        "\n",
        "def Identity(img, v):\n",
        "  return img\n",
        "\n",
        "  \n",
        "opmap = {\n",
        "    'Flip_LR' : Flip_LR,\n",
        "    'Flip_UD' : Flip_UD,\n",
        "    'AutoContrast' : AutoContrast,\n",
        "    'Equalize' : Equalize,\n",
        "    'Invert' : Invert,\n",
        "    'Rotate' : Rotate,\n",
        "    'Poserize' : Posterize,\n",
        "    'Crop' : Crop,\n",
        "    'Solarize' : Solarize,\n",
        "    'Color' : Color,\n",
        "    'Contrast' : Contrast,\n",
        "    'Brightness' : Brightness,\n",
        "    'Sharpness' : Sharpness,\n",
        "    'ShearX' : ShearX,\n",
        "    'ShearY' : ShearY,\n",
        "    'TranslateX' : TranslateX,\n",
        "    'TranslateY' : TranslateY,\n",
        "    'Cutout' : Cutout,\n",
        "    'Blur' : Blur,\n",
        "    'Smooth' : Smooth\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzpINrgRB2uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=== Get Ready... ===**"
      ]
    },
    {
      "metadata": {
        "id": "fE1On7L-B7Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ff7f3d7c-5332-4353-893c-4cb4672dabd2"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10\n",
        "from keras.datasets import cifar10\n",
        "(X, y), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Create the Reduced CIFAR-10 dataset\n",
        "#ix = np.random.choice(len(X), 4000, False)\n",
        "#x_reduced_train = X[ix]\n",
        "#y_reduced_train = y[ix]\n",
        "\n",
        "# Shuffle the training data\n",
        "shuffling = np.random.permutation(X.shape[0])   \n",
        "X = X[shuffling, :]\n",
        "y = y[shuffling]\n",
        "\n",
        "# Split Training --> Training + Validation\n",
        "nTrain = int(0.9 * X.shape[0])\n",
        "X_train = X[0:nTrain, :, :, :]\n",
        "y_train = y[:nTrain]\n",
        "\n",
        "X_validation = X[nTrain:, :, :, :]\n",
        "y_validation = y[nTrain:]\n",
        "\n",
        "X_reduced = X[:4000, :, :, :]\n",
        "y_reduced = y[:4000]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_validation.shape)\n",
        "print(X_reduced.shape)\n",
        "\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_validation = utils.to_categorical(y_validation)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "y_reduced = utils.to_categorical(y_reduced)\n",
        "\n",
        "categories = ['airplane', 'auto', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(4000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R60JBZnAFtsK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 250\n",
        "\n",
        "def train_model(X, model, aug, epochs):\n",
        "\n",
        "  tic = time.clock()\n",
        "  model_fit(model, aug, (X_validation, y_validation), len(X) // batch_size, epochs)\n",
        "  toc = time.clock()\n",
        "  \n",
        "  accuracy = model_evaluate(model, X_test, y_test)\n",
        "  \n",
        "  print('Test accuracy: %.3f (elaspsed time: %ds)' % (accuracy, (toc-tic)))\n",
        "  acc = model_cond_accuracy(model, X_test, y_test)\n",
        "  \n",
        "  print(\"Accuracy\")\n",
        "  for cat, a in zip(categories, acc):\n",
        "    print(cat, a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rvEYCZ0FSc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Baseline Training Without Data Augmentation**"
      ]
    },
    {
      "metadata": {
        "id": "CaqB-oyIGiek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2074
        },
        "outputId": "5256ef71-bef8-4413-995d-5b1157ccefcd"
      },
      "cell_type": "code",
      "source": [
        "ops = [Operation(([Identity] * 10, 0), 0)]\n",
        "transform1 = Transform(*ops)\n",
        "\n",
        "transforms = [transform1]\n",
        "aug = autoaugment(transforms, X_train, y_train, batch_size) \n",
        "\n",
        "model0 = create_model(X_train, 10)\n",
        "\n",
        "history0 = train_model(model0, aug, 50)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "180/180 [==============================] - 19s 107ms/step - loss: 2.3150 - acc: 0.2157 - val_loss: 1.9072 - val_acc: 0.3130\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.9128 - acc: 0.3246 - val_loss: 1.6609 - val_acc: 0.4032\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.7215 - acc: 0.3860 - val_loss: 1.6090 - val_acc: 0.4246\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.5929 - acc: 0.4275 - val_loss: 1.4410 - val_acc: 0.4826\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.5025 - acc: 0.4597 - val_loss: 1.3629 - val_acc: 0.5158\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.4435 - acc: 0.4834 - val_loss: 1.3087 - val_acc: 0.5280\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.3849 - acc: 0.5032 - val_loss: 1.2902 - val_acc: 0.5464\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.3344 - acc: 0.5220 - val_loss: 1.2782 - val_acc: 0.5480\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.2898 - acc: 0.5406 - val_loss: 1.2018 - val_acc: 0.5720\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.2501 - acc: 0.5557 - val_loss: 1.1615 - val_acc: 0.5810\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.2083 - acc: 0.5708 - val_loss: 1.1508 - val_acc: 0.5942\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1789 - acc: 0.5790 - val_loss: 1.1337 - val_acc: 0.6010\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1453 - acc: 0.5930 - val_loss: 1.1505 - val_acc: 0.5938\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.1116 - acc: 0.6074 - val_loss: 1.0766 - val_acc: 0.6178\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.0900 - acc: 0.6140 - val_loss: 1.0477 - val_acc: 0.6288\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 1.0635 - acc: 0.6237 - val_loss: 1.0395 - val_acc: 0.6348\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 1.0331 - acc: 0.6321 - val_loss: 1.0257 - val_acc: 0.6414\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 1.0089 - acc: 0.6453 - val_loss: 1.0067 - val_acc: 0.6410\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9806 - acc: 0.6522 - val_loss: 0.9656 - val_acc: 0.6598\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9578 - acc: 0.6627 - val_loss: 0.9530 - val_acc: 0.6666\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 0.9358 - acc: 0.6701 - val_loss: 0.9439 - val_acc: 0.6700\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.9225 - acc: 0.6758 - val_loss: 0.9317 - val_acc: 0.6722\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8991 - acc: 0.6840 - val_loss: 0.9635 - val_acc: 0.6708\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8805 - acc: 0.6892 - val_loss: 0.9416 - val_acc: 0.6712\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8608 - acc: 0.6998 - val_loss: 0.9110 - val_acc: 0.6844\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8418 - acc: 0.7046 - val_loss: 0.8633 - val_acc: 0.6990\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8271 - acc: 0.7096 - val_loss: 0.8758 - val_acc: 0.6986\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.8083 - acc: 0.7178 - val_loss: 0.8852 - val_acc: 0.6930\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7924 - acc: 0.7196 - val_loss: 0.8795 - val_acc: 0.6906\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 17s 95ms/step - loss: 0.7792 - acc: 0.7270 - val_loss: 0.8430 - val_acc: 0.7056\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 17s 95ms/step - loss: 0.7621 - acc: 0.7336 - val_loss: 0.8695 - val_acc: 0.6978\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7502 - acc: 0.7379 - val_loss: 0.8353 - val_acc: 0.7112\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7354 - acc: 0.7430 - val_loss: 0.8359 - val_acc: 0.7134\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7235 - acc: 0.7454 - val_loss: 0.8330 - val_acc: 0.7118\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 17s 94ms/step - loss: 0.7082 - acc: 0.7502 - val_loss: 0.8219 - val_acc: 0.7142\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 0.6935 - acc: 0.7565 - val_loss: 0.8084 - val_acc: 0.7196\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6832 - acc: 0.7593 - val_loss: 0.9269 - val_acc: 0.6852\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6749 - acc: 0.7609 - val_loss: 0.8189 - val_acc: 0.7238\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 0.6587 - acc: 0.7704 - val_loss: 0.7826 - val_acc: 0.7236\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6506 - acc: 0.7715 - val_loss: 0.8731 - val_acc: 0.7040\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6431 - acc: 0.7734 - val_loss: 0.7932 - val_acc: 0.7336\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6305 - acc: 0.7777 - val_loss: 0.7834 - val_acc: 0.7298\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 0.6196 - acc: 0.7839 - val_loss: 0.7800 - val_acc: 0.7320\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.6041 - acc: 0.7888 - val_loss: 0.7767 - val_acc: 0.7300\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5970 - acc: 0.7895 - val_loss: 0.7969 - val_acc: 0.7260\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5857 - acc: 0.7956 - val_loss: 0.7754 - val_acc: 0.7356\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5751 - acc: 0.7981 - val_loss: 0.7692 - val_acc: 0.7362\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 18s 99ms/step - loss: 0.5615 - acc: 0.8014 - val_loss: 0.7742 - val_acc: 0.7336\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5570 - acc: 0.8054 - val_loss: 0.7603 - val_acc: 0.7434\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 0.5480 - acc: 0.8068 - val_loss: 0.7450 - val_acc: 0.7418\n",
            "Test accuracy: 0.745 (elaspsed time: 722s)\n",
            "Accuracy\n",
            "airplane 0.742\n",
            "auto 0.86\n",
            "bird 0.63\n",
            "cat 0.583\n",
            "deer 0.681\n",
            "dog 0.701\n",
            "frog 0.823\n",
            "horse 0.792\n",
            "ship 0.835\n",
            "truck 0.798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xbBRcjrgODS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train for each individual image transform**\n",
        "Do transforms have significantly different effects for each image class?"
      ]
    },
    {
      "metadata": {
        "id": "aRR1t1pmgOab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        },
        "outputId": "e179bf9a-0754-4034-a9e2-35ec463812c6"
      },
      "cell_type": "code",
      "source": [
        "# Try one to see how many epochs to try... 100 seems to work well; need lots of extra training!\n",
        "op = opmap['Flip_LR']\n",
        "print('=========================================================')\n",
        "print('=========================================================')\n",
        "print('=== ', 'Flip_LR', ' ===')\n",
        "\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug = autoaugment(transform, X_train, y_train, batch_size) \n",
        "\n",
        "model = create_model(X_train, 10)\n",
        "\n",
        "history = train_model(model, aug, 100)\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "=========================================================\n",
            "===  Flip_LR  ===\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2195, in fromarray\n    mode, rawmode = _fromarray_typemap[typekey]\nKeyError: ((1, 1, 32, 3), '|u1')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"<ipython-input-14-9aaebf33287a>\", line 63, in autoaugment\n    _X = transform(_X, _y)\n  File \"<ipython-input-14-9aaebf33287a>\", line 47, in __call__\n    X = pil_wrap(X)\n  File \"<ipython-input-14-9aaebf33287a>\", line 12, in pil_wrap\n    np.uint8((img * STDS + MEANS) * 255.0)).convert('RGBA')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2198, in fromarray\n    raise TypeError(\"Cannot handle this data type\")\nTypeError: Cannot handle this data type\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-887411ebe145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-698a4fa13395>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, aug, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fbaf30ece83c>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, gen, val_data, nbatches, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     history = model.fit_generator(\n\u001b[0;32m---> 46\u001b[0;31m       gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PFfqv5A5qNcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        },
        "outputId": "1bd2c8c9-eb18-4ede-d873-c835a8f58d5b"
      },
      "cell_type": "code",
      "source": [
        "for name, op in opmap.items():\n",
        "  print('=========================================================')\n",
        "  print('=========================================================')\n",
        "  print('=== ', name, ' ===')\n",
        "\n",
        "  # 50% prob of transform\n",
        "  ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "  transform = [Transform(*ops)]\n",
        "\n",
        "  aug = autoaugment(transform, X_train, y_train, batch_size) \n",
        "  \n",
        "  model = create_model(X_train, 10)\n",
        "\n",
        "  history = train_model(model, aug, 100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "=========================================================\n",
            "===  Flip_LR  ===\n",
            "Epoch 1/100\n",
            " 74/180 [===========>..................] - ETA: 20s - loss: 2.5491 - acc: 0.1252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-23:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
            "    return six.next(_SHARED_SEQUENCES[uid])\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 62, in autoaugment\n",
            "    _X = transform(_X, _y)\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 48, in __call__\n",
            "    X = op(X, Y)\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 37, in __call__\n",
            "    x = pil_unwrap(x)\n",
            "KeyboardInterrupt\n",
            "  File \"<ipython-input-4-d4f43fd572ab>\", line 19, in pil_unwrap\n",
            "    pic_array = (pic_array[:, :, :3] - MEANS) / STDS\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1ecb09e7bf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-698a4fa13395>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, aug, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fbaf30ece83c>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, gen, val_data, nbatches, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     history = model.fit_generator(\n\u001b[0;32m---> 46\u001b[0;31m       gen, nbatches, epochs, verbose=1, use_multiprocessing=True, validation_data =  val_data)\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qvhbTUSMG50q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**AutoAugment Policy**"
      ]
    },
    {
      "metadata": {
        "id": "F3L2JdSGHhE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3621
        },
        "outputId": "dec4199a-3c2b-40b8-fc74-e66e37e9feaa"
      },
      "cell_type": "code",
      "source": [
        "# Utility function to create policy, tform, below\n",
        "def mk_op2(op1, p1, v1, op2, p2, v2):\n",
        "  ops = [Operation(([op1] * 10, v1), p1), Operation(([op2] * 10, v2), p2)]\n",
        "  return Transform(*ops)\n",
        "\n",
        "# Duplicate the AutoAugment CIFAR-10 policy selected by concatenations of AutoAugment\n",
        "tform = [\n",
        "    #0_0\n",
        "    mk_op2(Invert, 0.1, 7, Contrast, 0.2, 6),\n",
        "    mk_op2(Rotate, 0.7, 2, TranslateX, 0.3, 9),\n",
        "    mk_op2(Sharpness, 0.8, 1, Sharpness, 0.9, 3),\n",
        "    mk_op2(ShearY, 0.5, 8, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.5, 8, Equalize, 0.9, 2),\n",
        "    \n",
        "    #1_0\n",
        "    mk_op2(ShearY, 0.2, 7, Posterize, 0.3, 7),\n",
        "    mk_op2(Color, 0.4, 3, Brightness, 0.6, 7),\n",
        "    mk_op2(Sharpness, 0.3, 9, Brightness, 0.7, 9),\n",
        "    mk_op2(Equalize, 0.6, 5, Equalize, 0.5, 1),\n",
        "    mk_op2(Contrast, 0.6, 7, Sharpness, 0.6, 5),\n",
        "    \n",
        "    #2_0\n",
        "    mk_op2(Color, 0.7, 7, TranslateX, 0.5, 8),\n",
        "    mk_op2(Equalize, 0.3, 7, AutoContrast, 0.4, 8),\n",
        "    mk_op2(TranslateY, 0.4, 3, Sharpness, 0.2, 6),\n",
        "    mk_op2(Brightness, 0.9, 6, Color, 0.2, 8),\n",
        "    mk_op2(Solarize, 0.5, 2, Invert, 0.0, 3),\n",
        "    \n",
        "    #3_0\n",
        "    mk_op2(Equalize,0.2,0, AutoContrast,0.6,0),\n",
        "    mk_op2(Equalize,0.2,8, Equalize,0.6,4),\n",
        "    mk_op2(Color,0.9,9, Equalize,0.6,6),\n",
        "    mk_op2(AutoContrast,0.8,4, Solarize,0.2,8),\n",
        "    mk_op2(Brightness,0.1,3, Color,0.7,0),\n",
        "    \n",
        "    #4_0\n",
        "    mk_op2(Solarize,0.4,5, AutoContrast,0.9,3),\n",
        "    mk_op2(TranslateY,0.9,9, TranslateY,0.7,9),\n",
        "    mk_op2(AutoContrast,0.9,2, Solarize,0.8,3),\n",
        "    mk_op2(Equalize,0.8,8, Invert,0.1,3),\n",
        "    mk_op2(TranslateY,0.7,9, AutoContrast,0.9,1)\n",
        "]\n",
        "\n",
        "\n",
        "aug = autoaugment(tform, X_train, y_train, batch_size) \n",
        "\n",
        "model = create_model(X_train, 10)\n",
        "\n",
        "train_model(model, aug, 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "180/180 [==============================] - 70s 389ms/step - loss: 2.4581 - acc: 0.1135 - val_loss: 2.0783 - val_acc: 0.2264\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 62s 347ms/step - loss: 2.3042 - acc: 0.1370 - val_loss: 2.0000 - val_acc: 0.2642\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 68s 375ms/step - loss: 2.2584 - acc: 0.1450 - val_loss: 1.9712 - val_acc: 0.2750\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 2.2337 - acc: 0.1486 - val_loss: 1.9056 - val_acc: 0.3208\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.2156 - acc: 0.1559 - val_loss: 1.8762 - val_acc: 0.3032\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 68s 378ms/step - loss: 2.2049 - acc: 0.1587 - val_loss: 1.8288 - val_acc: 0.3308\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 2.1869 - acc: 0.1678 - val_loss: 1.7608 - val_acc: 0.3702\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 67s 375ms/step - loss: 2.1714 - acc: 0.1717 - val_loss: 1.7209 - val_acc: 0.3732\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 2.1470 - acc: 0.1825 - val_loss: 1.6758 - val_acc: 0.4020\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 2.1354 - acc: 0.1852 - val_loss: 1.6279 - val_acc: 0.4164\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 2.1316 - acc: 0.1875 - val_loss: 1.6464 - val_acc: 0.4086\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 2.1344 - acc: 0.1842 - val_loss: 1.5842 - val_acc: 0.4190\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 2.1024 - acc: 0.1966 - val_loss: 1.5608 - val_acc: 0.4320\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 2.0866 - acc: 0.2037 - val_loss: 1.5420 - val_acc: 0.4472\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 2.1065 - acc: 0.1953 - val_loss: 1.5680 - val_acc: 0.4376\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 64s 357ms/step - loss: 2.0803 - acc: 0.2078 - val_loss: 1.5026 - val_acc: 0.4690\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0890 - acc: 0.1996 - val_loss: 1.4499 - val_acc: 0.4712\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 2.0933 - acc: 0.2008 - val_loss: 1.4525 - val_acc: 0.4832\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 2.0842 - acc: 0.2043 - val_loss: 1.4330 - val_acc: 0.4910\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 64s 356ms/step - loss: 2.0475 - acc: 0.2183 - val_loss: 1.4205 - val_acc: 0.4894\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 2.0843 - acc: 0.2055 - val_loss: 1.3996 - val_acc: 0.5004\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.0645 - acc: 0.2125 - val_loss: 1.3825 - val_acc: 0.5146\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 63s 350ms/step - loss: 2.0443 - acc: 0.2192 - val_loss: 1.4155 - val_acc: 0.4976\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0555 - acc: 0.2165 - val_loss: 1.3528 - val_acc: 0.5186\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 2.0687 - acc: 0.2084 - val_loss: 1.4760 - val_acc: 0.4900\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 2.0482 - acc: 0.2177 - val_loss: 1.3961 - val_acc: 0.5000\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 65s 359ms/step - loss: 2.0304 - acc: 0.2254 - val_loss: 1.3364 - val_acc: 0.5238\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 71s 394ms/step - loss: 2.0781 - acc: 0.2073 - val_loss: 1.3414 - val_acc: 0.5248\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 2.0301 - acc: 0.2228 - val_loss: 1.3325 - val_acc: 0.5340\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 2.0290 - acc: 0.2266 - val_loss: 1.2848 - val_acc: 0.5422\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 2.0373 - acc: 0.2237 - val_loss: 1.3027 - val_acc: 0.5442\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 2.0153 - acc: 0.2348 - val_loss: 1.2776 - val_acc: 0.5466\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 2.0155 - acc: 0.2346 - val_loss: 1.3076 - val_acc: 0.5332\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 68s 378ms/step - loss: 2.0233 - acc: 0.2325 - val_loss: 1.3098 - val_acc: 0.5416\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 1.9817 - acc: 0.2511 - val_loss: 1.2796 - val_acc: 0.5558\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 63s 348ms/step - loss: 1.9703 - acc: 0.2582 - val_loss: 1.2877 - val_acc: 0.5488\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 2.0013 - acc: 0.2425 - val_loss: 1.2378 - val_acc: 0.5628\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 66s 368ms/step - loss: 1.9952 - acc: 0.2447 - val_loss: 1.2930 - val_acc: 0.5476\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 1.9813 - acc: 0.2504 - val_loss: 1.2377 - val_acc: 0.5612\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.9804 - acc: 0.2511 - val_loss: 1.2380 - val_acc: 0.5576\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 70s 387ms/step - loss: 2.0130 - acc: 0.2384 - val_loss: 1.2108 - val_acc: 0.5712\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.9719 - acc: 0.2582 - val_loss: 1.2144 - val_acc: 0.5732\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 65s 361ms/step - loss: 1.9579 - acc: 0.2649 - val_loss: 1.2328 - val_acc: 0.5664\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 63s 352ms/step - loss: 1.9350 - acc: 0.2746 - val_loss: 1.1986 - val_acc: 0.5752\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9695 - acc: 0.2552 - val_loss: 1.1667 - val_acc: 0.5826\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 1.9479 - acc: 0.2664 - val_loss: 1.1524 - val_acc: 0.5970\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9599 - acc: 0.2621 - val_loss: 1.1439 - val_acc: 0.5962\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 63s 349ms/step - loss: 1.9072 - acc: 0.2814 - val_loss: 1.1597 - val_acc: 0.5852\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.9430 - acc: 0.2700 - val_loss: 1.1410 - val_acc: 0.5974\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.9719 - acc: 0.2554 - val_loss: 1.1700 - val_acc: 0.5924\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 63s 347ms/step - loss: 1.9000 - acc: 0.2839 - val_loss: 1.1190 - val_acc: 0.6070\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.9446 - acc: 0.2660 - val_loss: 1.2358 - val_acc: 0.5702\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.9251 - acc: 0.2751 - val_loss: 1.0975 - val_acc: 0.6092\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.9517 - acc: 0.2659 - val_loss: 1.0998 - val_acc: 0.6086\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.9214 - acc: 0.2763 - val_loss: 1.1052 - val_acc: 0.6086\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.9337 - acc: 0.2715 - val_loss: 1.1069 - val_acc: 0.6166\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 64s 354ms/step - loss: 1.8890 - acc: 0.2905 - val_loss: 1.1112 - val_acc: 0.6052\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9202 - acc: 0.2763 - val_loss: 1.1707 - val_acc: 0.5994\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.9228 - acc: 0.2761 - val_loss: 1.0660 - val_acc: 0.6222\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.9284 - acc: 0.2751 - val_loss: 1.0778 - val_acc: 0.6180\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.8998 - acc: 0.2859 - val_loss: 1.0466 - val_acc: 0.6318\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 75s 415ms/step - loss: 1.9458 - acc: 0.2679 - val_loss: 1.0571 - val_acc: 0.6362\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 71s 394ms/step - loss: 1.9246 - acc: 0.2729 - val_loss: 1.0988 - val_acc: 0.6108\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.9039 - acc: 0.2846 - val_loss: 1.0448 - val_acc: 0.6310\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 70s 391ms/step - loss: 1.8959 - acc: 0.2867 - val_loss: 1.0474 - val_acc: 0.6390\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.8907 - acc: 0.2868 - val_loss: 1.0847 - val_acc: 0.6236\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 65s 364ms/step - loss: 1.8992 - acc: 0.2841 - val_loss: 1.0059 - val_acc: 0.6508\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 1.8748 - acc: 0.2968 - val_loss: 0.9927 - val_acc: 0.6522\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 66s 368ms/step - loss: 1.8993 - acc: 0.2842 - val_loss: 1.0137 - val_acc: 0.6456\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 71s 395ms/step - loss: 1.9511 - acc: 0.2662 - val_loss: 1.0267 - val_acc: 0.6450\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 68s 375ms/step - loss: 1.9072 - acc: 0.2828 - val_loss: 0.9953 - val_acc: 0.6552\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.9159 - acc: 0.2782 - val_loss: 1.0712 - val_acc: 0.6268\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 65s 360ms/step - loss: 1.8567 - acc: 0.3028 - val_loss: 1.0347 - val_acc: 0.6466\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 68s 380ms/step - loss: 1.8536 - acc: 0.3040 - val_loss: 0.9703 - val_acc: 0.6614\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8652 - acc: 0.2988 - val_loss: 1.0010 - val_acc: 0.6538\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 1.8849 - acc: 0.2907 - val_loss: 0.9867 - val_acc: 0.6604\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.8530 - acc: 0.3038 - val_loss: 1.0046 - val_acc: 0.6546\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 66s 364ms/step - loss: 1.8830 - acc: 0.2907 - val_loss: 0.9751 - val_acc: 0.6612\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 61s 341ms/step - loss: 1.8062 - acc: 0.3216 - val_loss: 0.9885 - val_acc: 0.6538\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.8773 - acc: 0.2938 - val_loss: 1.0141 - val_acc: 0.6454\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.8573 - acc: 0.3029 - val_loss: 1.0418 - val_acc: 0.6526\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.8669 - acc: 0.2982 - val_loss: 0.9502 - val_acc: 0.6676\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 71s 393ms/step - loss: 1.8802 - acc: 0.2915 - val_loss: 0.9768 - val_acc: 0.6590\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 72s 399ms/step - loss: 1.9005 - acc: 0.2884 - val_loss: 0.9602 - val_acc: 0.6738\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 69s 385ms/step - loss: 1.8387 - acc: 0.3067 - val_loss: 0.9688 - val_acc: 0.6742\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.8420 - acc: 0.3086 - val_loss: 0.9800 - val_acc: 0.6614\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.8345 - acc: 0.3106 - val_loss: 0.9437 - val_acc: 0.6768\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.8505 - acc: 0.3046 - val_loss: 0.9312 - val_acc: 0.6800\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.8718 - acc: 0.2969 - val_loss: 0.9579 - val_acc: 0.6766\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 70s 387ms/step - loss: 1.8890 - acc: 0.2927 - val_loss: 0.9951 - val_acc: 0.6570\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 64s 358ms/step - loss: 1.8556 - acc: 0.3048 - val_loss: 0.9219 - val_acc: 0.6824\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.8285 - acc: 0.3156 - val_loss: 0.9142 - val_acc: 0.6830\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.8405 - acc: 0.3081 - val_loss: 0.9215 - val_acc: 0.6824\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.8286 - acc: 0.3160 - val_loss: 0.9301 - val_acc: 0.6802\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 1.8249 - acc: 0.3155 - val_loss: 0.9071 - val_acc: 0.6844\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8395 - acc: 0.3111 - val_loss: 0.8897 - val_acc: 0.6970\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.8648 - acc: 0.2995 - val_loss: 0.9256 - val_acc: 0.6808\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 63s 351ms/step - loss: 1.8023 - acc: 0.3253 - val_loss: 0.8898 - val_acc: 0.6960\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 69s 384ms/step - loss: 1.8484 - acc: 0.3056 - val_loss: 0.8882 - val_acc: 0.6974\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.8521 - acc: 0.3060 - val_loss: 0.9415 - val_acc: 0.6788\n",
            "Test accuracy: 0.683 (elaspsed time: 1507s)\n",
            "Accuracy\n",
            "airplane 0.763\n",
            "auto 0.856\n",
            "bird 0.545\n",
            "cat 0.519\n",
            "deer 0.511\n",
            "dog 0.68\n",
            "frog 0.873\n",
            "horse 0.691\n",
            "ship 0.704\n",
            "truck 0.687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9cYbn-1fYXG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "c0a1b72c-703f-41d2-af32-76f1b3e392e0"
      },
      "cell_type": "code",
      "source": [
        "# Train some more!\n",
        "train_model(model, aug, 50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "180/180 [==============================] - 72s 401ms/step - loss: 1.8773 - acc: 0.2979 - val_loss: 0.9740 - val_acc: 0.6722\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.7850 - acc: 0.3317 - val_loss: 0.8716 - val_acc: 0.7034\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 71s 396ms/step - loss: 1.8211 - acc: 0.3178 - val_loss: 0.8782 - val_acc: 0.6956\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.8184 - acc: 0.3182 - val_loss: 0.9371 - val_acc: 0.6832\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 70s 387ms/step - loss: 1.8349 - acc: 0.3130 - val_loss: 0.8924 - val_acc: 0.6952\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 67s 375ms/step - loss: 1.8439 - acc: 0.3077 - val_loss: 0.8524 - val_acc: 0.7088\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.8352 - acc: 0.3104 - val_loss: 0.8808 - val_acc: 0.7002\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 67s 374ms/step - loss: 1.8266 - acc: 0.3169 - val_loss: 0.8753 - val_acc: 0.6910\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 1.7945 - acc: 0.3296 - val_loss: 0.9788 - val_acc: 0.6710\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 65s 360ms/step - loss: 1.8039 - acc: 0.3244 - val_loss: 0.8795 - val_acc: 0.7026\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.8158 - acc: 0.3192 - val_loss: 0.8460 - val_acc: 0.7132\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 67s 374ms/step - loss: 1.8289 - acc: 0.3124 - val_loss: 0.8664 - val_acc: 0.7028\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 64s 357ms/step - loss: 1.7840 - acc: 0.3329 - val_loss: 0.8492 - val_acc: 0.7074\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.7656 - acc: 0.3428 - val_loss: 0.8555 - val_acc: 0.7022\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 70s 390ms/step - loss: 1.8210 - acc: 0.3184 - val_loss: 0.8322 - val_acc: 0.7156\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 1.7918 - acc: 0.3293 - val_loss: 0.8253 - val_acc: 0.7170\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 70s 389ms/step - loss: 1.8059 - acc: 0.3218 - val_loss: 0.8283 - val_acc: 0.7192\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 69s 381ms/step - loss: 1.8158 - acc: 0.3205 - val_loss: 0.8617 - val_acc: 0.7044\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.8131 - acc: 0.3222 - val_loss: 0.8893 - val_acc: 0.7044\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 65s 359ms/step - loss: 1.7656 - acc: 0.3409 - val_loss: 0.8429 - val_acc: 0.7160\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 1.8317 - acc: 0.3132 - val_loss: 0.8383 - val_acc: 0.7170\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.7990 - acc: 0.3256 - val_loss: 0.8368 - val_acc: 0.7168\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 64s 354ms/step - loss: 1.7705 - acc: 0.3380 - val_loss: 0.8149 - val_acc: 0.7210\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 67s 373ms/step - loss: 1.8025 - acc: 0.3256 - val_loss: 0.8189 - val_acc: 0.7176\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 71s 392ms/step - loss: 1.8256 - acc: 0.3178 - val_loss: 0.8388 - val_acc: 0.7194\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 69s 385ms/step - loss: 1.8007 - acc: 0.3263 - val_loss: 0.8438 - val_acc: 0.7110\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 67s 373ms/step - loss: 1.7766 - acc: 0.3359 - val_loss: 0.8510 - val_acc: 0.7100\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 75s 414ms/step - loss: 1.8533 - acc: 0.3070 - val_loss: 0.8276 - val_acc: 0.7236\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.7924 - acc: 0.3279 - val_loss: 0.8466 - val_acc: 0.7166\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.7911 - acc: 0.3313 - val_loss: 0.7963 - val_acc: 0.7248\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 1.8009 - acc: 0.3263 - val_loss: 0.8387 - val_acc: 0.7096\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.7719 - acc: 0.3367 - val_loss: 0.8323 - val_acc: 0.7142\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 65s 360ms/step - loss: 1.7794 - acc: 0.3352 - val_loss: 0.8177 - val_acc: 0.7204\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.7985 - acc: 0.3291 - val_loss: 0.8194 - val_acc: 0.7168\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.7597 - acc: 0.3399 - val_loss: 0.8007 - val_acc: 0.7234\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7354 - acc: 0.3553 - val_loss: 0.7938 - val_acc: 0.7256\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 69s 381ms/step - loss: 1.7960 - acc: 0.3310 - val_loss: 0.8080 - val_acc: 0.7254\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.7905 - acc: 0.3294 - val_loss: 0.8579 - val_acc: 0.7170\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.7654 - acc: 0.3404 - val_loss: 0.8075 - val_acc: 0.7320\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 65s 364ms/step - loss: 1.7797 - acc: 0.3342 - val_loss: 0.7948 - val_acc: 0.7268\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 70s 389ms/step - loss: 1.8208 - acc: 0.3207 - val_loss: 0.8440 - val_acc: 0.7174\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.7678 - acc: 0.3397 - val_loss: 0.7953 - val_acc: 0.7284\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.7581 - acc: 0.3436 - val_loss: 0.8328 - val_acc: 0.7184\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.7364 - acc: 0.3529 - val_loss: 0.8010 - val_acc: 0.7296\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 70s 388ms/step - loss: 1.7855 - acc: 0.3331 - val_loss: 0.7958 - val_acc: 0.7258\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 67s 375ms/step - loss: 1.7544 - acc: 0.3454 - val_loss: 0.7915 - val_acc: 0.7268\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 69s 386ms/step - loss: 1.7721 - acc: 0.3388 - val_loss: 0.8101 - val_acc: 0.7230\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 64s 354ms/step - loss: 1.7000 - acc: 0.3672 - val_loss: 0.7723 - val_acc: 0.7342\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 65s 360ms/step - loss: 1.7576 - acc: 0.3470 - val_loss: 0.7875 - val_acc: 0.7364\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 69s 381ms/step - loss: 1.8051 - acc: 0.3255 - val_loss: 0.7994 - val_acc: 0.7328\n",
            "Test accuracy: 0.732 (elaspsed time: 769s)\n",
            "Accuracy\n",
            "airplane 0.745\n",
            "auto 0.838\n",
            "bird 0.526\n",
            "cat 0.605\n",
            "deer 0.742\n",
            "dog 0.627\n",
            "frog 0.825\n",
            "horse 0.739\n",
            "ship 0.869\n",
            "truck 0.806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ebmWusQX5NdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "18c4d5a3-758e-4a79-d1ee-c8631972bd9a"
      },
      "cell_type": "code",
      "source": [
        "# Train some more!\n",
        "train_model(model, aug, 50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "180/180 [==============================] - 74s 412ms/step - loss: 1.8126 - acc: 0.3222 - val_loss: 0.7744 - val_acc: 0.7360\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 68s 377ms/step - loss: 1.7033 - acc: 0.3661 - val_loss: 0.7893 - val_acc: 0.7330\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 70s 388ms/step - loss: 1.7516 - acc: 0.3462 - val_loss: 0.7894 - val_acc: 0.7378\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 65s 364ms/step - loss: 1.7548 - acc: 0.3468 - val_loss: 0.8557 - val_acc: 0.7160\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.7666 - acc: 0.3411 - val_loss: 0.7885 - val_acc: 0.7324\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 67s 374ms/step - loss: 1.7744 - acc: 0.3386 - val_loss: 0.7702 - val_acc: 0.7434\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 67s 374ms/step - loss: 1.7702 - acc: 0.3412 - val_loss: 0.7891 - val_acc: 0.7376\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 67s 370ms/step - loss: 1.7564 - acc: 0.3465 - val_loss: 0.7884 - val_acc: 0.7324\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.7228 - acc: 0.3590 - val_loss: 0.7891 - val_acc: 0.7324\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.7368 - acc: 0.3531 - val_loss: 0.7642 - val_acc: 0.7428\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.7473 - acc: 0.3512 - val_loss: 0.8057 - val_acc: 0.7316\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.7613 - acc: 0.3445 - val_loss: 0.7802 - val_acc: 0.7384\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.7160 - acc: 0.3601 - val_loss: 0.8213 - val_acc: 0.7246\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 68s 375ms/step - loss: 1.7035 - acc: 0.3630 - val_loss: 0.8199 - val_acc: 0.7242\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 70s 388ms/step - loss: 1.7610 - acc: 0.3455 - val_loss: 0.7692 - val_acc: 0.7424\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.7275 - acc: 0.3551 - val_loss: 0.7596 - val_acc: 0.7474\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 67s 373ms/step - loss: 1.7412 - acc: 0.3533 - val_loss: 0.7541 - val_acc: 0.7452\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 68s 376ms/step - loss: 1.7545 - acc: 0.3484 - val_loss: 0.8213 - val_acc: 0.7224\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 67s 373ms/step - loss: 1.7507 - acc: 0.3492 - val_loss: 0.7743 - val_acc: 0.7430\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 64s 356ms/step - loss: 1.6990 - acc: 0.3682 - val_loss: 0.7780 - val_acc: 0.7402\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 69s 385ms/step - loss: 1.7690 - acc: 0.3391 - val_loss: 0.7541 - val_acc: 0.7438\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 67s 371ms/step - loss: 1.7372 - acc: 0.3543 - val_loss: 0.7953 - val_acc: 0.7358\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.7088 - acc: 0.3625 - val_loss: 0.7455 - val_acc: 0.7454\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 67s 375ms/step - loss: 1.7395 - acc: 0.3553 - val_loss: 0.7624 - val_acc: 0.7456\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 70s 389ms/step - loss: 1.7684 - acc: 0.3438 - val_loss: 0.8396 - val_acc: 0.7282\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 69s 383ms/step - loss: 1.7396 - acc: 0.3520 - val_loss: 0.7587 - val_acc: 0.7464\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7177 - acc: 0.3647 - val_loss: 0.7690 - val_acc: 0.7458\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 76s 423ms/step - loss: 1.7927 - acc: 0.3330 - val_loss: 0.7917 - val_acc: 0.7426\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7302 - acc: 0.3570 - val_loss: 0.7685 - val_acc: 0.7434\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 66s 366ms/step - loss: 1.7307 - acc: 0.3568 - val_loss: 0.7545 - val_acc: 0.7460\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 67s 374ms/step - loss: 1.7422 - acc: 0.3516 - val_loss: 0.7752 - val_acc: 0.7410\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 66s 365ms/step - loss: 1.7112 - acc: 0.3641 - val_loss: 0.7441 - val_acc: 0.7470\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 65s 362ms/step - loss: 1.7223 - acc: 0.3595 - val_loss: 0.7612 - val_acc: 0.7410\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 68s 379ms/step - loss: 1.7394 - acc: 0.3530 - val_loss: 0.7554 - val_acc: 0.7440\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7000 - acc: 0.3678 - val_loss: 0.7537 - val_acc: 0.7478\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 65s 359ms/step - loss: 1.6727 - acc: 0.3799 - val_loss: 0.7644 - val_acc: 0.7426\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7386 - acc: 0.3547 - val_loss: 0.7663 - val_acc: 0.7460\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 66s 367ms/step - loss: 1.7334 - acc: 0.3529 - val_loss: 0.8262 - val_acc: 0.7270\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.7043 - acc: 0.3697 - val_loss: 0.7834 - val_acc: 0.7372\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 66s 368ms/step - loss: 1.7182 - acc: 0.3613 - val_loss: 0.7704 - val_acc: 0.7432\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 71s 395ms/step - loss: 1.7687 - acc: 0.3426 - val_loss: 0.7885 - val_acc: 0.7428\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.7078 - acc: 0.3650 - val_loss: 0.7629 - val_acc: 0.7444\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.7008 - acc: 0.3704 - val_loss: 0.7753 - val_acc: 0.7388\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 64s 357ms/step - loss: 1.6744 - acc: 0.3810 - val_loss: 0.7426 - val_acc: 0.7484\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 67s 372ms/step - loss: 1.7309 - acc: 0.3581 - val_loss: 0.7757 - val_acc: 0.7410\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 65s 363ms/step - loss: 1.7001 - acc: 0.3683 - val_loss: 0.7639 - val_acc: 0.7440\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 66s 369ms/step - loss: 1.7162 - acc: 0.3638 - val_loss: 0.7658 - val_acc: 0.7414\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 64s 353ms/step - loss: 1.6337 - acc: 0.3973 - val_loss: 0.7518 - val_acc: 0.7468\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 65s 364ms/step - loss: 1.7005 - acc: 0.3709 - val_loss: 0.7650 - val_acc: 0.7494\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 69s 382ms/step - loss: 1.7480 - acc: 0.3525 - val_loss: 0.7670 - val_acc: 0.7512\n",
            "Test accuracy: 0.750 (elaspsed time: 771s)\n",
            "Accuracy\n",
            "airplane 0.753\n",
            "auto 0.821\n",
            "bird 0.55\n",
            "cat 0.649\n",
            "deer 0.744\n",
            "dog 0.585\n",
            "frog 0.867\n",
            "horse 0.799\n",
            "ship 0.877\n",
            "truck 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sxFSb2RcGFZj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Common Baseline**\n",
        "Above results are like comparing Red Deliscious Apples to Granny Smith Apples\n",
        "Try a common baseline here"
      ]
    },
    {
      "metadata": {
        "id": "Wn280GVcGE1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "295416f2-d6c5-4a8e-d757-06abf5262189"
      },
      "cell_type": "code",
      "source": [
        "#No=op policy\n",
        "ops = [Operation(([Identity] * 10, 0), 0)]\n",
        "transform1 = Transform(*ops)\n",
        "\n",
        "transforms = [transform1]\n",
        "aug = autoaugment(transforms, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "base = create_model(X_reduced, 10)\n",
        "\n",
        "train_model(X_reduced, base, aug, 10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 2.9350 - acc: 0.1115 - val_loss: 2.1769 - val_acc: 0.1888\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 2.6319 - acc: 0.1560 - val_loss: 2.0965 - val_acc: 0.2206\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 2.4512 - acc: 0.1790 - val_loss: 2.1650 - val_acc: 0.2178\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 2.3121 - acc: 0.2165 - val_loss: 2.2085 - val_acc: 0.2264\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 2.2372 - acc: 0.2342 - val_loss: 2.2289 - val_acc: 0.2324\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 2.2136 - acc: 0.2455 - val_loss: 2.1214 - val_acc: 0.2612\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 2.1438 - acc: 0.2575 - val_loss: 1.9786 - val_acc: 0.3082\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 2.0777 - acc: 0.2785 - val_loss: 2.0395 - val_acc: 0.2834\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 2.0248 - acc: 0.2913 - val_loss: 2.0185 - val_acc: 0.2962\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.9752 - acc: 0.3118 - val_loss: 1.9926 - val_acc: 0.3066\n",
            "Test accuracy: 0.295 (elaspsed time: 18s)\n",
            "Accuracy\n",
            "airplane 0.262\n",
            "auto 0.349\n",
            "bird 0.044\n",
            "cat 0.056\n",
            "deer 0.725\n",
            "dog 0.103\n",
            "frog 0.476\n",
            "horse 0.302\n",
            "ship 0.397\n",
            "truck 0.239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRCVVqLTReAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finish training the baseline..."
      ]
    },
    {
      "metadata": {
        "id": "ort8hTtwRg_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1581
        },
        "outputId": "15bc9fb4-ef9f-43b9-ab8c-41962142eb1b"
      },
      "cell_type": "code",
      "source": [
        "base_final = create_model(X_reduced, 10)\n",
        "base_final.set_weights(base.get_weights())\n",
        "\n",
        "train_model(X_reduced, base_final, aug, 40)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 1.9321 - acc: 0.3185 - val_loss: 1.8264 - val_acc: 0.3584\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.8903 - acc: 0.3427 - val_loss: 1.7754 - val_acc: 0.3736\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.8385 - acc: 0.3405 - val_loss: 1.7752 - val_acc: 0.3772\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.8105 - acc: 0.3668 - val_loss: 1.7363 - val_acc: 0.3924\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.7723 - acc: 0.3752 - val_loss: 1.7718 - val_acc: 0.3756\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.7194 - acc: 0.3853 - val_loss: 1.7464 - val_acc: 0.3788\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.6949 - acc: 0.3913 - val_loss: 1.6721 - val_acc: 0.4114\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.6297 - acc: 0.4190 - val_loss: 1.8040 - val_acc: 0.3730\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.6200 - acc: 0.4253 - val_loss: 1.7288 - val_acc: 0.3930\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.6058 - acc: 0.4247 - val_loss: 1.7128 - val_acc: 0.4016\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.5584 - acc: 0.4398 - val_loss: 1.6827 - val_acc: 0.4138\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 1.5376 - acc: 0.4582 - val_loss: 1.6979 - val_acc: 0.4074\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.4981 - acc: 0.4692 - val_loss: 1.6955 - val_acc: 0.3974\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.4731 - acc: 0.4680 - val_loss: 1.6498 - val_acc: 0.4188\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.4641 - acc: 0.4765 - val_loss: 1.7155 - val_acc: 0.4082\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.4314 - acc: 0.4835 - val_loss: 1.6638 - val_acc: 0.4096\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.3961 - acc: 0.4900 - val_loss: 1.6424 - val_acc: 0.4206\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.3757 - acc: 0.5035 - val_loss: 1.6643 - val_acc: 0.4080\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.3670 - acc: 0.5083 - val_loss: 1.6331 - val_acc: 0.4232\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.3258 - acc: 0.5227 - val_loss: 1.6145 - val_acc: 0.4274\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.3095 - acc: 0.5287 - val_loss: 1.6682 - val_acc: 0.4168\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.3166 - acc: 0.5257 - val_loss: 1.7347 - val_acc: 0.3996\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.2652 - acc: 0.5468 - val_loss: 1.6207 - val_acc: 0.4386\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.2494 - acc: 0.5505 - val_loss: 1.6828 - val_acc: 0.4162\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.2406 - acc: 0.5498 - val_loss: 1.6370 - val_acc: 0.4364\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.2269 - acc: 0.5665 - val_loss: 1.6610 - val_acc: 0.4202\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 1.1800 - acc: 0.5817 - val_loss: 1.7169 - val_acc: 0.4058\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 1.1880 - acc: 0.5703 - val_loss: 1.6192 - val_acc: 0.4352\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.1578 - acc: 0.5945 - val_loss: 1.5674 - val_acc: 0.4494\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.1309 - acc: 0.6090 - val_loss: 1.5607 - val_acc: 0.4502\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.1221 - acc: 0.6052 - val_loss: 1.5420 - val_acc: 0.4528\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.0873 - acc: 0.6145 - val_loss: 1.5629 - val_acc: 0.4494\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.0732 - acc: 0.6195 - val_loss: 1.5616 - val_acc: 0.4574\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.0690 - acc: 0.6240 - val_loss: 1.5283 - val_acc: 0.4660\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 1.0445 - acc: 0.6272 - val_loss: 1.5317 - val_acc: 0.4684\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 1.0259 - acc: 0.6385 - val_loss: 1.5026 - val_acc: 0.4712\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.0087 - acc: 0.6405 - val_loss: 1.4878 - val_acc: 0.4724\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.9887 - acc: 0.6503 - val_loss: 1.4940 - val_acc: 0.4756\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.9757 - acc: 0.6545 - val_loss: 1.5139 - val_acc: 0.4696\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.9567 - acc: 0.6667 - val_loss: 1.5174 - val_acc: 0.4674\n",
            "Test accuracy: 0.476 (elaspsed time: 61s)\n",
            "Accuracy\n",
            "airplane 0.497\n",
            "auto 0.528\n",
            "bird 0.308\n",
            "cat 0.397\n",
            "deer 0.556\n",
            "dog 0.314\n",
            "frog 0.606\n",
            "horse 0.53\n",
            "ship 0.613\n",
            "truck 0.415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fWsMUOoXnDdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "5218a0e4-c0c4-4744-d93f-583381c11f05"
      },
      "cell_type": "code",
      "source": [
        "train_model(X_reduced, base_final, aug, 50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.9611 - acc: 0.6648 - val_loss: 1.5428 - val_acc: 0.4622\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.9377 - acc: 0.6707 - val_loss: 1.5092 - val_acc: 0.4736\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.9212 - acc: 0.6835 - val_loss: 1.5333 - val_acc: 0.4734\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.8976 - acc: 0.6885 - val_loss: 1.5204 - val_acc: 0.4714\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8918 - acc: 0.6962 - val_loss: 1.4804 - val_acc: 0.4804\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8673 - acc: 0.6942 - val_loss: 1.5596 - val_acc: 0.4594\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8730 - acc: 0.6947 - val_loss: 1.4626 - val_acc: 0.4878\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8363 - acc: 0.7160 - val_loss: 1.5053 - val_acc: 0.4726\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.8296 - acc: 0.7237 - val_loss: 1.4566 - val_acc: 0.4890\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.8121 - acc: 0.7235 - val_loss: 1.4969 - val_acc: 0.4838\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.8104 - acc: 0.7212 - val_loss: 1.5102 - val_acc: 0.4816\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.8004 - acc: 0.7230 - val_loss: 1.5256 - val_acc: 0.4722\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.7876 - acc: 0.7337 - val_loss: 1.4519 - val_acc: 0.4944\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.7609 - acc: 0.7423 - val_loss: 1.5021 - val_acc: 0.4736\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.7593 - acc: 0.7417 - val_loss: 1.4750 - val_acc: 0.4950\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.7383 - acc: 0.7547 - val_loss: 1.4535 - val_acc: 0.4900\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.7234 - acc: 0.7575 - val_loss: 1.5153 - val_acc: 0.4878\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.7194 - acc: 0.7613 - val_loss: 1.5073 - val_acc: 0.4868\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.7051 - acc: 0.7710 - val_loss: 1.4736 - val_acc: 0.4922\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.6920 - acc: 0.7752 - val_loss: 1.4810 - val_acc: 0.4902\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6955 - acc: 0.7675 - val_loss: 1.4434 - val_acc: 0.5074\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.6666 - acc: 0.7835 - val_loss: 1.4701 - val_acc: 0.4920\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6550 - acc: 0.7868 - val_loss: 1.4573 - val_acc: 0.4934\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6381 - acc: 0.7932 - val_loss: 1.4371 - val_acc: 0.5088\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6544 - acc: 0.7778 - val_loss: 1.4714 - val_acc: 0.5050\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.6049 - acc: 0.8080 - val_loss: 1.4334 - val_acc: 0.5114\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.6214 - acc: 0.7992 - val_loss: 1.4766 - val_acc: 0.4962\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.5966 - acc: 0.8068 - val_loss: 1.4543 - val_acc: 0.5082\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.5926 - acc: 0.8170 - val_loss: 1.4513 - val_acc: 0.5006\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.5890 - acc: 0.8060 - val_loss: 1.4705 - val_acc: 0.5096\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.5545 - acc: 0.8342 - val_loss: 1.4705 - val_acc: 0.5082\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.5513 - acc: 0.8315 - val_loss: 1.4588 - val_acc: 0.5078\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.5467 - acc: 0.8270 - val_loss: 1.4698 - val_acc: 0.5066\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.5419 - acc: 0.8215 - val_loss: 1.5006 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.5254 - acc: 0.8372 - val_loss: 1.4492 - val_acc: 0.5108\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.5211 - acc: 0.8373 - val_loss: 1.4504 - val_acc: 0.5122\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.5197 - acc: 0.8365 - val_loss: 1.4714 - val_acc: 0.5154\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4978 - acc: 0.8477 - val_loss: 1.4696 - val_acc: 0.5164\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.5014 - acc: 0.8447 - val_loss: 1.4801 - val_acc: 0.5118\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.4770 - acc: 0.8573 - val_loss: 1.4746 - val_acc: 0.5052\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.4900 - acc: 0.8412 - val_loss: 1.4602 - val_acc: 0.5130\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4702 - acc: 0.8560 - val_loss: 1.4860 - val_acc: 0.5098\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.4516 - acc: 0.8667 - val_loss: 1.4570 - val_acc: 0.5116\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.4435 - acc: 0.8655 - val_loss: 1.4654 - val_acc: 0.5208\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4426 - acc: 0.8675 - val_loss: 1.4975 - val_acc: 0.5100\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.4297 - acc: 0.8767 - val_loss: 1.4798 - val_acc: 0.5116\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.4307 - acc: 0.8718 - val_loss: 1.4566 - val_acc: 0.5268\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4363 - acc: 0.8652 - val_loss: 1.4770 - val_acc: 0.5232\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.4137 - acc: 0.8755 - val_loss: 1.4525 - val_acc: 0.5260\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.4018 - acc: 0.8807 - val_loss: 1.4517 - val_acc: 0.5196\n",
            "Test accuracy: 0.525 (elaspsed time: 74s)\n",
            "Accuracy\n",
            "airplane 0.544\n",
            "auto 0.647\n",
            "bird 0.37\n",
            "cat 0.366\n",
            "deer 0.49\n",
            "dog 0.37\n",
            "frog 0.647\n",
            "horse 0.569\n",
            "ship 0.744\n",
            "truck 0.501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9QAMvD0q5Bs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "75cc61e4-967d-4410-d7b6-20a9705e7dce"
      },
      "cell_type": "code",
      "source": [
        "train_model(X_reduced, base_final, aug, 50)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.3953 - acc: 0.8845 - val_loss: 1.4801 - val_acc: 0.5188\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.3862 - acc: 0.8840 - val_loss: 1.4740 - val_acc: 0.5224\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3836 - acc: 0.8892 - val_loss: 1.5035 - val_acc: 0.5108\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.3878 - acc: 0.8848 - val_loss: 1.4855 - val_acc: 0.5184\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3750 - acc: 0.8900 - val_loss: 1.4867 - val_acc: 0.5184\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.3532 - acc: 0.9045 - val_loss: 1.4812 - val_acc: 0.5276\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3517 - acc: 0.8995 - val_loss: 1.4698 - val_acc: 0.5214\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3435 - acc: 0.9028 - val_loss: 1.5069 - val_acc: 0.5148\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.3505 - acc: 0.8995 - val_loss: 1.4906 - val_acc: 0.5246\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3392 - acc: 0.9048 - val_loss: 1.5028 - val_acc: 0.5156\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3388 - acc: 0.9105 - val_loss: 1.5268 - val_acc: 0.5128\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.3147 - acc: 0.9185 - val_loss: 1.5364 - val_acc: 0.5136\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.3260 - acc: 0.9085 - val_loss: 1.4958 - val_acc: 0.5206\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.3145 - acc: 0.9195 - val_loss: 1.5017 - val_acc: 0.5282\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.3082 - acc: 0.9163 - val_loss: 1.5060 - val_acc: 0.5270\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.2964 - acc: 0.9200 - val_loss: 1.4807 - val_acc: 0.5266\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2999 - acc: 0.9163 - val_loss: 1.4983 - val_acc: 0.5256\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2921 - acc: 0.9185 - val_loss: 1.5079 - val_acc: 0.5228\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2873 - acc: 0.9227 - val_loss: 1.5084 - val_acc: 0.5206\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2847 - acc: 0.9242 - val_loss: 1.4974 - val_acc: 0.5310\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2693 - acc: 0.9333 - val_loss: 1.5370 - val_acc: 0.5268\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.2687 - acc: 0.9328 - val_loss: 1.5204 - val_acc: 0.5184\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2694 - acc: 0.9275 - val_loss: 1.5153 - val_acc: 0.5284\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2672 - acc: 0.9285 - val_loss: 1.5422 - val_acc: 0.5302\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.2637 - acc: 0.9335 - val_loss: 1.5353 - val_acc: 0.5286\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2548 - acc: 0.9305 - val_loss: 1.5028 - val_acc: 0.5256\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2428 - acc: 0.9392 - val_loss: 1.5027 - val_acc: 0.5308\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2500 - acc: 0.9365 - val_loss: 1.5240 - val_acc: 0.5266\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2450 - acc: 0.9362 - val_loss: 1.5070 - val_acc: 0.5312\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.2423 - acc: 0.9398 - val_loss: 1.5574 - val_acc: 0.5206\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2429 - acc: 0.9383 - val_loss: 1.5050 - val_acc: 0.5318\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2283 - acc: 0.9430 - val_loss: 1.5227 - val_acc: 0.5392\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2110 - acc: 0.9527 - val_loss: 1.5453 - val_acc: 0.5344\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2243 - acc: 0.9410 - val_loss: 1.5379 - val_acc: 0.5342\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2160 - acc: 0.9433 - val_loss: 1.5970 - val_acc: 0.5136\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2211 - acc: 0.9432 - val_loss: 1.5693 - val_acc: 0.5186\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2109 - acc: 0.9477 - val_loss: 1.5152 - val_acc: 0.5308\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.2052 - acc: 0.9508 - val_loss: 1.5406 - val_acc: 0.5320\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.2069 - acc: 0.9493 - val_loss: 1.5496 - val_acc: 0.5356\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2066 - acc: 0.9488 - val_loss: 1.5393 - val_acc: 0.5400\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1930 - acc: 0.9560 - val_loss: 1.5164 - val_acc: 0.5326\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1989 - acc: 0.9485 - val_loss: 1.5467 - val_acc: 0.5354\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1991 - acc: 0.9475 - val_loss: 1.5564 - val_acc: 0.5332\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1901 - acc: 0.9505 - val_loss: 1.5481 - val_acc: 0.5354\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1782 - acc: 0.9602 - val_loss: 1.5760 - val_acc: 0.5300\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1791 - acc: 0.9595 - val_loss: 1.5332 - val_acc: 0.5346\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1821 - acc: 0.9565 - val_loss: 1.5393 - val_acc: 0.5372\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1762 - acc: 0.9602 - val_loss: 1.5840 - val_acc: 0.5318\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1792 - acc: 0.9540 - val_loss: 1.5301 - val_acc: 0.5370\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1770 - acc: 0.9560 - val_loss: 1.6062 - val_acc: 0.5300\n",
            "Test accuracy: 0.522 (elaspsed time: 74s)\n",
            "Accuracy\n",
            "airplane 0.485\n",
            "auto 0.564\n",
            "bird 0.34\n",
            "cat 0.431\n",
            "deer 0.468\n",
            "dog 0.518\n",
            "frog 0.618\n",
            "horse 0.588\n",
            "ship 0.626\n",
            "truck 0.585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXNvw7k6Gd6A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now try train further with autoaugment...\n",
        "\n",
        "Note: train data is size 45,000 and minibatch size is 250 so that each epoch is exposed to 180 different sub-policies\n",
        "With 95 nearly unique sub-policies, each epoch is exposed to most or all sub-policies."
      ]
    },
    {
      "metadata": {
        "id": "pUBuzf9WGit2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3621
        },
        "outputId": "aae3dc28-c299-4743-cba5-bca5b2c5d1c5"
      },
      "cell_type": "code",
      "source": [
        "CIFAR10_Policy = [\n",
        "    #0_0\n",
        "    mk_op2(Invert, 0.1, 7, Contrast, 0.2, 6),\n",
        "    mk_op2(Rotate, 0.7, 2, TranslateX, 0.3, 9),\n",
        "    mk_op2(Sharpness, 0.8, 1, Sharpness, 0.9, 3),\n",
        "    mk_op2(ShearY, 0.5, 8, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.5, 8, Equalize, 0.9, 2),\n",
        "    \n",
        "    #1_0\n",
        "    mk_op2(ShearY, 0.2, 7, Posterize, 0.3, 7),\n",
        "    mk_op2(Color, 0.4, 3, Brightness, 0.6, 7),\n",
        "    mk_op2(Sharpness, 0.3, 9, Brightness, 0.7, 9),\n",
        "    mk_op2(Equalize, 0.6, 5, Equalize, 0.5, 1),\n",
        "    mk_op2(Contrast, 0.6, 7, Sharpness, 0.6, 5),\n",
        "    \n",
        "    #2_0\n",
        "    mk_op2(Color, 0.7, 7, TranslateX, 0.5, 8),\n",
        "    mk_op2(Equalize, 0.3, 7, AutoContrast, 0.4, 8),\n",
        "    mk_op2(TranslateY, 0.4, 3, Sharpness, 0.2, 6),\n",
        "    mk_op2(Brightness, 0.9, 6, Color, 0.2, 8),\n",
        "    mk_op2(Solarize, 0.5, 2, Invert, 0.0, 3),\n",
        "    \n",
        "    #3_0\n",
        "    mk_op2(Equalize,0.2,0, AutoContrast,0.6,0),\n",
        "    mk_op2(Equalize,0.2,8, Equalize,0.6,4),\n",
        "    mk_op2(Color,0.9,9, Equalize,0.6,6),\n",
        "    mk_op2(AutoContrast,0.8,4, Solarize,0.2,8),\n",
        "    mk_op2(Brightness,0.1,3, Color,0.7,0),\n",
        "    \n",
        "    #4_0\n",
        "    mk_op2(Solarize,0.4,5, AutoContrast,0.9,3),\n",
        "    mk_op2(TranslateY,0.9,9, TranslateY,0.7,9),\n",
        "    mk_op2(AutoContrast,0.9,2, Solarize,0.8,3),\n",
        "    mk_op2(Equalize,0.8,8, Invert,0.1,3),\n",
        "    mk_op2(TranslateY,0.7,9, AutoContrast,0.9,1)\n",
        "]\n",
        "\n",
        "\n",
        "aug_autoaug = autoaugment(CIFAR10_Policy, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "# create new model and copy base weights over\n",
        "model_autoaug = create_model(X_reduced, 10)\n",
        "model_autoaug.set_weights(base.get_weights())\n",
        "\n",
        "train_model(X_reduced, model_autoaug, aug_autoaug, 100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 573ms/step - loss: 2.4502 - acc: 0.1425 - val_loss: 2.0993 - val_acc: 0.3296\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 2.3739 - acc: 0.1375 - val_loss: 2.1054 - val_acc: 0.3536\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 2.3654 - acc: 0.1405 - val_loss: 2.1375 - val_acc: 0.3320\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 2.3624 - acc: 0.1368 - val_loss: 2.0098 - val_acc: 0.3408\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 2.3437 - acc: 0.1465 - val_loss: 2.0485 - val_acc: 0.3296\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 2.3166 - acc: 0.1520 - val_loss: 1.9614 - val_acc: 0.3428\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 2.3267 - acc: 0.1455 - val_loss: 1.8910 - val_acc: 0.3510\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 2.2900 - acc: 0.1418 - val_loss: 1.8739 - val_acc: 0.3598\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 2.2888 - acc: 0.1415 - val_loss: 1.8602 - val_acc: 0.3560\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 2.2736 - acc: 0.1525 - val_loss: 1.8724 - val_acc: 0.3520\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 2.2950 - acc: 0.1470 - val_loss: 1.9484 - val_acc: 0.3260\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 2.3167 - acc: 0.1265 - val_loss: 1.8169 - val_acc: 0.3640\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 2.2834 - acc: 0.1450 - val_loss: 1.8440 - val_acc: 0.3510\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 2.2735 - acc: 0.1470 - val_loss: 1.8545 - val_acc: 0.3496\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 2.2941 - acc: 0.1433 - val_loss: 1.8702 - val_acc: 0.3406\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 2.2441 - acc: 0.1565 - val_loss: 1.8520 - val_acc: 0.3436\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 2.2221 - acc: 0.1647 - val_loss: 1.9102 - val_acc: 0.3172\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 2.2673 - acc: 0.1450 - val_loss: 1.8284 - val_acc: 0.3564\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 2.2342 - acc: 0.1630 - val_loss: 1.8170 - val_acc: 0.3552\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 2.2294 - acc: 0.1628 - val_loss: 1.8066 - val_acc: 0.3688\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 2.2328 - acc: 0.1608 - val_loss: 1.8217 - val_acc: 0.3608\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 2.1847 - acc: 0.1807 - val_loss: 1.8288 - val_acc: 0.3478\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 2.2509 - acc: 0.1555 - val_loss: 1.7887 - val_acc: 0.3654\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 2.2254 - acc: 0.1670 - val_loss: 1.7992 - val_acc: 0.3612\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 2.2390 - acc: 0.1572 - val_loss: 1.7880 - val_acc: 0.3714\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 7s 441ms/step - loss: 2.2437 - acc: 0.1492 - val_loss: 1.7852 - val_acc: 0.3768\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 2.2258 - acc: 0.1538 - val_loss: 1.8191 - val_acc: 0.3554\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 2.2341 - acc: 0.1610 - val_loss: 1.8136 - val_acc: 0.3572\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 2.2419 - acc: 0.1600 - val_loss: 1.7876 - val_acc: 0.3612\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 7s 441ms/step - loss: 2.2398 - acc: 0.1560 - val_loss: 1.8200 - val_acc: 0.3522\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 2.2628 - acc: 0.1488 - val_loss: 1.7776 - val_acc: 0.3704\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 2.1998 - acc: 0.1723 - val_loss: 1.7957 - val_acc: 0.3734\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 2.2310 - acc: 0.1643 - val_loss: 1.7922 - val_acc: 0.3686\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 2.2520 - acc: 0.1615 - val_loss: 1.8365 - val_acc: 0.3460\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 2.2223 - acc: 0.1640 - val_loss: 1.7776 - val_acc: 0.3630\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 2.1742 - acc: 0.1858 - val_loss: 1.7762 - val_acc: 0.3712\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 2.2256 - acc: 0.1590 - val_loss: 1.7659 - val_acc: 0.3834\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 2.2224 - acc: 0.1620 - val_loss: 1.7631 - val_acc: 0.3760\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 7s 456ms/step - loss: 2.2422 - acc: 0.1467 - val_loss: 1.7882 - val_acc: 0.3768\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.2071 - acc: 0.1675 - val_loss: 1.8406 - val_acc: 0.3446\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 2.1541 - acc: 0.1820 - val_loss: 1.7589 - val_acc: 0.3756\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 2.1665 - acc: 0.1875 - val_loss: 1.7564 - val_acc: 0.3740\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 2.2577 - acc: 0.1455 - val_loss: 1.7348 - val_acc: 0.3890\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 2.2213 - acc: 0.1607 - val_loss: 1.7430 - val_acc: 0.3826\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 2.1814 - acc: 0.1785 - val_loss: 1.7391 - val_acc: 0.3852\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 2.2352 - acc: 0.1570 - val_loss: 1.7497 - val_acc: 0.3766\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 2.1867 - acc: 0.1713 - val_loss: 1.7520 - val_acc: 0.3750\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 2.2080 - acc: 0.1698 - val_loss: 1.7824 - val_acc: 0.3652\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 2.1993 - acc: 0.1675 - val_loss: 1.7396 - val_acc: 0.3802\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 2.1866 - acc: 0.1758 - val_loss: 1.7231 - val_acc: 0.3828\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 2.1664 - acc: 0.1898 - val_loss: 1.7142 - val_acc: 0.3892\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 2.1756 - acc: 0.1900 - val_loss: 1.7040 - val_acc: 0.3908\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 2.1255 - acc: 0.2030 - val_loss: 1.7140 - val_acc: 0.3868\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 2.1982 - acc: 0.1678 - val_loss: 1.7692 - val_acc: 0.3738\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 2.1763 - acc: 0.1860 - val_loss: 1.7367 - val_acc: 0.3776\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 2.1570 - acc: 0.1908 - val_loss: 1.7004 - val_acc: 0.3932\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 2.2002 - acc: 0.1822 - val_loss: 1.7226 - val_acc: 0.3786\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 2.1436 - acc: 0.1890 - val_loss: 1.7260 - val_acc: 0.3864\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 2.1919 - acc: 0.1803 - val_loss: 1.7136 - val_acc: 0.3902\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 2.1730 - acc: 0.1855 - val_loss: 1.6958 - val_acc: 0.4032\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.1432 - acc: 0.2038 - val_loss: 1.6885 - val_acc: 0.3942\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 2.1162 - acc: 0.2110 - val_loss: 1.6910 - val_acc: 0.4060\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 7s 461ms/step - loss: 2.1848 - acc: 0.1778 - val_loss: 1.7084 - val_acc: 0.4014\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 2.1439 - acc: 0.1970 - val_loss: 1.7058 - val_acc: 0.3966\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 2.1438 - acc: 0.1958 - val_loss: 1.6729 - val_acc: 0.4026\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 2.1402 - acc: 0.2012 - val_loss: 1.6919 - val_acc: 0.3918\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 2.1074 - acc: 0.2085 - val_loss: 1.6567 - val_acc: 0.4020\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 8s 469ms/step - loss: 2.1825 - acc: 0.1775 - val_loss: 1.6949 - val_acc: 0.4010\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.1695 - acc: 0.1985 - val_loss: 1.6746 - val_acc: 0.4028\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.1262 - acc: 0.2043 - val_loss: 1.6834 - val_acc: 0.3998\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 2.1729 - acc: 0.1940 - val_loss: 1.6708 - val_acc: 0.4012\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 2.1071 - acc: 0.2093 - val_loss: 1.6522 - val_acc: 0.4120\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.1069 - acc: 0.2173 - val_loss: 1.6569 - val_acc: 0.4068\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 2.1663 - acc: 0.1902 - val_loss: 1.6738 - val_acc: 0.4106\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.1556 - acc: 0.2068 - val_loss: 1.6969 - val_acc: 0.4006\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 2.1321 - acc: 0.2048 - val_loss: 1.6780 - val_acc: 0.4008\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 2.1980 - acc: 0.1810 - val_loss: 1.6825 - val_acc: 0.4006\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 7s 450ms/step - loss: 2.1809 - acc: 0.1825 - val_loss: 1.6694 - val_acc: 0.4108\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 6s 404ms/step - loss: 2.1517 - acc: 0.1900 - val_loss: 1.6830 - val_acc: 0.4080\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 8s 473ms/step - loss: 2.1937 - acc: 0.1865 - val_loss: 1.6978 - val_acc: 0.4080\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 2.1595 - acc: 0.2030 - val_loss: 1.6666 - val_acc: 0.4100\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 2.1463 - acc: 0.2090 - val_loss: 1.6669 - val_acc: 0.4028\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 2.1067 - acc: 0.2145 - val_loss: 1.6546 - val_acc: 0.4076\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 2.0792 - acc: 0.2290 - val_loss: 1.6387 - val_acc: 0.4144\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 2.0800 - acc: 0.2222 - val_loss: 1.6380 - val_acc: 0.4044\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 2.1075 - acc: 0.2135 - val_loss: 1.6336 - val_acc: 0.4190\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 2.1487 - acc: 0.2143 - val_loss: 1.6954 - val_acc: 0.4056\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 2.1064 - acc: 0.2175 - val_loss: 1.6457 - val_acc: 0.4246\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 2.1295 - acc: 0.2160 - val_loss: 1.6365 - val_acc: 0.4190\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.1122 - acc: 0.2160 - val_loss: 1.6185 - val_acc: 0.4220\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 2.1134 - acc: 0.2185 - val_loss: 1.6445 - val_acc: 0.4034\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 6s 404ms/step - loss: 2.1064 - acc: 0.2140 - val_loss: 1.6318 - val_acc: 0.4100\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 2.1349 - acc: 0.2088 - val_loss: 1.6435 - val_acc: 0.4182\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 7s 463ms/step - loss: 2.1344 - acc: 0.2170 - val_loss: 1.6450 - val_acc: 0.4218\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 2.0827 - acc: 0.2390 - val_loss: 1.6263 - val_acc: 0.4216\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 2.0656 - acc: 0.2390 - val_loss: 1.6491 - val_acc: 0.4130\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 2.0920 - acc: 0.2295 - val_loss: 1.6244 - val_acc: 0.4176\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.1195 - acc: 0.2255 - val_loss: 1.6250 - val_acc: 0.4188\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 2.0806 - acc: 0.2245 - val_loss: 1.6553 - val_acc: 0.4028\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 2.0784 - acc: 0.2368 - val_loss: 1.6310 - val_acc: 0.4168\n",
            "Test accuracy: 0.411 (elaspsed time: 168s)\n",
            "Accuracy\n",
            "airplane 0.492\n",
            "auto 0.502\n",
            "bird 0.309\n",
            "cat 0.23\n",
            "deer 0.303\n",
            "dog 0.471\n",
            "frog 0.53\n",
            "horse 0.434\n",
            "ship 0.433\n",
            "truck 0.409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eb7OUC0XehQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5321
        },
        "outputId": "ce1bbdc4-6afa-466d-a0da-3c8f5a0e58fc"
      },
      "cell_type": "code",
      "source": [
        "# train more...\n",
        "train_model(X_reduced, model_autoaug, aug_autoaug, 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 2.0764 - acc: 0.2405 - val_loss: 1.6512 - val_acc: 0.4208\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 2.1110 - acc: 0.2190 - val_loss: 1.6287 - val_acc: 0.4292\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.1144 - acc: 0.2272 - val_loss: 1.6380 - val_acc: 0.4114\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 7s 412ms/step - loss: 2.0581 - acc: 0.2455 - val_loss: 1.6035 - val_acc: 0.4282\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 2.0638 - acc: 0.2470 - val_loss: 1.6104 - val_acc: 0.4278\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 2.0513 - acc: 0.2515 - val_loss: 1.6403 - val_acc: 0.4094\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.0540 - acc: 0.2475 - val_loss: 1.6124 - val_acc: 0.4256\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 2.0903 - acc: 0.2270 - val_loss: 1.6059 - val_acc: 0.4244\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.0441 - acc: 0.2547 - val_loss: 1.6053 - val_acc: 0.4274\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 2.0544 - acc: 0.2495 - val_loss: 1.5980 - val_acc: 0.4232\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 2.0370 - acc: 0.2635 - val_loss: 1.6168 - val_acc: 0.4122\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 2.1115 - acc: 0.2387 - val_loss: 1.6084 - val_acc: 0.4198\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 2.0944 - acc: 0.2352 - val_loss: 1.6069 - val_acc: 0.4228\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 2.0784 - acc: 0.2338 - val_loss: 1.5924 - val_acc: 0.4322\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 2.1019 - acc: 0.2423 - val_loss: 1.6252 - val_acc: 0.4238\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 2.0219 - acc: 0.2565 - val_loss: 1.5885 - val_acc: 0.4320\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 6s 404ms/step - loss: 2.0147 - acc: 0.2715 - val_loss: 1.5889 - val_acc: 0.4288\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 2.0529 - acc: 0.2680 - val_loss: 1.6386 - val_acc: 0.4292\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.9882 - acc: 0.2663 - val_loss: 1.5949 - val_acc: 0.4246\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 2.0094 - acc: 0.2675 - val_loss: 1.5874 - val_acc: 0.4392\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 2.0265 - acc: 0.2615 - val_loss: 1.5915 - val_acc: 0.4358\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.9175 - acc: 0.3063 - val_loss: 1.6032 - val_acc: 0.4236\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 2.0369 - acc: 0.2678 - val_loss: 1.6026 - val_acc: 0.4330\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.9824 - acc: 0.2903 - val_loss: 1.5988 - val_acc: 0.4312\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 1.9959 - acc: 0.2825 - val_loss: 1.5759 - val_acc: 0.4450\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 2.0671 - acc: 0.2530 - val_loss: 1.5738 - val_acc: 0.4392\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 2.0049 - acc: 0.2797 - val_loss: 1.5970 - val_acc: 0.4372\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 2.0405 - acc: 0.2630 - val_loss: 1.6073 - val_acc: 0.4222\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 2.0087 - acc: 0.2838 - val_loss: 1.5759 - val_acc: 0.4420\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 2.0183 - acc: 0.2723 - val_loss: 1.5607 - val_acc: 0.4520\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 2.0273 - acc: 0.2650 - val_loss: 1.6052 - val_acc: 0.4330\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.9833 - acc: 0.2780 - val_loss: 1.5701 - val_acc: 0.4426\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 2.0006 - acc: 0.2680 - val_loss: 1.5651 - val_acc: 0.4460\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 2.0465 - acc: 0.2555 - val_loss: 1.6546 - val_acc: 0.4230\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.9894 - acc: 0.2893 - val_loss: 1.5865 - val_acc: 0.4450\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 1.9515 - acc: 0.2967 - val_loss: 1.5748 - val_acc: 0.4428\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 2.0038 - acc: 0.2758 - val_loss: 1.5617 - val_acc: 0.4394\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 1.9886 - acc: 0.2855 - val_loss: 1.5731 - val_acc: 0.4438\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.0316 - acc: 0.2648 - val_loss: 1.5943 - val_acc: 0.4320\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 2.0205 - acc: 0.2668 - val_loss: 1.5875 - val_acc: 0.4362\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 1.9313 - acc: 0.3000 - val_loss: 1.5548 - val_acc: 0.4478\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.9100 - acc: 0.3160 - val_loss: 1.5746 - val_acc: 0.4438\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 7s 464ms/step - loss: 2.0662 - acc: 0.2608 - val_loss: 1.6135 - val_acc: 0.4284\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 1.9945 - acc: 0.2910 - val_loss: 1.5665 - val_acc: 0.4440\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.9503 - acc: 0.3007 - val_loss: 1.5769 - val_acc: 0.4316\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 7s 468ms/step - loss: 2.0133 - acc: 0.2898 - val_loss: 1.5670 - val_acc: 0.4470\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.9744 - acc: 0.3003 - val_loss: 1.6163 - val_acc: 0.4306\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.9352 - acc: 0.3155 - val_loss: 1.5659 - val_acc: 0.4368\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.9722 - acc: 0.2938 - val_loss: 1.5606 - val_acc: 0.4442\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 1.9230 - acc: 0.3095 - val_loss: 1.5560 - val_acc: 0.4442\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 1.9342 - acc: 0.3135 - val_loss: 1.5761 - val_acc: 0.4464\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 1.8998 - acc: 0.3208 - val_loss: 1.5721 - val_acc: 0.4342\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.8458 - acc: 0.3467 - val_loss: 1.5413 - val_acc: 0.4424\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 1.9491 - acc: 0.3015 - val_loss: 1.5500 - val_acc: 0.4442\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 1.9011 - acc: 0.3300 - val_loss: 1.5489 - val_acc: 0.4538\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 1.8837 - acc: 0.3420 - val_loss: 1.5426 - val_acc: 0.4554\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 7s 450ms/step - loss: 1.9779 - acc: 0.2982 - val_loss: 1.6142 - val_acc: 0.4220\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.8813 - acc: 0.3290 - val_loss: 1.5391 - val_acc: 0.4488\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 7s 409ms/step - loss: 1.9461 - acc: 0.3132 - val_loss: 1.5428 - val_acc: 0.4404\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 1.9505 - acc: 0.3043 - val_loss: 1.5356 - val_acc: 0.4506\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 1.8654 - acc: 0.3488 - val_loss: 1.5515 - val_acc: 0.4366\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.8412 - acc: 0.3450 - val_loss: 1.5593 - val_acc: 0.4380\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 1.8898 - acc: 0.3503 - val_loss: 1.5390 - val_acc: 0.4512\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.8656 - acc: 0.3423 - val_loss: 1.5368 - val_acc: 0.4550\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.8904 - acc: 0.3330 - val_loss: 1.5452 - val_acc: 0.4566\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 1.8309 - acc: 0.3640 - val_loss: 1.5625 - val_acc: 0.4488\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 1.7622 - acc: 0.3852 - val_loss: 1.5253 - val_acc: 0.4560\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 8s 470ms/step - loss: 1.8795 - acc: 0.3578 - val_loss: 1.5280 - val_acc: 0.4566\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 7s 449ms/step - loss: 1.8579 - acc: 0.3620 - val_loss: 1.5364 - val_acc: 0.4572\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.7770 - acc: 0.3880 - val_loss: 1.5335 - val_acc: 0.4534\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 1.9154 - acc: 0.3265 - val_loss: 1.5191 - val_acc: 0.4566\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.9123 - acc: 0.3193 - val_loss: 1.5123 - val_acc: 0.4576\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.7268 - acc: 0.4115 - val_loss: 1.5290 - val_acc: 0.4508\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 1.8912 - acc: 0.3365 - val_loss: 1.5226 - val_acc: 0.4540\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.8679 - acc: 0.3572 - val_loss: 1.5541 - val_acc: 0.4518\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.8749 - acc: 0.3433 - val_loss: 1.5124 - val_acc: 0.4606\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 7s 448ms/step - loss: 1.9212 - acc: 0.3383 - val_loss: 1.5240 - val_acc: 0.4546\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 1.9714 - acc: 0.3125 - val_loss: 1.5366 - val_acc: 0.4592\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.9441 - acc: 0.3168 - val_loss: 1.5413 - val_acc: 0.4586\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 1.9162 - acc: 0.3435 - val_loss: 1.5405 - val_acc: 0.4492\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 1.8869 - acc: 0.3380 - val_loss: 1.5514 - val_acc: 0.4572\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.8334 - acc: 0.3555 - val_loss: 1.5541 - val_acc: 0.4518\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.8384 - acc: 0.3555 - val_loss: 1.5226 - val_acc: 0.4526\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.7830 - acc: 0.3767 - val_loss: 1.5120 - val_acc: 0.4578\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 1.8015 - acc: 0.3653 - val_loss: 1.5459 - val_acc: 0.4470\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 1.8468 - acc: 0.3553 - val_loss: 1.5525 - val_acc: 0.4494\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 7s 461ms/step - loss: 1.7628 - acc: 0.3925 - val_loss: 1.5603 - val_acc: 0.4476\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 1.7894 - acc: 0.3840 - val_loss: 1.5784 - val_acc: 0.4486\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 1.8382 - acc: 0.3650 - val_loss: 1.5446 - val_acc: 0.4604\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 1.8337 - acc: 0.3618 - val_loss: 1.5214 - val_acc: 0.4604\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 1.7574 - acc: 0.4073 - val_loss: 1.5352 - val_acc: 0.4436\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 1.8061 - acc: 0.3605 - val_loss: 1.5203 - val_acc: 0.4554\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.8336 - acc: 0.3648 - val_loss: 1.5386 - val_acc: 0.4518\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 7s 455ms/step - loss: 1.7988 - acc: 0.4002 - val_loss: 1.5633 - val_acc: 0.4386\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.7171 - acc: 0.4190 - val_loss: 1.5358 - val_acc: 0.4566\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.7736 - acc: 0.3823 - val_loss: 1.5524 - val_acc: 0.4532\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 1.7665 - acc: 0.3962 - val_loss: 1.5075 - val_acc: 0.4618\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 1.7939 - acc: 0.3960 - val_loss: 1.5337 - val_acc: 0.4368\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 1.8193 - acc: 0.3715 - val_loss: 1.5127 - val_acc: 0.4616\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 1.7542 - acc: 0.3955 - val_loss: 1.5312 - val_acc: 0.4672\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.7398 - acc: 0.4090 - val_loss: 1.5271 - val_acc: 0.4460\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 1.9157 - acc: 0.3303 - val_loss: 1.5454 - val_acc: 0.4550\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 8s 493ms/step - loss: 1.8484 - acc: 0.3615 - val_loss: 1.5348 - val_acc: 0.4514\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 1.6668 - acc: 0.4198 - val_loss: 1.5145 - val_acc: 0.4562\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.7026 - acc: 0.4133 - val_loss: 1.5154 - val_acc: 0.4514\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 1.7742 - acc: 0.3920 - val_loss: 1.5205 - val_acc: 0.4618\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.7385 - acc: 0.4050 - val_loss: 1.5043 - val_acc: 0.4610\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.6891 - acc: 0.4260 - val_loss: 1.5081 - val_acc: 0.4594\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 7s 454ms/step - loss: 1.8635 - acc: 0.3500 - val_loss: 1.5149 - val_acc: 0.4582\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 1.6908 - acc: 0.4328 - val_loss: 1.5202 - val_acc: 0.4610\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.7132 - acc: 0.4103 - val_loss: 1.5192 - val_acc: 0.4602\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 1.7813 - acc: 0.3818 - val_loss: 1.4942 - val_acc: 0.4644\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 1.8006 - acc: 0.3800 - val_loss: 1.5161 - val_acc: 0.4562\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.7751 - acc: 0.3828 - val_loss: 1.5082 - val_acc: 0.4710\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 1.7484 - acc: 0.4025 - val_loss: 1.5308 - val_acc: 0.4580\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.6059 - acc: 0.4573 - val_loss: 1.5391 - val_acc: 0.4506\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 1.8620 - acc: 0.3743 - val_loss: 1.5032 - val_acc: 0.4568\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 8s 487ms/step - loss: 1.8023 - acc: 0.3908 - val_loss: 1.5235 - val_acc: 0.4596\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 1.7234 - acc: 0.4053 - val_loss: 1.5232 - val_acc: 0.4484\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.6940 - acc: 0.4328 - val_loss: 1.5608 - val_acc: 0.4410\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 1.6521 - acc: 0.4383 - val_loss: 1.5164 - val_acc: 0.4586\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 8s 482ms/step - loss: 1.6621 - acc: 0.4510 - val_loss: 1.5265 - val_acc: 0.4514\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 7s 441ms/step - loss: 1.7423 - acc: 0.4110 - val_loss: 1.5353 - val_acc: 0.4436\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 1.6511 - acc: 0.4410 - val_loss: 1.5050 - val_acc: 0.4654\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 1.6463 - acc: 0.4368 - val_loss: 1.5332 - val_acc: 0.4592\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.5912 - acc: 0.4693 - val_loss: 1.5078 - val_acc: 0.4616\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 8s 486ms/step - loss: 1.7675 - acc: 0.4058 - val_loss: 1.5732 - val_acc: 0.4280\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.6940 - acc: 0.4320 - val_loss: 1.5236 - val_acc: 0.4552\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.5886 - acc: 0.4617 - val_loss: 1.5282 - val_acc: 0.4622\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 1.6767 - acc: 0.4332 - val_loss: 1.5065 - val_acc: 0.4692\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 7s 409ms/step - loss: 1.5350 - acc: 0.4888 - val_loss: 1.5154 - val_acc: 0.4618\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 7s 454ms/step - loss: 1.7722 - acc: 0.3975 - val_loss: 1.5249 - val_acc: 0.4616\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.6716 - acc: 0.4417 - val_loss: 1.5186 - val_acc: 0.4666\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.5740 - acc: 0.4743 - val_loss: 1.5054 - val_acc: 0.4644\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 1.7217 - acc: 0.4180 - val_loss: 1.5246 - val_acc: 0.4512\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 7s 448ms/step - loss: 1.6670 - acc: 0.4337 - val_loss: 1.5304 - val_acc: 0.4532\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 1.5826 - acc: 0.4688 - val_loss: 1.5250 - val_acc: 0.4550\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 1.6977 - acc: 0.4223 - val_loss: 1.5048 - val_acc: 0.4676\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 1.7110 - acc: 0.4150 - val_loss: 1.5064 - val_acc: 0.4636\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.6901 - acc: 0.4237 - val_loss: 1.5030 - val_acc: 0.4770\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.5537 - acc: 0.4878 - val_loss: 1.4915 - val_acc: 0.4758\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.5637 - acc: 0.4865 - val_loss: 1.5090 - val_acc: 0.4614\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.5580 - acc: 0.4778 - val_loss: 1.5081 - val_acc: 0.4656\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 1.5044 - acc: 0.4910 - val_loss: 1.5154 - val_acc: 0.4708\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 1.6530 - acc: 0.4460 - val_loss: 1.5110 - val_acc: 0.4694\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 7s 442ms/step - loss: 1.5592 - acc: 0.4835 - val_loss: 1.5475 - val_acc: 0.4468\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 1.6208 - acc: 0.4600 - val_loss: 1.6656 - val_acc: 0.4456\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.5148 - acc: 0.4930 - val_loss: 1.5027 - val_acc: 0.4618\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 7s 449ms/step - loss: 1.5613 - acc: 0.4903 - val_loss: 1.5143 - val_acc: 0.4558\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 1.5973 - acc: 0.4733 - val_loss: 1.5331 - val_acc: 0.4520\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 1.5936 - acc: 0.4680 - val_loss: 1.4815 - val_acc: 0.4672\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 1.4632 - acc: 0.5250 - val_loss: 1.4956 - val_acc: 0.4686\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.5087 - acc: 0.5140 - val_loss: 1.4781 - val_acc: 0.4644\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 1.6208 - acc: 0.4785 - val_loss: 1.5117 - val_acc: 0.4646\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 1.5595 - acc: 0.4925 - val_loss: 1.4891 - val_acc: 0.4692\n",
            "Epoch 156/200\n",
            "10/16 [=================>............] - ETA: 1s - loss: 1.4214 - acc: 0.5412"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eVIKMzYzn-PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "14fc6885-1932-472b-8248-23a2dadbfff5"
      },
      "cell_type": "code",
      "source": [
        "# train more...\n",
        "train_model(X_reduced, model_autoaug, aug_autoaug, 50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 7s 464ms/step - loss: 1.7893 - acc: 0.3825 - val_loss: 1.5263 - val_acc: 0.4794\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 1.6762 - acc: 0.4053 - val_loss: 1.5389 - val_acc: 0.4710\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 1.7925 - acc: 0.3745 - val_loss: 1.5060 - val_acc: 0.4758\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 1.7172 - acc: 0.4090 - val_loss: 1.5440 - val_acc: 0.4852\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.6094 - acc: 0.4415 - val_loss: 1.5366 - val_acc: 0.4728\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 1.7220 - acc: 0.4102 - val_loss: 1.5154 - val_acc: 0.4836\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.7162 - acc: 0.3987 - val_loss: 1.5074 - val_acc: 0.4872\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6012 - acc: 0.4407 - val_loss: 1.4919 - val_acc: 0.4846\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6741 - acc: 0.4078 - val_loss: 1.4961 - val_acc: 0.4936\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 1.6684 - acc: 0.4228 - val_loss: 1.5375 - val_acc: 0.4788\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.6845 - acc: 0.4088 - val_loss: 1.4870 - val_acc: 0.4944\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 7s 455ms/step - loss: 1.8040 - acc: 0.3787 - val_loss: 1.5146 - val_acc: 0.4856\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.6390 - acc: 0.4337 - val_loss: 1.4836 - val_acc: 0.4872\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.7278 - acc: 0.4055 - val_loss: 1.5090 - val_acc: 0.4818\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5304 - acc: 0.4813 - val_loss: 1.4812 - val_acc: 0.4912\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 1.5163 - acc: 0.4768 - val_loss: 1.5031 - val_acc: 0.4836\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.6879 - acc: 0.4130 - val_loss: 1.4943 - val_acc: 0.4896\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.6532 - acc: 0.4175 - val_loss: 1.4804 - val_acc: 0.4914\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 1.6712 - acc: 0.4248 - val_loss: 1.5311 - val_acc: 0.4836\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.7194 - acc: 0.3980 - val_loss: 1.4972 - val_acc: 0.4932\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.5762 - acc: 0.4572 - val_loss: 1.5116 - val_acc: 0.4932\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 1.6631 - acc: 0.4238 - val_loss: 1.4954 - val_acc: 0.4928\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.6091 - acc: 0.4382 - val_loss: 1.4938 - val_acc: 0.4930\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.5848 - acc: 0.4507 - val_loss: 1.4965 - val_acc: 0.4854\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.6248 - acc: 0.4383 - val_loss: 1.5001 - val_acc: 0.4844\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.5278 - acc: 0.4805 - val_loss: 1.4954 - val_acc: 0.4858\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.6052 - acc: 0.4413 - val_loss: 1.5291 - val_acc: 0.4918\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.5888 - acc: 0.4600 - val_loss: 1.4851 - val_acc: 0.4952\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.7001 - acc: 0.4078 - val_loss: 1.4860 - val_acc: 0.4920\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 8s 482ms/step - loss: 1.7764 - acc: 0.3852 - val_loss: 1.4868 - val_acc: 0.4956\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 1.7016 - acc: 0.4072 - val_loss: 1.4912 - val_acc: 0.4870\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5944 - acc: 0.4423 - val_loss: 1.5025 - val_acc: 0.4916\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 1.4332 - acc: 0.5163 - val_loss: 1.4839 - val_acc: 0.4894\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.6388 - acc: 0.4413 - val_loss: 1.5043 - val_acc: 0.4864\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 1.7102 - acc: 0.4045 - val_loss: 1.4971 - val_acc: 0.4922\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5365 - acc: 0.4837 - val_loss: 1.4776 - val_acc: 0.4958\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.6748 - acc: 0.4197 - val_loss: 1.4857 - val_acc: 0.4914\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.5809 - acc: 0.4648 - val_loss: 1.5210 - val_acc: 0.4716\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 1.5561 - acc: 0.4607 - val_loss: 1.4834 - val_acc: 0.4996\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.5997 - acc: 0.4490 - val_loss: 1.5079 - val_acc: 0.4902\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 7s 412ms/step - loss: 1.6691 - acc: 0.4213 - val_loss: 1.4830 - val_acc: 0.4936\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.6066 - acc: 0.4505 - val_loss: 1.4868 - val_acc: 0.4990\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 1.5684 - acc: 0.4687 - val_loss: 1.4970 - val_acc: 0.5006\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 1.6436 - acc: 0.4215 - val_loss: 1.5066 - val_acc: 0.4862\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.5474 - acc: 0.4725 - val_loss: 1.4819 - val_acc: 0.4984\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 1.6184 - acc: 0.4505 - val_loss: 1.4872 - val_acc: 0.4950\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5026 - acc: 0.4828 - val_loss: 1.4635 - val_acc: 0.4970\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.4773 - acc: 0.4960 - val_loss: 1.4834 - val_acc: 0.5016\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.4896 - acc: 0.4887 - val_loss: 1.4747 - val_acc: 0.4928\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.6797 - acc: 0.4243 - val_loss: 1.4931 - val_acc: 0.4876\n",
            "Test accuracy: 0.494 (elaspsed time: 80s)\n",
            "Accuracy\n",
            "airplane 0.563\n",
            "auto 0.619\n",
            "bird 0.348\n",
            "cat 0.311\n",
            "deer 0.339\n",
            "dog 0.479\n",
            "frog 0.575\n",
            "horse 0.672\n",
            "ship 0.486\n",
            "truck 0.547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pUldhku9pMIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "ead5d55a-bd1d-4c17-d680-52a3d090cae3"
      },
      "cell_type": "code",
      "source": [
        "# train more...\n",
        "train_model(X_reduced, model_autoaug, aug_autoaug, 50)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 7s 454ms/step - loss: 1.5838 - acc: 0.4700 - val_loss: 1.4908 - val_acc: 0.4886\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.5429 - acc: 0.4675 - val_loss: 1.4955 - val_acc: 0.4846\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 7s 443ms/step - loss: 1.6076 - acc: 0.4565 - val_loss: 1.5014 - val_acc: 0.4894\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 1.5436 - acc: 0.4813 - val_loss: 1.4961 - val_acc: 0.4908\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.4081 - acc: 0.5375 - val_loss: 1.5003 - val_acc: 0.4888\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 1.5508 - acc: 0.4765 - val_loss: 1.4950 - val_acc: 0.4896\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.5252 - acc: 0.4870 - val_loss: 1.5166 - val_acc: 0.4928\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.4393 - acc: 0.5137 - val_loss: 1.4939 - val_acc: 0.4996\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.5550 - acc: 0.4470 - val_loss: 1.4966 - val_acc: 0.4890\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.4737 - acc: 0.5148 - val_loss: 1.4814 - val_acc: 0.5010\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 1.4961 - acc: 0.4883 - val_loss: 1.5127 - val_acc: 0.4882\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 7s 442ms/step - loss: 1.6573 - acc: 0.4463 - val_loss: 1.5267 - val_acc: 0.4832\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.4570 - acc: 0.5045 - val_loss: 1.5577 - val_acc: 0.4994\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.5467 - acc: 0.4882 - val_loss: 1.4868 - val_acc: 0.5034\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.3441 - acc: 0.5517 - val_loss: 1.4964 - val_acc: 0.5054\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.3537 - acc: 0.5362 - val_loss: 1.4952 - val_acc: 0.5068\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.5058 - acc: 0.4838 - val_loss: 1.5065 - val_acc: 0.5032\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.5123 - acc: 0.4857 - val_loss: 1.5067 - val_acc: 0.5032\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.4657 - acc: 0.5070 - val_loss: 1.5518 - val_acc: 0.4930\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 1.5574 - acc: 0.4650 - val_loss: 1.5100 - val_acc: 0.5034\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.4141 - acc: 0.5210 - val_loss: 1.4948 - val_acc: 0.5076\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 1.4851 - acc: 0.5128 - val_loss: 1.5321 - val_acc: 0.5002\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.4309 - acc: 0.5182 - val_loss: 1.5079 - val_acc: 0.4984\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.4424 - acc: 0.5137 - val_loss: 1.5202 - val_acc: 0.4994\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 1.4397 - acc: 0.5183 - val_loss: 1.4971 - val_acc: 0.4994\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.3386 - acc: 0.5598 - val_loss: 1.4839 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.4594 - acc: 0.5050 - val_loss: 1.5671 - val_acc: 0.4964\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.4422 - acc: 0.5188 - val_loss: 1.5047 - val_acc: 0.4948\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 1.5658 - acc: 0.4743 - val_loss: 1.5279 - val_acc: 0.4898\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 8s 487ms/step - loss: 1.5952 - acc: 0.4530 - val_loss: 1.5300 - val_acc: 0.4804\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 1.5014 - acc: 0.5020 - val_loss: 1.4556 - val_acc: 0.5068\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.4769 - acc: 0.5093 - val_loss: 1.5352 - val_acc: 0.4906\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.2961 - acc: 0.5840 - val_loss: 1.5558 - val_acc: 0.4962\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.4519 - acc: 0.5280 - val_loss: 1.4720 - val_acc: 0.5012\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.5420 - acc: 0.4743 - val_loss: 1.5040 - val_acc: 0.4932\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.3939 - acc: 0.5365 - val_loss: 1.5187 - val_acc: 0.5020\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.4884 - acc: 0.4985 - val_loss: 1.4907 - val_acc: 0.5078\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 1.4170 - acc: 0.5177 - val_loss: 1.5065 - val_acc: 0.4964\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.3979 - acc: 0.5298 - val_loss: 1.5101 - val_acc: 0.5024\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.4617 - acc: 0.5158 - val_loss: 1.5008 - val_acc: 0.4980\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.5771 - acc: 0.4590 - val_loss: 1.4832 - val_acc: 0.5014\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.4633 - acc: 0.5095 - val_loss: 1.5048 - val_acc: 0.5028\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.3740 - acc: 0.5445 - val_loss: 1.5173 - val_acc: 0.4970\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 1.4967 - acc: 0.5000 - val_loss: 1.4917 - val_acc: 0.4984\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.3888 - acc: 0.5410 - val_loss: 1.5317 - val_acc: 0.4938\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.4942 - acc: 0.5148 - val_loss: 1.5471 - val_acc: 0.4968\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.3595 - acc: 0.5380 - val_loss: 1.4949 - val_acc: 0.5090\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.3529 - acc: 0.5422 - val_loss: 1.5385 - val_acc: 0.5026\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.3014 - acc: 0.5610 - val_loss: 1.4995 - val_acc: 0.5038\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.5257 - acc: 0.4823 - val_loss: 1.5463 - val_acc: 0.4940\n",
            "Test accuracy: 0.488 (elaspsed time: 81s)\n",
            "Accuracy\n",
            "airplane 0.532\n",
            "auto 0.635\n",
            "bird 0.297\n",
            "cat 0.394\n",
            "deer 0.35\n",
            "dog 0.484\n",
            "frog 0.486\n",
            "horse 0.649\n",
            "ship 0.515\n",
            "truck 0.541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tduMk0iirZKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "f36aad33-f01a-4fb6-b7ea-1287292cf0df"
      },
      "cell_type": "code",
      "source": [
        "# train more...\n",
        "train_model(X_reduced, model_autoaug, aug_autoaug, 50)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 7s 465ms/step - loss: 1.4180 - acc: 0.5448 - val_loss: 1.4911 - val_acc: 0.5106\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.3939 - acc: 0.5340 - val_loss: 1.5347 - val_acc: 0.5014\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 7s 451ms/step - loss: 1.4507 - acc: 0.5193 - val_loss: 1.5213 - val_acc: 0.5006\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 1.3364 - acc: 0.5665 - val_loss: 1.4912 - val_acc: 0.5036\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.2359 - acc: 0.5960 - val_loss: 1.5086 - val_acc: 0.4974\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 1.3578 - acc: 0.5490 - val_loss: 1.5228 - val_acc: 0.5030\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.3552 - acc: 0.5545 - val_loss: 1.4833 - val_acc: 0.5056\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.3250 - acc: 0.5502 - val_loss: 1.5055 - val_acc: 0.5040\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.4635 - acc: 0.4937 - val_loss: 1.4977 - val_acc: 0.5020\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.2749 - acc: 0.5940 - val_loss: 1.5030 - val_acc: 0.4972\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.3226 - acc: 0.5615 - val_loss: 1.5176 - val_acc: 0.5016\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 1.5166 - acc: 0.5058 - val_loss: 1.4899 - val_acc: 0.5096\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.3237 - acc: 0.5592 - val_loss: 1.5314 - val_acc: 0.5060\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.3468 - acc: 0.5630 - val_loss: 1.5069 - val_acc: 0.5092\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.2055 - acc: 0.6005 - val_loss: 1.4966 - val_acc: 0.5136\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.2255 - acc: 0.5943 - val_loss: 1.5546 - val_acc: 0.5008\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 1.3268 - acc: 0.5585 - val_loss: 1.4985 - val_acc: 0.5082\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.3724 - acc: 0.5428 - val_loss: 1.5238 - val_acc: 0.5066\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 7s 406ms/step - loss: 1.3357 - acc: 0.5620 - val_loss: 1.5107 - val_acc: 0.4990\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 1.4343 - acc: 0.5125 - val_loss: 1.5447 - val_acc: 0.5046\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.2902 - acc: 0.5660 - val_loss: 1.5276 - val_acc: 0.5082\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 1.3037 - acc: 0.5742 - val_loss: 1.5053 - val_acc: 0.5106\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.2726 - acc: 0.5875 - val_loss: 1.5299 - val_acc: 0.4982\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 1.2795 - acc: 0.5755 - val_loss: 1.5123 - val_acc: 0.5004\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.2734 - acc: 0.5842 - val_loss: 1.5195 - val_acc: 0.5032\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.1306 - acc: 0.6342 - val_loss: 1.4970 - val_acc: 0.5086\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.3305 - acc: 0.5625 - val_loss: 1.5173 - val_acc: 0.5054\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.2734 - acc: 0.5798 - val_loss: 1.5203 - val_acc: 0.5042\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.4001 - acc: 0.5527 - val_loss: 1.5117 - val_acc: 0.5024\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 8s 478ms/step - loss: 1.4432 - acc: 0.5302 - val_loss: 1.5103 - val_acc: 0.5056\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.3418 - acc: 0.5560 - val_loss: 1.5383 - val_acc: 0.4930\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.3770 - acc: 0.5445 - val_loss: 1.5465 - val_acc: 0.4988\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1226 - acc: 0.6502 - val_loss: 1.5157 - val_acc: 0.5062\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 1.3149 - acc: 0.5750 - val_loss: 1.4910 - val_acc: 0.5074\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 1.3979 - acc: 0.5397 - val_loss: 1.5332 - val_acc: 0.4988\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.2730 - acc: 0.5868 - val_loss: 1.5083 - val_acc: 0.5054\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.3595 - acc: 0.5510 - val_loss: 1.5191 - val_acc: 0.5130\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.2872 - acc: 0.5825 - val_loss: 1.6226 - val_acc: 0.4914\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.2316 - acc: 0.5922 - val_loss: 1.5183 - val_acc: 0.5090\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.3404 - acc: 0.5642 - val_loss: 1.5943 - val_acc: 0.4968\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 1.4315 - acc: 0.5213 - val_loss: 1.5375 - val_acc: 0.5022\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.3267 - acc: 0.5723 - val_loss: 1.5192 - val_acc: 0.5096\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.2497 - acc: 0.5973 - val_loss: 1.5704 - val_acc: 0.5012\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.3587 - acc: 0.5452 - val_loss: 1.5934 - val_acc: 0.4968\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.2660 - acc: 0.5890 - val_loss: 1.5531 - val_acc: 0.5062\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.3373 - acc: 0.5683 - val_loss: 1.5244 - val_acc: 0.5088\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.2250 - acc: 0.6013 - val_loss: 1.5127 - val_acc: 0.5036\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.2205 - acc: 0.5995 - val_loss: 1.5487 - val_acc: 0.5092\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.1511 - acc: 0.6245 - val_loss: 1.5298 - val_acc: 0.5110\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 1.4209 - acc: 0.5358 - val_loss: 1.5348 - val_acc: 0.4988\n",
            "Test accuracy: 0.498 (elaspsed time: 80s)\n",
            "Accuracy\n",
            "airplane 0.593\n",
            "auto 0.653\n",
            "bird 0.368\n",
            "cat 0.402\n",
            "deer 0.396\n",
            "dog 0.443\n",
            "frog 0.58\n",
            "horse 0.591\n",
            "ship 0.441\n",
            "truck 0.518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J1NYZ2dBKCqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Do the same for each transform in isolation..."
      ]
    },
    {
      "metadata": {
        "id": "NpHEp_HgKG1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "0d8286e2-8abb-4183-be82-56183080bd23"
      },
      "cell_type": "code",
      "source": [
        "# Try one to see how many epochs to try... \n",
        "op = opmap['Flip_LR']\n",
        "\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug_fliplr = autoaugment(transform, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_fliplr = create_model(X_reduced, 10)\n",
        "model_fliplr.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_fliplr, aug_fliplr, 300)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 2.3316 - acc: 0.1917 - val_loss: 1.8594 - val_acc: 0.3600\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 2.1970 - acc: 0.1950 - val_loss: 1.8433 - val_acc: 0.3590\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1766 - acc: 0.2070 - val_loss: 1.7979 - val_acc: 0.3806\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.1392 - acc: 0.2238 - val_loss: 1.8590 - val_acc: 0.3732\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1363 - acc: 0.2245 - val_loss: 1.8012 - val_acc: 0.3780\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1593 - acc: 0.2080 - val_loss: 1.7677 - val_acc: 0.3794\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1323 - acc: 0.2133 - val_loss: 1.7286 - val_acc: 0.3946\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1216 - acc: 0.2140 - val_loss: 1.7352 - val_acc: 0.3924\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0953 - acc: 0.2235 - val_loss: 1.7721 - val_acc: 0.3682\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.0974 - acc: 0.2258 - val_loss: 1.7343 - val_acc: 0.3852\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 2.0839 - acc: 0.2298 - val_loss: 1.7625 - val_acc: 0.3800\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 2.0784 - acc: 0.2462 - val_loss: 1.7398 - val_acc: 0.3954\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0602 - acc: 0.2365 - val_loss: 1.7134 - val_acc: 0.3970\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.0735 - acc: 0.2335 - val_loss: 1.7400 - val_acc: 0.3964\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0225 - acc: 0.2508 - val_loss: 1.7450 - val_acc: 0.3934\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.0285 - acc: 0.2555 - val_loss: 1.6869 - val_acc: 0.4014\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0483 - acc: 0.2410 - val_loss: 1.6824 - val_acc: 0.4012\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.9879 - acc: 0.2653 - val_loss: 1.6771 - val_acc: 0.4062\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.0132 - acc: 0.2520 - val_loss: 1.6539 - val_acc: 0.4126\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.9953 - acc: 0.2620 - val_loss: 1.6403 - val_acc: 0.4186\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9886 - acc: 0.2575 - val_loss: 1.6353 - val_acc: 0.4246\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.9663 - acc: 0.2780 - val_loss: 1.6587 - val_acc: 0.4150\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9853 - acc: 0.2628 - val_loss: 1.6796 - val_acc: 0.4002\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9483 - acc: 0.2743 - val_loss: 1.6469 - val_acc: 0.4258\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.9518 - acc: 0.2752 - val_loss: 1.6238 - val_acc: 0.4262\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9224 - acc: 0.2830 - val_loss: 1.6548 - val_acc: 0.4218\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9365 - acc: 0.2772 - val_loss: 1.6100 - val_acc: 0.4296\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9170 - acc: 0.2828 - val_loss: 1.6016 - val_acc: 0.4330\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.9485 - acc: 0.2708 - val_loss: 1.6348 - val_acc: 0.4178\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9215 - acc: 0.2802 - val_loss: 1.6247 - val_acc: 0.4186\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8898 - acc: 0.2977 - val_loss: 1.6493 - val_acc: 0.4230\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.9009 - acc: 0.2830 - val_loss: 1.6420 - val_acc: 0.4252\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8891 - acc: 0.2845 - val_loss: 1.6023 - val_acc: 0.4386\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.8633 - acc: 0.3032 - val_loss: 1.6026 - val_acc: 0.4336\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.8507 - acc: 0.3095 - val_loss: 1.6529 - val_acc: 0.4188\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8524 - acc: 0.3027 - val_loss: 1.5788 - val_acc: 0.4370\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8590 - acc: 0.3077 - val_loss: 1.5579 - val_acc: 0.4454\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8126 - acc: 0.3148 - val_loss: 1.5890 - val_acc: 0.4432\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8456 - acc: 0.3078 - val_loss: 1.5530 - val_acc: 0.4460\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8241 - acc: 0.3188 - val_loss: 1.5527 - val_acc: 0.4488\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.8445 - acc: 0.3097 - val_loss: 1.5429 - val_acc: 0.4506\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8169 - acc: 0.3155 - val_loss: 1.5413 - val_acc: 0.4548\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7922 - acc: 0.3342 - val_loss: 1.5380 - val_acc: 0.4578\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8347 - acc: 0.3222 - val_loss: 1.5321 - val_acc: 0.4538\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.8143 - acc: 0.3278 - val_loss: 1.5411 - val_acc: 0.4530\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7960 - acc: 0.3310 - val_loss: 1.5338 - val_acc: 0.4488\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7689 - acc: 0.3388 - val_loss: 1.5454 - val_acc: 0.4448\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7859 - acc: 0.3325 - val_loss: 1.5503 - val_acc: 0.4510\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7769 - acc: 0.3403 - val_loss: 1.5147 - val_acc: 0.4626\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7632 - acc: 0.3465 - val_loss: 1.5424 - val_acc: 0.4596\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.7577 - acc: 0.3445 - val_loss: 1.5414 - val_acc: 0.4500\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7535 - acc: 0.3480 - val_loss: 1.5283 - val_acc: 0.4610\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7521 - acc: 0.3615 - val_loss: 1.5190 - val_acc: 0.4644\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.7254 - acc: 0.3615 - val_loss: 1.5034 - val_acc: 0.4660\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7301 - acc: 0.3613 - val_loss: 1.5138 - val_acc: 0.4700\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.7294 - acc: 0.3668 - val_loss: 1.5250 - val_acc: 0.4626\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7105 - acc: 0.3730 - val_loss: 1.5118 - val_acc: 0.4758\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7270 - acc: 0.3618 - val_loss: 1.5252 - val_acc: 0.4620\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.6936 - acc: 0.3677 - val_loss: 1.5186 - val_acc: 0.4626\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.7148 - acc: 0.3670 - val_loss: 1.5019 - val_acc: 0.4700\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.6737 - acc: 0.3890 - val_loss: 1.5029 - val_acc: 0.4790\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6950 - acc: 0.3718 - val_loss: 1.5218 - val_acc: 0.4636\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6640 - acc: 0.3880 - val_loss: 1.5017 - val_acc: 0.4724\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.6783 - acc: 0.3837 - val_loss: 1.5009 - val_acc: 0.4650\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6606 - acc: 0.3930 - val_loss: 1.5406 - val_acc: 0.4570\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.6503 - acc: 0.3897 - val_loss: 1.4934 - val_acc: 0.4708\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.6407 - acc: 0.4018 - val_loss: 1.4943 - val_acc: 0.4758\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6434 - acc: 0.4005 - val_loss: 1.4994 - val_acc: 0.4778\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.6716 - acc: 0.3893 - val_loss: 1.5146 - val_acc: 0.4728\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6406 - acc: 0.3980 - val_loss: 1.5126 - val_acc: 0.4702\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6425 - acc: 0.4000 - val_loss: 1.5096 - val_acc: 0.4734\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6295 - acc: 0.4038 - val_loss: 1.4844 - val_acc: 0.4846\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6265 - acc: 0.4128 - val_loss: 1.4937 - val_acc: 0.4778\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.5954 - acc: 0.4188 - val_loss: 1.4892 - val_acc: 0.4738\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6045 - acc: 0.4120 - val_loss: 1.4781 - val_acc: 0.4754\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5904 - acc: 0.4200 - val_loss: 1.4918 - val_acc: 0.4758\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5968 - acc: 0.4163 - val_loss: 1.5143 - val_acc: 0.4780\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5758 - acc: 0.4247 - val_loss: 1.5224 - val_acc: 0.4826\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5778 - acc: 0.4240 - val_loss: 1.4799 - val_acc: 0.4854\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5706 - acc: 0.4278 - val_loss: 1.5032 - val_acc: 0.4772\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5672 - acc: 0.4333 - val_loss: 1.5069 - val_acc: 0.4748\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5870 - acc: 0.4202 - val_loss: 1.4838 - val_acc: 0.4912\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5275 - acc: 0.4495 - val_loss: 1.4637 - val_acc: 0.4846\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5621 - acc: 0.4322 - val_loss: 1.4927 - val_acc: 0.4854\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5555 - acc: 0.4425 - val_loss: 1.4813 - val_acc: 0.4848\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5451 - acc: 0.4412 - val_loss: 1.5036 - val_acc: 0.4820\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5442 - acc: 0.4392 - val_loss: 1.5086 - val_acc: 0.4794\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5473 - acc: 0.4447 - val_loss: 1.4977 - val_acc: 0.4870\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5103 - acc: 0.4628 - val_loss: 1.4777 - val_acc: 0.4918\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5236 - acc: 0.4558 - val_loss: 1.4732 - val_acc: 0.4912\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5286 - acc: 0.4592 - val_loss: 1.4878 - val_acc: 0.4878\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5035 - acc: 0.4650 - val_loss: 1.5214 - val_acc: 0.4906\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4853 - acc: 0.4628 - val_loss: 1.4841 - val_acc: 0.4888\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.4526 - acc: 0.4800 - val_loss: 1.4913 - val_acc: 0.4938\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4919 - acc: 0.4722 - val_loss: 1.4760 - val_acc: 0.4870\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4817 - acc: 0.4715 - val_loss: 1.4828 - val_acc: 0.4978\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4720 - acc: 0.4857 - val_loss: 1.4799 - val_acc: 0.4942\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4666 - acc: 0.4795 - val_loss: 1.6719 - val_acc: 0.4692\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4588 - acc: 0.4770 - val_loss: 1.4770 - val_acc: 0.4964\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4591 - acc: 0.4815 - val_loss: 1.5057 - val_acc: 0.4870\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4498 - acc: 0.4875 - val_loss: 1.5017 - val_acc: 0.4858\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4622 - acc: 0.4828 - val_loss: 1.4787 - val_acc: 0.4932\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4413 - acc: 0.4980 - val_loss: 1.4976 - val_acc: 0.4880\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4383 - acc: 0.4933 - val_loss: 1.4978 - val_acc: 0.4826\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4215 - acc: 0.4952 - val_loss: 1.4919 - val_acc: 0.4902\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4134 - acc: 0.5100 - val_loss: 1.4991 - val_acc: 0.4896\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.4291 - acc: 0.4988 - val_loss: 1.4687 - val_acc: 0.4994\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4098 - acc: 0.5040 - val_loss: 1.4961 - val_acc: 0.4908\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3984 - acc: 0.5135 - val_loss: 1.5222 - val_acc: 0.4870\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4224 - acc: 0.4977 - val_loss: 1.5233 - val_acc: 0.4926\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3852 - acc: 0.5112 - val_loss: 1.5171 - val_acc: 0.4916\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3815 - acc: 0.5125 - val_loss: 1.4664 - val_acc: 0.4998\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3460 - acc: 0.5290 - val_loss: 1.5299 - val_acc: 0.4798\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3786 - acc: 0.5242 - val_loss: 1.4642 - val_acc: 0.5076\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.3886 - acc: 0.5075 - val_loss: 1.4875 - val_acc: 0.4924\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3540 - acc: 0.5303 - val_loss: 1.5182 - val_acc: 0.5008\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3483 - acc: 0.5317 - val_loss: 1.4717 - val_acc: 0.4994\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3461 - acc: 0.5220 - val_loss: 1.4834 - val_acc: 0.4932\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3245 - acc: 0.5368 - val_loss: 1.5250 - val_acc: 0.4998\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3189 - acc: 0.5420 - val_loss: 1.4741 - val_acc: 0.4964\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.3338 - acc: 0.5390 - val_loss: 1.5002 - val_acc: 0.4948\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3210 - acc: 0.5423 - val_loss: 1.4835 - val_acc: 0.5090\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3229 - acc: 0.5385 - val_loss: 1.4861 - val_acc: 0.5038\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2908 - acc: 0.5490 - val_loss: 1.5100 - val_acc: 0.4992\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2858 - acc: 0.5500 - val_loss: 1.4992 - val_acc: 0.5004\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.3271 - acc: 0.5415 - val_loss: 1.4885 - val_acc: 0.5066\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.3021 - acc: 0.5465 - val_loss: 1.5040 - val_acc: 0.5068\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2933 - acc: 0.5445 - val_loss: 1.5243 - val_acc: 0.5042\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2789 - acc: 0.5572 - val_loss: 1.6200 - val_acc: 0.4974\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2669 - acc: 0.5627 - val_loss: 1.4855 - val_acc: 0.5158\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2914 - acc: 0.5583 - val_loss: 1.4832 - val_acc: 0.5108\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2645 - acc: 0.5725 - val_loss: 1.5285 - val_acc: 0.5058\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2823 - acc: 0.5545 - val_loss: 1.4836 - val_acc: 0.5058\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2724 - acc: 0.5565 - val_loss: 1.4831 - val_acc: 0.5150\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2488 - acc: 0.5733 - val_loss: 1.4647 - val_acc: 0.5130\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2566 - acc: 0.5623 - val_loss: 1.5561 - val_acc: 0.4866\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2385 - acc: 0.5692 - val_loss: 1.5035 - val_acc: 0.5028\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2539 - acc: 0.5672 - val_loss: 1.4633 - val_acc: 0.5120\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 1.2229 - acc: 0.5863 - val_loss: 1.4840 - val_acc: 0.5074\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.1983 - acc: 0.5895 - val_loss: 1.5192 - val_acc: 0.5114\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2045 - acc: 0.5970 - val_loss: 1.5043 - val_acc: 0.5016\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2177 - acc: 0.5795 - val_loss: 1.4866 - val_acc: 0.5122\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2071 - acc: 0.5858 - val_loss: 1.5067 - val_acc: 0.5078\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2246 - acc: 0.5840 - val_loss: 1.4939 - val_acc: 0.5142\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1618 - acc: 0.6038 - val_loss: 1.4833 - val_acc: 0.5132\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.1820 - acc: 0.6015 - val_loss: 1.4875 - val_acc: 0.5052\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1984 - acc: 0.5970 - val_loss: 1.4713 - val_acc: 0.5118\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1660 - acc: 0.6060 - val_loss: 1.5400 - val_acc: 0.5056\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1432 - acc: 0.6175 - val_loss: 1.5069 - val_acc: 0.5060\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1596 - acc: 0.6060 - val_loss: 1.5009 - val_acc: 0.5088\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.1883 - acc: 0.5992 - val_loss: 1.5064 - val_acc: 0.5052\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1723 - acc: 0.5992 - val_loss: 1.5186 - val_acc: 0.5008\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1749 - acc: 0.6035 - val_loss: 1.5596 - val_acc: 0.5054\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1272 - acc: 0.6235 - val_loss: 1.5035 - val_acc: 0.5010\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.1097 - acc: 0.6217 - val_loss: 1.4922 - val_acc: 0.5110\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1120 - acc: 0.6325 - val_loss: 1.5228 - val_acc: 0.5116\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1525 - acc: 0.6125 - val_loss: 1.5067 - val_acc: 0.5156\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1206 - acc: 0.6298 - val_loss: 1.4956 - val_acc: 0.5138\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1398 - acc: 0.6103 - val_loss: 1.5308 - val_acc: 0.5122\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0900 - acc: 0.6378 - val_loss: 1.4985 - val_acc: 0.5142\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1086 - acc: 0.6328 - val_loss: 1.4876 - val_acc: 0.5204\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1135 - acc: 0.6178 - val_loss: 1.4961 - val_acc: 0.5134\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1053 - acc: 0.6255 - val_loss: 1.5135 - val_acc: 0.5120\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0682 - acc: 0.6538 - val_loss: 1.5048 - val_acc: 0.5140\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1090 - acc: 0.6245 - val_loss: 1.4933 - val_acc: 0.5188\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0803 - acc: 0.6398 - val_loss: 1.5047 - val_acc: 0.5048\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0694 - acc: 0.6445 - val_loss: 1.5064 - val_acc: 0.5160\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0762 - acc: 0.6433 - val_loss: 1.5314 - val_acc: 0.5152\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0718 - acc: 0.6438 - val_loss: 1.5186 - val_acc: 0.5134\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.0524 - acc: 0.6507 - val_loss: 1.5314 - val_acc: 0.5152\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.0402 - acc: 0.6487 - val_loss: 1.5073 - val_acc: 0.5196\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0334 - acc: 0.6572 - val_loss: 1.5150 - val_acc: 0.5130\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0583 - acc: 0.6367 - val_loss: 1.5130 - val_acc: 0.5136\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0345 - acc: 0.6622 - val_loss: 1.5088 - val_acc: 0.5210\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.0304 - acc: 0.6608 - val_loss: 1.5205 - val_acc: 0.5100\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0416 - acc: 0.6550 - val_loss: 1.5066 - val_acc: 0.5034\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0219 - acc: 0.6582 - val_loss: 1.5011 - val_acc: 0.5214\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0064 - acc: 0.6690 - val_loss: 1.5213 - val_acc: 0.5178\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.0164 - acc: 0.6630 - val_loss: 1.6422 - val_acc: 0.4880\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0107 - acc: 0.6725 - val_loss: 1.5310 - val_acc: 0.5160\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9847 - acc: 0.6698 - val_loss: 1.5732 - val_acc: 0.5126\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9944 - acc: 0.6688 - val_loss: 1.4993 - val_acc: 0.5162\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9888 - acc: 0.6638 - val_loss: 1.5013 - val_acc: 0.5178\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.9984 - acc: 0.6658 - val_loss: 1.5305 - val_acc: 0.5188\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0030 - acc: 0.6730 - val_loss: 1.5105 - val_acc: 0.5126\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9575 - acc: 0.6923 - val_loss: 1.5402 - val_acc: 0.5080\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9695 - acc: 0.6803 - val_loss: 1.5378 - val_acc: 0.5104\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9695 - acc: 0.6828 - val_loss: 1.5756 - val_acc: 0.5046\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9617 - acc: 0.6812 - val_loss: 1.5194 - val_acc: 0.5110\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.9760 - acc: 0.6750 - val_loss: 1.5833 - val_acc: 0.5038\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9381 - acc: 0.7015 - val_loss: 1.5265 - val_acc: 0.5220\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9531 - acc: 0.6837 - val_loss: 1.5066 - val_acc: 0.5146\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9371 - acc: 0.6878 - val_loss: 1.5405 - val_acc: 0.5114\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.9461 - acc: 0.6863 - val_loss: 1.5510 - val_acc: 0.5120\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.9580 - acc: 0.6840 - val_loss: 1.5124 - val_acc: 0.5146\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9327 - acc: 0.6980 - val_loss: 1.5335 - val_acc: 0.5130\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.9427 - acc: 0.6870 - val_loss: 1.5405 - val_acc: 0.5152\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.9209 - acc: 0.6960 - val_loss: 1.5689 - val_acc: 0.5062\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9026 - acc: 0.7065 - val_loss: 1.5606 - val_acc: 0.5212\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8958 - acc: 0.7045 - val_loss: 1.6099 - val_acc: 0.5058\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.9061 - acc: 0.6985 - val_loss: 1.5708 - val_acc: 0.5096\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8962 - acc: 0.7025 - val_loss: 1.5664 - val_acc: 0.5014\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.8887 - acc: 0.7035 - val_loss: 1.5503 - val_acc: 0.5174\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.8777 - acc: 0.7165 - val_loss: 1.5038 - val_acc: 0.5254\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8880 - acc: 0.7092 - val_loss: 1.5654 - val_acc: 0.5124\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8673 - acc: 0.7150 - val_loss: 1.5154 - val_acc: 0.5262\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8839 - acc: 0.7115 - val_loss: 1.5451 - val_acc: 0.5192\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.8843 - acc: 0.7140 - val_loss: 1.5218 - val_acc: 0.5204\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8625 - acc: 0.7232 - val_loss: 1.5231 - val_acc: 0.5218\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.8587 - acc: 0.7195 - val_loss: 1.5545 - val_acc: 0.5168\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.8353 - acc: 0.7240 - val_loss: 1.6088 - val_acc: 0.5098\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8555 - acc: 0.7245 - val_loss: 1.5551 - val_acc: 0.5164\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.8558 - acc: 0.7140 - val_loss: 1.5494 - val_acc: 0.5176\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.8261 - acc: 0.7400 - val_loss: 1.6188 - val_acc: 0.5106\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8143 - acc: 0.7302 - val_loss: 1.5708 - val_acc: 0.5148\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8546 - acc: 0.7150 - val_loss: 1.5547 - val_acc: 0.5136\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.7901 - acc: 0.7422 - val_loss: 1.5658 - val_acc: 0.5186\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8197 - acc: 0.7265 - val_loss: 1.5740 - val_acc: 0.5062\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8150 - acc: 0.7338 - val_loss: 1.5858 - val_acc: 0.5086\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8131 - acc: 0.7370 - val_loss: 1.6080 - val_acc: 0.5194\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8005 - acc: 0.7350 - val_loss: 1.5467 - val_acc: 0.5164\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8134 - acc: 0.7365 - val_loss: 1.5359 - val_acc: 0.5200\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.8098 - acc: 0.7353 - val_loss: 1.5420 - val_acc: 0.5256\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7978 - acc: 0.7325 - val_loss: 1.5647 - val_acc: 0.5246\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8086 - acc: 0.7355 - val_loss: 1.5433 - val_acc: 0.5152\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7875 - acc: 0.7480 - val_loss: 1.5518 - val_acc: 0.5160\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.7783 - acc: 0.7437 - val_loss: 1.5825 - val_acc: 0.5168\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7754 - acc: 0.7530 - val_loss: 1.6049 - val_acc: 0.5130\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.7719 - acc: 0.7540 - val_loss: 1.5398 - val_acc: 0.5180\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7675 - acc: 0.7548 - val_loss: 1.5690 - val_acc: 0.5200\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.7485 - acc: 0.7540 - val_loss: 1.5641 - val_acc: 0.5222\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7354 - acc: 0.7630 - val_loss: 1.5579 - val_acc: 0.5276\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7451 - acc: 0.7600 - val_loss: 1.5863 - val_acc: 0.5210\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.7344 - acc: 0.7675 - val_loss: 1.5530 - val_acc: 0.5180\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7490 - acc: 0.7660 - val_loss: 1.5571 - val_acc: 0.5298\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.7304 - acc: 0.7663 - val_loss: 1.5539 - val_acc: 0.5236\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.7447 - acc: 0.7590 - val_loss: 1.5795 - val_acc: 0.5242\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.7385 - acc: 0.7600 - val_loss: 1.6159 - val_acc: 0.5174\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7049 - acc: 0.7778 - val_loss: 1.6067 - val_acc: 0.5192\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7478 - acc: 0.7548 - val_loss: 1.5865 - val_acc: 0.5104\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7163 - acc: 0.7675 - val_loss: 1.6402 - val_acc: 0.5198\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.7160 - acc: 0.7670 - val_loss: 1.5347 - val_acc: 0.5244\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7089 - acc: 0.7768 - val_loss: 1.5794 - val_acc: 0.5178\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.7105 - acc: 0.7750 - val_loss: 1.5775 - val_acc: 0.5210\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6895 - acc: 0.7782 - val_loss: 1.5499 - val_acc: 0.5254\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.6989 - acc: 0.7758 - val_loss: 1.5766 - val_acc: 0.5204\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.7024 - acc: 0.7790 - val_loss: 1.5533 - val_acc: 0.5238\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.6719 - acc: 0.7842 - val_loss: 1.5705 - val_acc: 0.5190\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.6857 - acc: 0.7802 - val_loss: 1.5985 - val_acc: 0.5134\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.6776 - acc: 0.7895 - val_loss: 1.5819 - val_acc: 0.5178\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.6568 - acc: 0.7910 - val_loss: 1.6172 - val_acc: 0.5110\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.6805 - acc: 0.7823 - val_loss: 1.5766 - val_acc: 0.5122\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 0.6727 - acc: 0.7807 - val_loss: 1.6114 - val_acc: 0.5244\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.6762 - acc: 0.7827 - val_loss: 1.6324 - val_acc: 0.5216\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6676 - acc: 0.7952 - val_loss: 1.5862 - val_acc: 0.5176\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.6462 - acc: 0.7940 - val_loss: 1.5883 - val_acc: 0.5192\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.6502 - acc: 0.7953 - val_loss: 1.5658 - val_acc: 0.5312\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.6418 - acc: 0.7905 - val_loss: 1.5535 - val_acc: 0.5208\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.6444 - acc: 0.7950 - val_loss: 1.5925 - val_acc: 0.5266\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6214 - acc: 0.8090 - val_loss: 1.6436 - val_acc: 0.5146\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.6502 - acc: 0.7955 - val_loss: 1.5991 - val_acc: 0.5166\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.6205 - acc: 0.8047 - val_loss: 1.5765 - val_acc: 0.5210\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.6448 - acc: 0.7985 - val_loss: 1.5805 - val_acc: 0.5218\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6267 - acc: 0.8013 - val_loss: 1.6028 - val_acc: 0.5280\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.6190 - acc: 0.8082 - val_loss: 1.6294 - val_acc: 0.5238\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6081 - acc: 0.8050 - val_loss: 1.6099 - val_acc: 0.5162\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.6082 - acc: 0.8082 - val_loss: 1.5953 - val_acc: 0.5224\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.6363 - acc: 0.7968 - val_loss: 1.5760 - val_acc: 0.5266\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.5965 - acc: 0.8062 - val_loss: 1.6306 - val_acc: 0.5236\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.5933 - acc: 0.8110 - val_loss: 1.6162 - val_acc: 0.5180\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 0.6047 - acc: 0.8140 - val_loss: 1.6038 - val_acc: 0.5246\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6032 - acc: 0.8060 - val_loss: 1.5966 - val_acc: 0.5236\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.5768 - acc: 0.8178 - val_loss: 1.6017 - val_acc: 0.5186\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.6283 - acc: 0.8023 - val_loss: 1.5874 - val_acc: 0.5254\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.6053 - acc: 0.8077 - val_loss: 1.6643 - val_acc: 0.5122\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5866 - acc: 0.8233 - val_loss: 1.5674 - val_acc: 0.5244\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.5967 - acc: 0.8155 - val_loss: 1.6281 - val_acc: 0.5202\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5802 - acc: 0.8242 - val_loss: 1.5902 - val_acc: 0.5282\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.5776 - acc: 0.8137 - val_loss: 1.5865 - val_acc: 0.5230\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.5798 - acc: 0.8113 - val_loss: 1.7108 - val_acc: 0.5100\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.5598 - acc: 0.8185 - val_loss: 1.6119 - val_acc: 0.5238\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.5636 - acc: 0.8205 - val_loss: 1.6972 - val_acc: 0.5102\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.5634 - acc: 0.8160 - val_loss: 1.6134 - val_acc: 0.5208\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 0.5559 - acc: 0.8185 - val_loss: 1.5972 - val_acc: 0.5246\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.5580 - acc: 0.8252 - val_loss: 1.6105 - val_acc: 0.5210\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.5599 - acc: 0.8220 - val_loss: 1.6325 - val_acc: 0.5240\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.5599 - acc: 0.8267 - val_loss: 1.6560 - val_acc: 0.5114\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.5456 - acc: 0.8287 - val_loss: 1.6057 - val_acc: 0.5206\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5474 - acc: 0.8265 - val_loss: 1.6170 - val_acc: 0.5182\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.5239 - acc: 0.8377 - val_loss: 1.6939 - val_acc: 0.5018\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5510 - acc: 0.8275 - val_loss: 1.6801 - val_acc: 0.5146\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.5302 - acc: 0.8315 - val_loss: 1.7089 - val_acc: 0.5148\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5490 - acc: 0.8255 - val_loss: 1.6330 - val_acc: 0.5222\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.5256 - acc: 0.8352 - val_loss: 1.6269 - val_acc: 0.5254\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.4990 - acc: 0.8488 - val_loss: 1.6506 - val_acc: 0.5316\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.5213 - acc: 0.8342 - val_loss: 1.6218 - val_acc: 0.5200\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.4966 - acc: 0.8455 - val_loss: 1.6269 - val_acc: 0.5232\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.5076 - acc: 0.8425 - val_loss: 1.6048 - val_acc: 0.5196\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 0.5071 - acc: 0.8447 - val_loss: 1.7029 - val_acc: 0.5140\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.5361 - acc: 0.8275 - val_loss: 1.7137 - val_acc: 0.5244\n",
            "Test accuracy: 0.526 (elaspsed time: 484s)\n",
            "Accuracy\n",
            "airplane 0.6\n",
            "auto 0.681\n",
            "bird 0.317\n",
            "cat 0.25\n",
            "deer 0.404\n",
            "dog 0.459\n",
            "frog 0.709\n",
            "horse 0.688\n",
            "ship 0.551\n",
            "truck 0.605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMRWu9BuwzZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "24b1e52d-3799-4d50-8925-6b09cb2f923d"
      },
      "cell_type": "code",
      "source": [
        "# Try one to see how many epochs to try... \n",
        "op = opmap['Cutout']\n",
        "\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug_cutout = autoaugment(transform, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_cutout = create_model(X_reduced, 10)\n",
        "model_cutout.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_cutout, aug_cutout, 300)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 2.2986 - acc: 0.1995 - val_loss: 1.8615 - val_acc: 0.3700\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 3s 191ms/step - loss: 2.2051 - acc: 0.2048 - val_loss: 1.8320 - val_acc: 0.3624\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.1961 - acc: 0.2038 - val_loss: 1.8168 - val_acc: 0.3666\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.1724 - acc: 0.2110 - val_loss: 1.8240 - val_acc: 0.3724\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 2.1660 - acc: 0.2157 - val_loss: 1.7610 - val_acc: 0.3812\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.1325 - acc: 0.2250 - val_loss: 1.7575 - val_acc: 0.3820\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.1109 - acc: 0.2197 - val_loss: 1.7349 - val_acc: 0.3960\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.0863 - acc: 0.2248 - val_loss: 1.8052 - val_acc: 0.3742\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0788 - acc: 0.2405 - val_loss: 1.7106 - val_acc: 0.3940\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0785 - acc: 0.2280 - val_loss: 1.7061 - val_acc: 0.3972\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0470 - acc: 0.2500 - val_loss: 1.7321 - val_acc: 0.3976\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.0521 - acc: 0.2453 - val_loss: 1.6987 - val_acc: 0.4040\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 2.0509 - acc: 0.2402 - val_loss: 1.6975 - val_acc: 0.4062\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0272 - acc: 0.2590 - val_loss: 1.7175 - val_acc: 0.4016\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0411 - acc: 0.2413 - val_loss: 1.6758 - val_acc: 0.4102\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0061 - acc: 0.2625 - val_loss: 1.7078 - val_acc: 0.4070\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.0186 - acc: 0.2605 - val_loss: 1.6813 - val_acc: 0.4068\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 2.0045 - acc: 0.2528 - val_loss: 1.6693 - val_acc: 0.4062\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9585 - acc: 0.2607 - val_loss: 1.6387 - val_acc: 0.4226\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9805 - acc: 0.2615 - val_loss: 1.6469 - val_acc: 0.4224\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9920 - acc: 0.2562 - val_loss: 1.6290 - val_acc: 0.4288\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.9547 - acc: 0.2658 - val_loss: 1.6156 - val_acc: 0.4276\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.9721 - acc: 0.2665 - val_loss: 1.6436 - val_acc: 0.4270\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9452 - acc: 0.2673 - val_loss: 1.6123 - val_acc: 0.4270\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.9405 - acc: 0.2750 - val_loss: 1.6783 - val_acc: 0.4086\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.9236 - acc: 0.2747 - val_loss: 1.6136 - val_acc: 0.4334\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9352 - acc: 0.2683 - val_loss: 1.5951 - val_acc: 0.4246\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9233 - acc: 0.2785 - val_loss: 1.5857 - val_acc: 0.4358\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.9069 - acc: 0.2838 - val_loss: 1.5751 - val_acc: 0.4418\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.8703 - acc: 0.3035 - val_loss: 1.5634 - val_acc: 0.4404\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8817 - acc: 0.2922 - val_loss: 1.5747 - val_acc: 0.4426\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.8645 - acc: 0.2948 - val_loss: 1.5959 - val_acc: 0.4296\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8272 - acc: 0.3105 - val_loss: 1.5879 - val_acc: 0.4354\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.8501 - acc: 0.3058 - val_loss: 1.5591 - val_acc: 0.4396\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8387 - acc: 0.3082 - val_loss: 1.5760 - val_acc: 0.4406\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8519 - acc: 0.3050 - val_loss: 1.5629 - val_acc: 0.4412\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.8513 - acc: 0.3020 - val_loss: 1.5521 - val_acc: 0.4468\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8236 - acc: 0.3157 - val_loss: 1.5381 - val_acc: 0.4496\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8382 - acc: 0.3128 - val_loss: 1.5497 - val_acc: 0.4476\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8328 - acc: 0.3248 - val_loss: 1.5575 - val_acc: 0.4482\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.8161 - acc: 0.3203 - val_loss: 1.5607 - val_acc: 0.4496\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8105 - acc: 0.3290 - val_loss: 1.5543 - val_acc: 0.4524\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8029 - acc: 0.3345 - val_loss: 1.5513 - val_acc: 0.4540\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8097 - acc: 0.3318 - val_loss: 1.5892 - val_acc: 0.4344\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7517 - acc: 0.3438 - val_loss: 1.5715 - val_acc: 0.4414\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7600 - acc: 0.3348 - val_loss: 1.5663 - val_acc: 0.4516\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.7748 - acc: 0.3397 - val_loss: 1.5309 - val_acc: 0.4608\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8103 - acc: 0.3268 - val_loss: 1.5547 - val_acc: 0.4616\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7738 - acc: 0.3325 - val_loss: 1.5630 - val_acc: 0.4620\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7626 - acc: 0.3450 - val_loss: 1.5305 - val_acc: 0.4638\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7391 - acc: 0.3448 - val_loss: 1.5189 - val_acc: 0.4644\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7564 - acc: 0.3375 - val_loss: 1.5468 - val_acc: 0.4606\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7468 - acc: 0.3448 - val_loss: 1.5317 - val_acc: 0.4720\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7482 - acc: 0.3513 - val_loss: 1.5201 - val_acc: 0.4706\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.7437 - acc: 0.3493 - val_loss: 1.5613 - val_acc: 0.4474\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7159 - acc: 0.3585 - val_loss: 1.4972 - val_acc: 0.4720\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6919 - acc: 0.3642 - val_loss: 1.5036 - val_acc: 0.4714\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.7150 - acc: 0.3635 - val_loss: 1.5390 - val_acc: 0.4650\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.7210 - acc: 0.3625 - val_loss: 1.5373 - val_acc: 0.4692\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6697 - acc: 0.3747 - val_loss: 1.5001 - val_acc: 0.4786\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.7243 - acc: 0.3498 - val_loss: 1.5100 - val_acc: 0.4784\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.6803 - acc: 0.3750 - val_loss: 1.5134 - val_acc: 0.4756\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 1.7047 - acc: 0.3620 - val_loss: 1.4950 - val_acc: 0.4880\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.6963 - acc: 0.3748 - val_loss: 1.4881 - val_acc: 0.4836\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.6815 - acc: 0.3857 - val_loss: 1.4932 - val_acc: 0.4890\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6489 - acc: 0.3863 - val_loss: 1.5467 - val_acc: 0.4832\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6865 - acc: 0.3753 - val_loss: 1.5327 - val_acc: 0.4728\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.6495 - acc: 0.3890 - val_loss: 1.4897 - val_acc: 0.4870\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6432 - acc: 0.3880 - val_loss: 1.5176 - val_acc: 0.4738\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6528 - acc: 0.3928 - val_loss: 1.5401 - val_acc: 0.4726\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6166 - acc: 0.4060 - val_loss: 1.5035 - val_acc: 0.4794\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6253 - acc: 0.3980 - val_loss: 1.5018 - val_acc: 0.4800\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6301 - acc: 0.3988 - val_loss: 1.4719 - val_acc: 0.4894\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6180 - acc: 0.4025 - val_loss: 1.4817 - val_acc: 0.4840\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6252 - acc: 0.4037 - val_loss: 1.4771 - val_acc: 0.4954\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6138 - acc: 0.4055 - val_loss: 1.5062 - val_acc: 0.4892\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5863 - acc: 0.4132 - val_loss: 1.4888 - val_acc: 0.4850\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.5761 - acc: 0.4208 - val_loss: 1.4780 - val_acc: 0.4868\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5867 - acc: 0.4155 - val_loss: 1.4788 - val_acc: 0.4988\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.6100 - acc: 0.4000 - val_loss: 1.6094 - val_acc: 0.4728\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5664 - acc: 0.4190 - val_loss: 1.5219 - val_acc: 0.4924\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5842 - acc: 0.4193 - val_loss: 1.4918 - val_acc: 0.4908\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5997 - acc: 0.4100 - val_loss: 1.4982 - val_acc: 0.4844\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5652 - acc: 0.4290 - val_loss: 1.4786 - val_acc: 0.4942\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5721 - acc: 0.4152 - val_loss: 1.4933 - val_acc: 0.4922\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.5515 - acc: 0.4265 - val_loss: 1.4745 - val_acc: 0.4976\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5494 - acc: 0.4252 - val_loss: 1.4878 - val_acc: 0.4914\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5435 - acc: 0.4390 - val_loss: 1.5028 - val_acc: 0.4916\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5522 - acc: 0.4313 - val_loss: 1.5635 - val_acc: 0.4804\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.5565 - acc: 0.4390 - val_loss: 1.4758 - val_acc: 0.5038\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5164 - acc: 0.4463 - val_loss: 1.4784 - val_acc: 0.4990\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.5473 - acc: 0.4303 - val_loss: 1.5330 - val_acc: 0.4866\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5124 - acc: 0.4558 - val_loss: 1.5167 - val_acc: 0.4952\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.5088 - acc: 0.4575 - val_loss: 1.4890 - val_acc: 0.5036\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5235 - acc: 0.4390 - val_loss: 1.5073 - val_acc: 0.4900\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4912 - acc: 0.4605 - val_loss: 1.5373 - val_acc: 0.4790\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.4983 - acc: 0.4510 - val_loss: 1.4763 - val_acc: 0.4952\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4628 - acc: 0.4692 - val_loss: 1.4693 - val_acc: 0.5002\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4830 - acc: 0.4625 - val_loss: 1.4908 - val_acc: 0.5028\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4953 - acc: 0.4570 - val_loss: 1.4884 - val_acc: 0.4970\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4387 - acc: 0.4830 - val_loss: 1.5073 - val_acc: 0.4934\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4636 - acc: 0.4715 - val_loss: 1.5024 - val_acc: 0.5018\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4709 - acc: 0.4735 - val_loss: 1.4916 - val_acc: 0.5042\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4695 - acc: 0.4678 - val_loss: 1.5276 - val_acc: 0.4946\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4596 - acc: 0.4760 - val_loss: 1.5197 - val_acc: 0.5090\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4553 - acc: 0.4760 - val_loss: 1.4802 - val_acc: 0.5028\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4497 - acc: 0.4765 - val_loss: 1.5021 - val_acc: 0.4956\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4492 - acc: 0.4758 - val_loss: 1.5153 - val_acc: 0.5038\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4380 - acc: 0.4895 - val_loss: 1.5062 - val_acc: 0.4982\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4462 - acc: 0.4877 - val_loss: 1.4615 - val_acc: 0.5102\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4145 - acc: 0.4907 - val_loss: 1.4792 - val_acc: 0.5014\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4222 - acc: 0.4868 - val_loss: 1.4886 - val_acc: 0.5056\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3945 - acc: 0.4968 - val_loss: 1.5165 - val_acc: 0.5012\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.4176 - acc: 0.4908 - val_loss: 1.5095 - val_acc: 0.5020\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4029 - acc: 0.5005 - val_loss: 1.4713 - val_acc: 0.5084\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3759 - acc: 0.5137 - val_loss: 1.4993 - val_acc: 0.4998\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3931 - acc: 0.5047 - val_loss: 1.6005 - val_acc: 0.4986\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.3969 - acc: 0.4980 - val_loss: 1.4987 - val_acc: 0.5028\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3814 - acc: 0.5118 - val_loss: 1.4900 - val_acc: 0.5168\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.4078 - acc: 0.4895 - val_loss: 1.5007 - val_acc: 0.5090\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3707 - acc: 0.5165 - val_loss: 1.5057 - val_acc: 0.5164\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.3728 - acc: 0.5113 - val_loss: 1.5081 - val_acc: 0.5104\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3798 - acc: 0.5095 - val_loss: 1.5039 - val_acc: 0.5164\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3444 - acc: 0.5263 - val_loss: 1.4992 - val_acc: 0.5148\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3500 - acc: 0.5160 - val_loss: 1.4832 - val_acc: 0.5182\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3781 - acc: 0.5100 - val_loss: 1.5193 - val_acc: 0.5136\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3373 - acc: 0.5355 - val_loss: 1.5520 - val_acc: 0.4850\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3210 - acc: 0.5362 - val_loss: 1.4981 - val_acc: 0.5036\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.3405 - acc: 0.5248 - val_loss: 1.5002 - val_acc: 0.5092\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3481 - acc: 0.5205 - val_loss: 1.5049 - val_acc: 0.5134\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3085 - acc: 0.5435 - val_loss: 1.5079 - val_acc: 0.5074\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2972 - acc: 0.5488 - val_loss: 1.4850 - val_acc: 0.5160\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.3325 - acc: 0.5307 - val_loss: 1.5128 - val_acc: 0.5148\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2968 - acc: 0.5510 - val_loss: 1.5355 - val_acc: 0.5034\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3171 - acc: 0.5403 - val_loss: 1.5079 - val_acc: 0.5142\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3049 - acc: 0.5452 - val_loss: 1.5724 - val_acc: 0.5034\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3030 - acc: 0.5417 - val_loss: 1.5396 - val_acc: 0.4992\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2994 - acc: 0.5420 - val_loss: 1.5233 - val_acc: 0.4978\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.2926 - acc: 0.5443 - val_loss: 1.5119 - val_acc: 0.5112\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2969 - acc: 0.5430 - val_loss: 1.5087 - val_acc: 0.5128\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2846 - acc: 0.5480 - val_loss: 1.5374 - val_acc: 0.5062\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2723 - acc: 0.5492 - val_loss: 1.5449 - val_acc: 0.5074\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2821 - acc: 0.5455 - val_loss: 1.5516 - val_acc: 0.5160\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2578 - acc: 0.5523 - val_loss: 1.4905 - val_acc: 0.5114\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2612 - acc: 0.5595 - val_loss: 1.4876 - val_acc: 0.5062\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.2799 - acc: 0.5473 - val_loss: 1.5104 - val_acc: 0.5144\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2600 - acc: 0.5595 - val_loss: 1.5304 - val_acc: 0.5188\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2540 - acc: 0.5593 - val_loss: 1.5255 - val_acc: 0.5102\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2187 - acc: 0.5833 - val_loss: 1.5153 - val_acc: 0.5178\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2281 - acc: 0.5750 - val_loss: 1.5152 - val_acc: 0.5188\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2276 - acc: 0.5670 - val_loss: 1.5149 - val_acc: 0.5130\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 1.2667 - acc: 0.5505 - val_loss: 1.5027 - val_acc: 0.5146\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.2039 - acc: 0.5853 - val_loss: 1.6238 - val_acc: 0.5104\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.2430 - acc: 0.5720 - val_loss: 1.5056 - val_acc: 0.5084\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.2237 - acc: 0.5773 - val_loss: 1.5246 - val_acc: 0.5160\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1887 - acc: 0.5880 - val_loss: 1.5322 - val_acc: 0.5174\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2130 - acc: 0.5733 - val_loss: 1.5159 - val_acc: 0.5194\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2230 - acc: 0.5800 - val_loss: 1.5337 - val_acc: 0.5152\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1999 - acc: 0.5905 - val_loss: 1.5422 - val_acc: 0.5172\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2244 - acc: 0.5772 - val_loss: 1.5481 - val_acc: 0.5146\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2065 - acc: 0.5767 - val_loss: 1.5577 - val_acc: 0.5190\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2013 - acc: 0.5875 - val_loss: 1.5330 - val_acc: 0.5218\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2114 - acc: 0.5710 - val_loss: 1.5065 - val_acc: 0.5246\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1721 - acc: 0.5860 - val_loss: 1.5170 - val_acc: 0.5170\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.1742 - acc: 0.6077 - val_loss: 1.5384 - val_acc: 0.5176\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1710 - acc: 0.5993 - val_loss: 1.5380 - val_acc: 0.5214\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1536 - acc: 0.6060 - val_loss: 1.6119 - val_acc: 0.5064\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1698 - acc: 0.5965 - val_loss: 1.5784 - val_acc: 0.5204\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.1859 - acc: 0.5900 - val_loss: 1.5920 - val_acc: 0.5128\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1542 - acc: 0.6057 - val_loss: 1.5406 - val_acc: 0.5144\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1538 - acc: 0.5988 - val_loss: 1.5529 - val_acc: 0.5096\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.1632 - acc: 0.6035 - val_loss: 1.5521 - val_acc: 0.5138\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1393 - acc: 0.6175 - val_loss: 1.5466 - val_acc: 0.5146\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1137 - acc: 0.6142 - val_loss: 1.5465 - val_acc: 0.5168\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.1298 - acc: 0.6070 - val_loss: 1.5482 - val_acc: 0.5232\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1131 - acc: 0.6185 - val_loss: 1.5801 - val_acc: 0.5064\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.1607 - acc: 0.6027 - val_loss: 1.5119 - val_acc: 0.5214\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.1188 - acc: 0.6215 - val_loss: 1.5309 - val_acc: 0.5150\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1200 - acc: 0.6208 - val_loss: 1.6081 - val_acc: 0.5026\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.1419 - acc: 0.6115 - val_loss: 1.5620 - val_acc: 0.5218\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.1004 - acc: 0.6312 - val_loss: 1.5275 - val_acc: 0.5180\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.1050 - acc: 0.6215 - val_loss: 1.5383 - val_acc: 0.5056\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.1189 - acc: 0.6225 - val_loss: 1.5963 - val_acc: 0.5114\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0976 - acc: 0.6308 - val_loss: 1.5613 - val_acc: 0.5158\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.1064 - acc: 0.6233 - val_loss: 1.5588 - val_acc: 0.5162\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.1073 - acc: 0.6250 - val_loss: 1.5407 - val_acc: 0.5308\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0805 - acc: 0.6358 - val_loss: 1.5127 - val_acc: 0.5202\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.0956 - acc: 0.6260 - val_loss: 1.5454 - val_acc: 0.5098\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 1.0876 - acc: 0.6305 - val_loss: 1.5637 - val_acc: 0.5232\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0606 - acc: 0.6430 - val_loss: 1.5680 - val_acc: 0.5194\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0616 - acc: 0.6400 - val_loss: 1.6194 - val_acc: 0.4992\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.0504 - acc: 0.6462 - val_loss: 1.5541 - val_acc: 0.5276\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0662 - acc: 0.6443 - val_loss: 1.5661 - val_acc: 0.5130\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.0305 - acc: 0.6505 - val_loss: 1.5426 - val_acc: 0.5210\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.0510 - acc: 0.6487 - val_loss: 1.5348 - val_acc: 0.5274\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0507 - acc: 0.6378 - val_loss: 1.5743 - val_acc: 0.5242\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0343 - acc: 0.6493 - val_loss: 1.5613 - val_acc: 0.5202\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.0170 - acc: 0.6662 - val_loss: 1.5539 - val_acc: 0.5202\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0003 - acc: 0.6608 - val_loss: 1.5561 - val_acc: 0.5138\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0261 - acc: 0.6590 - val_loss: 1.5927 - val_acc: 0.5218\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0139 - acc: 0.6605 - val_loss: 1.5554 - val_acc: 0.5214\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.0368 - acc: 0.6478 - val_loss: 1.5558 - val_acc: 0.5222\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0218 - acc: 0.6575 - val_loss: 1.5597 - val_acc: 0.5234\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0232 - acc: 0.6617 - val_loss: 1.5579 - val_acc: 0.5250\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.9842 - acc: 0.6655 - val_loss: 1.5431 - val_acc: 0.5244\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.0033 - acc: 0.6707 - val_loss: 1.5546 - val_acc: 0.5254\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.0181 - acc: 0.6647 - val_loss: 1.5867 - val_acc: 0.5258\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9851 - acc: 0.6735 - val_loss: 1.5860 - val_acc: 0.5170\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.9982 - acc: 0.6645 - val_loss: 1.5953 - val_acc: 0.5062\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.0205 - acc: 0.6485 - val_loss: 1.6051 - val_acc: 0.5336\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.0025 - acc: 0.6645 - val_loss: 1.5887 - val_acc: 0.5304\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.9610 - acc: 0.6772 - val_loss: 1.5875 - val_acc: 0.5258\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.9921 - acc: 0.6652 - val_loss: 1.5761 - val_acc: 0.5302\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.9686 - acc: 0.6830 - val_loss: 1.5981 - val_acc: 0.5266\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.9632 - acc: 0.6765 - val_loss: 1.5677 - val_acc: 0.5302\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9618 - acc: 0.6810 - val_loss: 1.5606 - val_acc: 0.5228\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9490 - acc: 0.6845 - val_loss: 1.5503 - val_acc: 0.5268\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9439 - acc: 0.6880 - val_loss: 1.6165 - val_acc: 0.5078\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.9798 - acc: 0.6683 - val_loss: 1.5559 - val_acc: 0.5222\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9395 - acc: 0.6910 - val_loss: 1.5977 - val_acc: 0.5278\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9601 - acc: 0.6812 - val_loss: 1.5529 - val_acc: 0.5252\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.9441 - acc: 0.6953 - val_loss: 1.5602 - val_acc: 0.5174\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.9415 - acc: 0.6847 - val_loss: 1.6162 - val_acc: 0.5152\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9166 - acc: 0.6993 - val_loss: 1.5913 - val_acc: 0.5190\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.9329 - acc: 0.6947 - val_loss: 1.5619 - val_acc: 0.5230\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9296 - acc: 0.6885 - val_loss: 1.6595 - val_acc: 0.5198\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.9358 - acc: 0.6922 - val_loss: 1.6171 - val_acc: 0.5312\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9196 - acc: 0.6953 - val_loss: 1.6576 - val_acc: 0.5138\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.8865 - acc: 0.7053 - val_loss: 1.6085 - val_acc: 0.5198\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9178 - acc: 0.6995 - val_loss: 1.5680 - val_acc: 0.5298\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9132 - acc: 0.6998 - val_loss: 1.5800 - val_acc: 0.5206\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.9023 - acc: 0.7115 - val_loss: 1.6572 - val_acc: 0.5160\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9004 - acc: 0.7092 - val_loss: 1.5871 - val_acc: 0.5294\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.8746 - acc: 0.7095 - val_loss: 1.5952 - val_acc: 0.5258\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.8868 - acc: 0.7008 - val_loss: 1.5652 - val_acc: 0.5254\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.8893 - acc: 0.7153 - val_loss: 1.5755 - val_acc: 0.5264\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8770 - acc: 0.7042 - val_loss: 1.6317 - val_acc: 0.5152\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.8758 - acc: 0.7087 - val_loss: 1.6369 - val_acc: 0.5200\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.8558 - acc: 0.7180 - val_loss: 1.6647 - val_acc: 0.5138\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.8817 - acc: 0.7078 - val_loss: 1.5713 - val_acc: 0.5238\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.8511 - acc: 0.7310 - val_loss: 1.6135 - val_acc: 0.5184\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.8623 - acc: 0.7237 - val_loss: 1.5896 - val_acc: 0.5284\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8629 - acc: 0.7115 - val_loss: 1.5760 - val_acc: 0.5286\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.8530 - acc: 0.7272 - val_loss: 1.5751 - val_acc: 0.5192\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.8712 - acc: 0.7145 - val_loss: 1.5957 - val_acc: 0.5254\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.8604 - acc: 0.7145 - val_loss: 1.5943 - val_acc: 0.5254\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8296 - acc: 0.7330 - val_loss: 1.5893 - val_acc: 0.5310\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8511 - acc: 0.7180 - val_loss: 1.6028 - val_acc: 0.5266\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8447 - acc: 0.7205 - val_loss: 1.5869 - val_acc: 0.5190\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8412 - acc: 0.7180 - val_loss: 1.6048 - val_acc: 0.5182\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.8392 - acc: 0.7192 - val_loss: 1.5689 - val_acc: 0.5296\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.8034 - acc: 0.7345 - val_loss: 1.5736 - val_acc: 0.5234\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8227 - acc: 0.7308 - val_loss: 1.6511 - val_acc: 0.5198\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8082 - acc: 0.7350 - val_loss: 1.6218 - val_acc: 0.5318\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.8278 - acc: 0.7265 - val_loss: 1.6375 - val_acc: 0.5300\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8281 - acc: 0.7260 - val_loss: 1.5917 - val_acc: 0.5364\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8285 - acc: 0.7235 - val_loss: 1.6695 - val_acc: 0.5164\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.8283 - acc: 0.7285 - val_loss: 1.6999 - val_acc: 0.5226\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.8012 - acc: 0.7303 - val_loss: 1.6107 - val_acc: 0.5268\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 0.7941 - acc: 0.7360 - val_loss: 1.5895 - val_acc: 0.5294\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.7689 - acc: 0.7527 - val_loss: 1.6339 - val_acc: 0.5120\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.7841 - acc: 0.7460 - val_loss: 1.6123 - val_acc: 0.5292\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7715 - acc: 0.7438 - val_loss: 1.6502 - val_acc: 0.5314\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7835 - acc: 0.7433 - val_loss: 1.5879 - val_acc: 0.5286\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7889 - acc: 0.7397 - val_loss: 1.5922 - val_acc: 0.5336\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.7736 - acc: 0.7492 - val_loss: 1.6100 - val_acc: 0.5336\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7778 - acc: 0.7430 - val_loss: 1.6069 - val_acc: 0.5236\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7398 - acc: 0.7580 - val_loss: 1.6080 - val_acc: 0.5212\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.7647 - acc: 0.7517 - val_loss: 1.5893 - val_acc: 0.5330\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.7569 - acc: 0.7598 - val_loss: 1.6075 - val_acc: 0.5246\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7521 - acc: 0.7558 - val_loss: 1.6343 - val_acc: 0.5270\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.7515 - acc: 0.7570 - val_loss: 1.5796 - val_acc: 0.5264\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.7791 - acc: 0.7467 - val_loss: 1.6062 - val_acc: 0.5238\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.7581 - acc: 0.7527 - val_loss: 1.6218 - val_acc: 0.5244\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 0.7225 - acc: 0.7687 - val_loss: 1.5809 - val_acc: 0.5236\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7490 - acc: 0.7572 - val_loss: 1.6015 - val_acc: 0.5218\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.7269 - acc: 0.7638 - val_loss: 1.6091 - val_acc: 0.5258\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.7197 - acc: 0.7703 - val_loss: 1.6071 - val_acc: 0.5336\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7152 - acc: 0.7692 - val_loss: 1.6166 - val_acc: 0.5298\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 0.6998 - acc: 0.7707 - val_loss: 1.5874 - val_acc: 0.5268\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.7376 - acc: 0.7552 - val_loss: 1.6087 - val_acc: 0.5190\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.7068 - acc: 0.7675 - val_loss: 1.6256 - val_acc: 0.5320\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.7081 - acc: 0.7725 - val_loss: 1.6371 - val_acc: 0.5256\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.7349 - acc: 0.7530 - val_loss: 1.5880 - val_acc: 0.5268\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 0.6941 - acc: 0.7725 - val_loss: 1.6161 - val_acc: 0.5260\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.7098 - acc: 0.7695 - val_loss: 1.6689 - val_acc: 0.5330\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.7113 - acc: 0.7660 - val_loss: 1.6240 - val_acc: 0.5284\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.7214 - acc: 0.7635 - val_loss: 1.6529 - val_acc: 0.5270\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 0.7168 - acc: 0.7665 - val_loss: 1.6874 - val_acc: 0.5186\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 0.7048 - acc: 0.7638 - val_loss: 1.6246 - val_acc: 0.5350\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.7111 - acc: 0.7657 - val_loss: 1.6234 - val_acc: 0.5374\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6791 - acc: 0.7835 - val_loss: 1.6570 - val_acc: 0.5318\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.7104 - acc: 0.7630 - val_loss: 1.5989 - val_acc: 0.5314\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6865 - acc: 0.7802 - val_loss: 1.6319 - val_acc: 0.5350\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.6531 - acc: 0.7890 - val_loss: 1.6648 - val_acc: 0.5304\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.6612 - acc: 0.7820 - val_loss: 1.6270 - val_acc: 0.5310\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.6929 - acc: 0.7725 - val_loss: 1.6954 - val_acc: 0.5236\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 0.6551 - acc: 0.7892 - val_loss: 1.6452 - val_acc: 0.5228\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.6654 - acc: 0.7833 - val_loss: 1.6437 - val_acc: 0.5304\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.6705 - acc: 0.7757 - val_loss: 1.6819 - val_acc: 0.5214\n",
            "Test accuracy: 0.523 (elaspsed time: 483s)\n",
            "Accuracy\n",
            "airplane 0.563\n",
            "auto 0.624\n",
            "bird 0.281\n",
            "cat 0.341\n",
            "deer 0.501\n",
            "dog 0.539\n",
            "frog 0.507\n",
            "horse 0.677\n",
            "ship 0.616\n",
            "truck 0.577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N_JBa6IgzuWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "605c7094-2dca-43e5-8ee8-a4fcc32c2e1a"
      },
      "cell_type": "code",
      "source": [
        "# Try one to see how many epochs to try... \n",
        "op = opmap['TranslateY']\n",
        "\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug_translate_y = autoaugment(transform, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_translate_y = create_model(X_reduced, 10)\n",
        "model_translate_y.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_translate_y, aug_translate_y, 300)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 2.3039 - acc: 0.1963 - val_loss: 1.8583 - val_acc: 0.3602\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 2.2109 - acc: 0.1935 - val_loss: 1.8352 - val_acc: 0.3740\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.1824 - acc: 0.2130 - val_loss: 1.8095 - val_acc: 0.3714\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.1750 - acc: 0.2078 - val_loss: 1.8254 - val_acc: 0.3576\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.1477 - acc: 0.2033 - val_loss: 1.7976 - val_acc: 0.3682\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.1229 - acc: 0.2260 - val_loss: 1.7654 - val_acc: 0.3856\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 2.1294 - acc: 0.2178 - val_loss: 1.7535 - val_acc: 0.3846\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 2.0786 - acc: 0.2290 - val_loss: 1.7446 - val_acc: 0.3884\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 2.0978 - acc: 0.2305 - val_loss: 1.7327 - val_acc: 0.3954\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.0609 - acc: 0.2290 - val_loss: 1.7306 - val_acc: 0.3908\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.0902 - acc: 0.2355 - val_loss: 1.7527 - val_acc: 0.3922\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 2.0567 - acc: 0.2285 - val_loss: 1.7357 - val_acc: 0.3910\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0452 - acc: 0.2400 - val_loss: 1.6934 - val_acc: 0.4014\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0324 - acc: 0.2413 - val_loss: 1.6965 - val_acc: 0.4052\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 2.0403 - acc: 0.2443 - val_loss: 1.6848 - val_acc: 0.4024\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.0177 - acc: 0.2460 - val_loss: 1.6893 - val_acc: 0.4036\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 2.0305 - acc: 0.2460 - val_loss: 1.6973 - val_acc: 0.4134\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9888 - acc: 0.2535 - val_loss: 1.6489 - val_acc: 0.4204\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.0025 - acc: 0.2628 - val_loss: 1.6643 - val_acc: 0.4160\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0000 - acc: 0.2492 - val_loss: 1.6624 - val_acc: 0.4160\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.9746 - acc: 0.2673 - val_loss: 1.6351 - val_acc: 0.4242\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9634 - acc: 0.2635 - val_loss: 1.6493 - val_acc: 0.4160\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.9850 - acc: 0.2600 - val_loss: 1.6512 - val_acc: 0.4210\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9453 - acc: 0.2765 - val_loss: 1.6496 - val_acc: 0.4190\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.9534 - acc: 0.2682 - val_loss: 1.6210 - val_acc: 0.4342\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9462 - acc: 0.2705 - val_loss: 1.6200 - val_acc: 0.4274\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.9360 - acc: 0.2728 - val_loss: 1.6253 - val_acc: 0.4290\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9213 - acc: 0.2760 - val_loss: 1.6066 - val_acc: 0.4396\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.9494 - acc: 0.2708 - val_loss: 1.6046 - val_acc: 0.4284\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.9175 - acc: 0.2793 - val_loss: 1.6056 - val_acc: 0.4350\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8883 - acc: 0.2945 - val_loss: 1.6072 - val_acc: 0.4296\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8907 - acc: 0.2940 - val_loss: 1.6229 - val_acc: 0.4266\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8632 - acc: 0.2978 - val_loss: 1.5886 - val_acc: 0.4402\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8815 - acc: 0.2860 - val_loss: 1.5870 - val_acc: 0.4446\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8610 - acc: 0.2980 - val_loss: 1.5807 - val_acc: 0.4414\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8802 - acc: 0.2933 - val_loss: 1.5963 - val_acc: 0.4252\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.8768 - acc: 0.3088 - val_loss: 1.5644 - val_acc: 0.4426\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8674 - acc: 0.3008 - val_loss: 1.5660 - val_acc: 0.4382\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.8319 - acc: 0.3148 - val_loss: 1.5767 - val_acc: 0.4436\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8383 - acc: 0.3073 - val_loss: 1.5502 - val_acc: 0.4494\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.8381 - acc: 0.3135 - val_loss: 1.5489 - val_acc: 0.4540\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.8246 - acc: 0.3110 - val_loss: 1.5678 - val_acc: 0.4488\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8050 - acc: 0.3190 - val_loss: 1.5393 - val_acc: 0.4536\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8323 - acc: 0.3058 - val_loss: 1.5340 - val_acc: 0.4538\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.8096 - acc: 0.3165 - val_loss: 1.5740 - val_acc: 0.4502\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.8133 - acc: 0.3150 - val_loss: 1.5556 - val_acc: 0.4476\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.7853 - acc: 0.3293 - val_loss: 1.5566 - val_acc: 0.4532\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7895 - acc: 0.3243 - val_loss: 1.5737 - val_acc: 0.4456\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.7763 - acc: 0.3360 - val_loss: 1.5719 - val_acc: 0.4522\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7748 - acc: 0.3333 - val_loss: 1.5428 - val_acc: 0.4598\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7543 - acc: 0.3405 - val_loss: 1.5514 - val_acc: 0.4556\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7656 - acc: 0.3355 - val_loss: 1.5473 - val_acc: 0.4538\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.7777 - acc: 0.3338 - val_loss: 1.5270 - val_acc: 0.4632\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7567 - acc: 0.3430 - val_loss: 1.5462 - val_acc: 0.4562\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7332 - acc: 0.3383 - val_loss: 1.5247 - val_acc: 0.4670\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7564 - acc: 0.3397 - val_loss: 1.5618 - val_acc: 0.4626\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7388 - acc: 0.3405 - val_loss: 1.5409 - val_acc: 0.4656\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7281 - acc: 0.3450 - val_loss: 1.5374 - val_acc: 0.4598\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7123 - acc: 0.3573 - val_loss: 1.5979 - val_acc: 0.4438\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.7521 - acc: 0.3397 - val_loss: 1.5268 - val_acc: 0.4662\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7044 - acc: 0.3590 - val_loss: 1.5294 - val_acc: 0.4756\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.7149 - acc: 0.3500 - val_loss: 1.5158 - val_acc: 0.4690\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7085 - acc: 0.3565 - val_loss: 1.5157 - val_acc: 0.4700\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6876 - acc: 0.3690 - val_loss: 1.5235 - val_acc: 0.4684\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6971 - acc: 0.3702 - val_loss: 1.5549 - val_acc: 0.4580\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6744 - acc: 0.3765 - val_loss: 1.5523 - val_acc: 0.4548\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6584 - acc: 0.3705 - val_loss: 1.5046 - val_acc: 0.4744\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6713 - acc: 0.3688 - val_loss: 1.5158 - val_acc: 0.4732\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.6934 - acc: 0.3655 - val_loss: 1.5269 - val_acc: 0.4762\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.6777 - acc: 0.3605 - val_loss: 1.5228 - val_acc: 0.4766\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6853 - acc: 0.3647 - val_loss: 1.5209 - val_acc: 0.4696\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6507 - acc: 0.3910 - val_loss: 1.5081 - val_acc: 0.4800\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6643 - acc: 0.3752 - val_loss: 1.5081 - val_acc: 0.4760\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6259 - acc: 0.3860 - val_loss: 1.5309 - val_acc: 0.4792\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6489 - acc: 0.3810 - val_loss: 1.5237 - val_acc: 0.4730\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6419 - acc: 0.3835 - val_loss: 1.5313 - val_acc: 0.4714\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6359 - acc: 0.3885 - val_loss: 1.5150 - val_acc: 0.4850\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6222 - acc: 0.3885 - val_loss: 1.5541 - val_acc: 0.4690\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.6122 - acc: 0.4020 - val_loss: 1.5361 - val_acc: 0.4676\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6275 - acc: 0.3905 - val_loss: 1.5196 - val_acc: 0.4756\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6016 - acc: 0.4025 - val_loss: 1.5415 - val_acc: 0.4792\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6165 - acc: 0.3890 - val_loss: 1.5004 - val_acc: 0.4854\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5721 - acc: 0.4085 - val_loss: 1.4921 - val_acc: 0.4854\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6013 - acc: 0.4035 - val_loss: 1.5074 - val_acc: 0.4818\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.5904 - acc: 0.4078 - val_loss: 1.5017 - val_acc: 0.4906\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5803 - acc: 0.4073 - val_loss: 1.5193 - val_acc: 0.4776\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5891 - acc: 0.4050 - val_loss: 1.5098 - val_acc: 0.4844\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5955 - acc: 0.4065 - val_loss: 1.5102 - val_acc: 0.4920\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5789 - acc: 0.4115 - val_loss: 1.5182 - val_acc: 0.4882\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.5922 - acc: 0.4053 - val_loss: 1.5268 - val_acc: 0.4868\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5773 - acc: 0.4098 - val_loss: 1.5471 - val_acc: 0.4736\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5350 - acc: 0.4207 - val_loss: 1.5247 - val_acc: 0.4938\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5309 - acc: 0.4315 - val_loss: 1.5224 - val_acc: 0.4968\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5162 - acc: 0.4315 - val_loss: 1.5252 - val_acc: 0.4880\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.5574 - acc: 0.4113 - val_loss: 1.5200 - val_acc: 0.4954\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.5361 - acc: 0.4225 - val_loss: 1.5229 - val_acc: 0.4872\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5443 - acc: 0.4225 - val_loss: 1.5315 - val_acc: 0.4932\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5241 - acc: 0.4297 - val_loss: 1.5720 - val_acc: 0.4954\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5274 - acc: 0.4290 - val_loss: 1.5045 - val_acc: 0.4974\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5125 - acc: 0.4400 - val_loss: 1.5175 - val_acc: 0.4944\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5433 - acc: 0.4208 - val_loss: 1.5071 - val_acc: 0.4980\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5411 - acc: 0.4232 - val_loss: 1.5368 - val_acc: 0.4964\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5174 - acc: 0.4287 - val_loss: 1.5303 - val_acc: 0.4950\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.5355 - acc: 0.4348 - val_loss: 1.5641 - val_acc: 0.4842\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5167 - acc: 0.4362 - val_loss: 1.5243 - val_acc: 0.4962\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.5036 - acc: 0.4372 - val_loss: 1.5393 - val_acc: 0.4922\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.5198 - acc: 0.4280 - val_loss: 1.5105 - val_acc: 0.5064\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 1.5028 - acc: 0.4420 - val_loss: 1.5094 - val_acc: 0.5036\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4830 - acc: 0.4480 - val_loss: 1.5286 - val_acc: 0.4928\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4941 - acc: 0.4413 - val_loss: 1.5184 - val_acc: 0.5064\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4921 - acc: 0.4453 - val_loss: 1.6155 - val_acc: 0.4800\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4590 - acc: 0.4653 - val_loss: 1.5290 - val_acc: 0.5038\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4496 - acc: 0.4595 - val_loss: 1.5231 - val_acc: 0.4996\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4793 - acc: 0.4445 - val_loss: 1.5097 - val_acc: 0.4948\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.5009 - acc: 0.4513 - val_loss: 1.5149 - val_acc: 0.4998\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.4546 - acc: 0.4600 - val_loss: 1.5134 - val_acc: 0.5070\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4290 - acc: 0.4730 - val_loss: 1.5224 - val_acc: 0.4948\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4444 - acc: 0.4678 - val_loss: 1.5603 - val_acc: 0.4990\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4377 - acc: 0.4665 - val_loss: 1.5518 - val_acc: 0.5056\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4320 - acc: 0.4580 - val_loss: 1.5158 - val_acc: 0.5014\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.4491 - acc: 0.4700 - val_loss: 1.5316 - val_acc: 0.5054\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.4427 - acc: 0.4615 - val_loss: 1.5293 - val_acc: 0.5034\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4393 - acc: 0.4643 - val_loss: 1.5277 - val_acc: 0.5042\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4150 - acc: 0.4845 - val_loss: 1.5437 - val_acc: 0.4956\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3997 - acc: 0.4867 - val_loss: 1.5227 - val_acc: 0.5076\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4435 - acc: 0.4643 - val_loss: 1.5097 - val_acc: 0.5080\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4339 - acc: 0.4658 - val_loss: 1.5714 - val_acc: 0.5060\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4292 - acc: 0.4692 - val_loss: 1.5570 - val_acc: 0.5112\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4037 - acc: 0.4865 - val_loss: 1.6267 - val_acc: 0.5062\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4074 - acc: 0.4750 - val_loss: 1.5044 - val_acc: 0.5152\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.4108 - acc: 0.4847 - val_loss: 1.5526 - val_acc: 0.5110\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4147 - acc: 0.4810 - val_loss: 1.5806 - val_acc: 0.5088\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4177 - acc: 0.4817 - val_loss: 1.5511 - val_acc: 0.5128\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4005 - acc: 0.4770 - val_loss: 1.6068 - val_acc: 0.5088\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3981 - acc: 0.4758 - val_loss: 1.5303 - val_acc: 0.5190\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3979 - acc: 0.4898 - val_loss: 1.5748 - val_acc: 0.5052\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3977 - acc: 0.4842 - val_loss: 1.6031 - val_acc: 0.5044\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4040 - acc: 0.4830 - val_loss: 1.5390 - val_acc: 0.5118\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3753 - acc: 0.5000 - val_loss: 1.6375 - val_acc: 0.5054\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3825 - acc: 0.4958 - val_loss: 1.5418 - val_acc: 0.5150\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3740 - acc: 0.4925 - val_loss: 1.5479 - val_acc: 0.5062\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3703 - acc: 0.5055 - val_loss: 1.5759 - val_acc: 0.5154\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3766 - acc: 0.4937 - val_loss: 1.5555 - val_acc: 0.5134\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3915 - acc: 0.4895 - val_loss: 1.5599 - val_acc: 0.5092\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3588 - acc: 0.4943 - val_loss: 1.5563 - val_acc: 0.5104\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3554 - acc: 0.5040 - val_loss: 1.5718 - val_acc: 0.5142\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3716 - acc: 0.4910 - val_loss: 1.5649 - val_acc: 0.5166\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3615 - acc: 0.5063 - val_loss: 1.5846 - val_acc: 0.5160\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3465 - acc: 0.5105 - val_loss: 1.5906 - val_acc: 0.5082\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3417 - acc: 0.5095 - val_loss: 1.5612 - val_acc: 0.5190\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 1.3660 - acc: 0.5010 - val_loss: 1.5731 - val_acc: 0.5176\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3707 - acc: 0.5035 - val_loss: 1.5642 - val_acc: 0.5168\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3662 - acc: 0.4983 - val_loss: 1.5903 - val_acc: 0.5168\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3147 - acc: 0.5158 - val_loss: 1.5946 - val_acc: 0.5088\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3072 - acc: 0.5238 - val_loss: 1.5580 - val_acc: 0.5148\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3316 - acc: 0.5148 - val_loss: 1.5658 - val_acc: 0.5122\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3370 - acc: 0.5062 - val_loss: 1.5443 - val_acc: 0.5172\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3364 - acc: 0.5098 - val_loss: 1.5910 - val_acc: 0.5206\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3425 - acc: 0.5078 - val_loss: 1.5686 - val_acc: 0.5156\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3239 - acc: 0.5187 - val_loss: 1.5871 - val_acc: 0.5210\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3331 - acc: 0.5130 - val_loss: 1.5343 - val_acc: 0.5232\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3348 - acc: 0.5113 - val_loss: 1.6065 - val_acc: 0.5054\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.3369 - acc: 0.5100 - val_loss: 1.5708 - val_acc: 0.5100\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2979 - acc: 0.5270 - val_loss: 1.5315 - val_acc: 0.5228\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 1.3396 - acc: 0.5188 - val_loss: 1.5168 - val_acc: 0.5250\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3185 - acc: 0.5183 - val_loss: 1.5939 - val_acc: 0.5242\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3227 - acc: 0.5118 - val_loss: 1.5745 - val_acc: 0.5212\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3171 - acc: 0.5265 - val_loss: 1.5773 - val_acc: 0.5242\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3115 - acc: 0.5240 - val_loss: 1.5938 - val_acc: 0.5212\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2854 - acc: 0.5330 - val_loss: 1.5901 - val_acc: 0.5230\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2826 - acc: 0.5300 - val_loss: 1.5947 - val_acc: 0.5218\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2901 - acc: 0.5325 - val_loss: 1.6156 - val_acc: 0.5234\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3159 - acc: 0.5225 - val_loss: 1.6147 - val_acc: 0.5248\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2762 - acc: 0.5383 - val_loss: 1.6377 - val_acc: 0.5212\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2936 - acc: 0.5393 - val_loss: 1.6036 - val_acc: 0.5174\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.3160 - acc: 0.5262 - val_loss: 1.6204 - val_acc: 0.5174\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2704 - acc: 0.5397 - val_loss: 1.5793 - val_acc: 0.5200\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2590 - acc: 0.5450 - val_loss: 1.6051 - val_acc: 0.5226\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2978 - acc: 0.5348 - val_loss: 1.5897 - val_acc: 0.5134\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2655 - acc: 0.5420 - val_loss: 1.5780 - val_acc: 0.5188\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2627 - acc: 0.5470 - val_loss: 1.5855 - val_acc: 0.5172\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2916 - acc: 0.5325 - val_loss: 1.5834 - val_acc: 0.5222\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2573 - acc: 0.5495 - val_loss: 1.5776 - val_acc: 0.5196\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2712 - acc: 0.5367 - val_loss: 1.6448 - val_acc: 0.5202\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2789 - acc: 0.5358 - val_loss: 1.5822 - val_acc: 0.5126\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2762 - acc: 0.5465 - val_loss: 1.6370 - val_acc: 0.5242\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2577 - acc: 0.5428 - val_loss: 1.6220 - val_acc: 0.5180\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2857 - acc: 0.5355 - val_loss: 1.6242 - val_acc: 0.5220\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2509 - acc: 0.5488 - val_loss: 1.6268 - val_acc: 0.5180\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.2805 - acc: 0.5360 - val_loss: 1.5803 - val_acc: 0.5208\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2361 - acc: 0.5535 - val_loss: 1.5844 - val_acc: 0.5292\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2564 - acc: 0.5462 - val_loss: 1.6489 - val_acc: 0.5068\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2433 - acc: 0.5505 - val_loss: 1.6125 - val_acc: 0.5158\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2466 - acc: 0.5560 - val_loss: 1.6549 - val_acc: 0.5180\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2613 - acc: 0.5435 - val_loss: 1.6203 - val_acc: 0.5252\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2650 - acc: 0.5403 - val_loss: 1.6337 - val_acc: 0.5284\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2734 - acc: 0.5392 - val_loss: 1.6557 - val_acc: 0.5164\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2311 - acc: 0.5567 - val_loss: 1.5908 - val_acc: 0.5242\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2262 - acc: 0.5630 - val_loss: 1.6002 - val_acc: 0.5284\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2291 - acc: 0.5572 - val_loss: 1.6267 - val_acc: 0.5262\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2681 - acc: 0.5448 - val_loss: 1.6233 - val_acc: 0.5206\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2285 - acc: 0.5618 - val_loss: 1.5995 - val_acc: 0.5258\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2188 - acc: 0.5667 - val_loss: 1.5773 - val_acc: 0.5314\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2034 - acc: 0.5695 - val_loss: 1.6460 - val_acc: 0.5284\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2424 - acc: 0.5550 - val_loss: 1.6281 - val_acc: 0.5326\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2200 - acc: 0.5680 - val_loss: 1.6421 - val_acc: 0.5318\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.2362 - acc: 0.5575 - val_loss: 1.7767 - val_acc: 0.5058\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2230 - acc: 0.5665 - val_loss: 1.6280 - val_acc: 0.5296\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2253 - acc: 0.5612 - val_loss: 1.6097 - val_acc: 0.5308\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2222 - acc: 0.5663 - val_loss: 1.5889 - val_acc: 0.5298\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1738 - acc: 0.5780 - val_loss: 1.6775 - val_acc: 0.5300\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2152 - acc: 0.5630 - val_loss: 1.5917 - val_acc: 0.5272\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2236 - acc: 0.5635 - val_loss: 1.5948 - val_acc: 0.5240\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.1989 - acc: 0.5750 - val_loss: 1.6623 - val_acc: 0.5308\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1928 - acc: 0.5772 - val_loss: 1.5913 - val_acc: 0.5258\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.2346 - acc: 0.5578 - val_loss: 1.6008 - val_acc: 0.5198\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1637 - acc: 0.5940 - val_loss: 1.6206 - val_acc: 0.5268\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2112 - acc: 0.5703 - val_loss: 1.7035 - val_acc: 0.5182\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1812 - acc: 0.5792 - val_loss: 1.6690 - val_acc: 0.5192\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1910 - acc: 0.5732 - val_loss: 1.6742 - val_acc: 0.5176\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1956 - acc: 0.5818 - val_loss: 1.6305 - val_acc: 0.5278\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2311 - acc: 0.5695 - val_loss: 1.6062 - val_acc: 0.5358\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.1948 - acc: 0.5805 - val_loss: 1.6572 - val_acc: 0.5274\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2048 - acc: 0.5673 - val_loss: 1.6833 - val_acc: 0.5230\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1870 - acc: 0.5825 - val_loss: 1.6730 - val_acc: 0.5144\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1830 - acc: 0.5750 - val_loss: 1.6909 - val_acc: 0.5252\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1908 - acc: 0.5825 - val_loss: 1.6987 - val_acc: 0.5242\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1840 - acc: 0.5732 - val_loss: 1.6392 - val_acc: 0.5352\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.1928 - acc: 0.5765 - val_loss: 1.6420 - val_acc: 0.5252\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2006 - acc: 0.5700 - val_loss: 1.6602 - val_acc: 0.5226\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1519 - acc: 0.5957 - val_loss: 1.6485 - val_acc: 0.5304\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1592 - acc: 0.5873 - val_loss: 1.6548 - val_acc: 0.5342\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1860 - acc: 0.5847 - val_loss: 1.6913 - val_acc: 0.5210\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1502 - acc: 0.5963 - val_loss: 1.6320 - val_acc: 0.5274\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1586 - acc: 0.5935 - val_loss: 1.6646 - val_acc: 0.5270\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1541 - acc: 0.5917 - val_loss: 1.6319 - val_acc: 0.5350\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2040 - acc: 0.5778 - val_loss: 1.6722 - val_acc: 0.5208\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1823 - acc: 0.5800 - val_loss: 1.6832 - val_acc: 0.5250\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1286 - acc: 0.6063 - val_loss: 1.6635 - val_acc: 0.5306\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1688 - acc: 0.5898 - val_loss: 1.6255 - val_acc: 0.5288\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1636 - acc: 0.5868 - val_loss: 1.6482 - val_acc: 0.5286\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1406 - acc: 0.6045 - val_loss: 1.6734 - val_acc: 0.5306\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1532 - acc: 0.5925 - val_loss: 1.6387 - val_acc: 0.5324\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1575 - acc: 0.6012 - val_loss: 1.6669 - val_acc: 0.5296\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1301 - acc: 0.6070 - val_loss: 1.7010 - val_acc: 0.5296\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1492 - acc: 0.5932 - val_loss: 1.6110 - val_acc: 0.5380\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.1733 - acc: 0.5800 - val_loss: 1.6924 - val_acc: 0.5326\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1542 - acc: 0.5880 - val_loss: 1.6520 - val_acc: 0.5362\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1498 - acc: 0.5950 - val_loss: 1.6337 - val_acc: 0.5318\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1225 - acc: 0.6040 - val_loss: 1.7028 - val_acc: 0.5326\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1141 - acc: 0.6065 - val_loss: 1.6580 - val_acc: 0.5294\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1507 - acc: 0.5970 - val_loss: 1.6978 - val_acc: 0.5300\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1123 - acc: 0.6078 - val_loss: 1.6655 - val_acc: 0.5366\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1200 - acc: 0.6073 - val_loss: 1.6723 - val_acc: 0.5334\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1374 - acc: 0.6017 - val_loss: 1.7475 - val_acc: 0.5204\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1185 - acc: 0.6065 - val_loss: 1.6570 - val_acc: 0.5284\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1190 - acc: 0.6102 - val_loss: 1.6685 - val_acc: 0.5318\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1109 - acc: 0.6153 - val_loss: 1.6927 - val_acc: 0.5186\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.1486 - acc: 0.5950 - val_loss: 1.6572 - val_acc: 0.5368\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.1489 - acc: 0.5948 - val_loss: 1.7642 - val_acc: 0.5266\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1460 - acc: 0.5975 - val_loss: 1.6489 - val_acc: 0.5332\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1131 - acc: 0.6122 - val_loss: 1.6888 - val_acc: 0.5352\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1345 - acc: 0.5988 - val_loss: 1.7320 - val_acc: 0.5226\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1162 - acc: 0.6098 - val_loss: 1.7304 - val_acc: 0.5340\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1114 - acc: 0.6070 - val_loss: 1.7145 - val_acc: 0.5346\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1131 - acc: 0.6090 - val_loss: 1.7271 - val_acc: 0.5284\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1136 - acc: 0.6025 - val_loss: 1.6866 - val_acc: 0.5310\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.1408 - acc: 0.5997 - val_loss: 1.6838 - val_acc: 0.5322\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1083 - acc: 0.6147 - val_loss: 1.6606 - val_acc: 0.5350\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.0623 - acc: 0.6330 - val_loss: 1.8060 - val_acc: 0.5186\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0842 - acc: 0.6207 - val_loss: 1.6965 - val_acc: 0.5402\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1158 - acc: 0.6033 - val_loss: 1.6757 - val_acc: 0.5274\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.0847 - acc: 0.6180 - val_loss: 1.6647 - val_acc: 0.5366\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 1.1681 - acc: 0.5877 - val_loss: 1.6714 - val_acc: 0.5404\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.1180 - acc: 0.6087 - val_loss: 1.8499 - val_acc: 0.5068\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1071 - acc: 0.6095 - val_loss: 1.6868 - val_acc: 0.5358\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.1296 - acc: 0.5997 - val_loss: 1.7449 - val_acc: 0.5264\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.1081 - acc: 0.6062 - val_loss: 1.6889 - val_acc: 0.5340\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0871 - acc: 0.6295 - val_loss: 1.6853 - val_acc: 0.5308\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.0842 - acc: 0.6233 - val_loss: 1.6468 - val_acc: 0.5340\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0899 - acc: 0.6247 - val_loss: 1.6799 - val_acc: 0.5298\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0788 - acc: 0.6220 - val_loss: 1.6992 - val_acc: 0.5240\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.0784 - acc: 0.6235 - val_loss: 1.6984 - val_acc: 0.5292\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.0399 - acc: 0.6355 - val_loss: 1.6762 - val_acc: 0.5310\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0942 - acc: 0.6225 - val_loss: 1.6584 - val_acc: 0.5328\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0594 - acc: 0.6370 - val_loss: 1.6868 - val_acc: 0.5330\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0748 - acc: 0.6215 - val_loss: 1.7340 - val_acc: 0.5324\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.0818 - acc: 0.6270 - val_loss: 1.7082 - val_acc: 0.5326\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0698 - acc: 0.6265 - val_loss: 1.6887 - val_acc: 0.5332\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0863 - acc: 0.6273 - val_loss: 1.8396 - val_acc: 0.5118\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0860 - acc: 0.6253 - val_loss: 1.6857 - val_acc: 0.5334\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0678 - acc: 0.6315 - val_loss: 1.7711 - val_acc: 0.5182\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.0919 - acc: 0.6240 - val_loss: 1.6618 - val_acc: 0.5394\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0780 - acc: 0.6238 - val_loss: 1.6595 - val_acc: 0.5340\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0597 - acc: 0.6350 - val_loss: 1.6833 - val_acc: 0.5352\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0524 - acc: 0.6370 - val_loss: 1.6735 - val_acc: 0.5316\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0384 - acc: 0.6438 - val_loss: 1.7108 - val_acc: 0.5332\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.0484 - acc: 0.6350 - val_loss: 1.6975 - val_acc: 0.5338\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.0539 - acc: 0.6322 - val_loss: 1.7170 - val_acc: 0.5266\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.0581 - acc: 0.6375 - val_loss: 1.7071 - val_acc: 0.5274\n",
            "Test accuracy: 0.525 (elaspsed time: 485s)\n",
            "Accuracy\n",
            "airplane 0.66\n",
            "auto 0.734\n",
            "bird 0.329\n",
            "cat 0.339\n",
            "deer 0.369\n",
            "dog 0.401\n",
            "frog 0.753\n",
            "horse 0.597\n",
            "ship 0.571\n",
            "truck 0.499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WbttEZP0_Qlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "be0c7125-e282-4ab3-ac43-16d47a036a7b"
      },
      "cell_type": "code",
      "source": [
        "# How about combining two transforms that increased accuracy (AND)?\n",
        "op1 = opmap['TranslateY']\n",
        "op2 = opmap['Flip_LR']\n",
        "# 50% prob of transform\n",
        "ops = [Operation(([op1] * 10, 5), 0.5), Operation(([op2] * 10, 5), 0.5)]\n",
        "transform = [Transform(*ops)]\n",
        "\n",
        "aug_2_tform = autoaugment(transform, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_2_tform= create_model(X_reduced, 10)\n",
        "model_2_tform.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_2_tform, aug_2_tform, 300)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 8s 526ms/step - loss: 2.4575 - acc: 0.1395 - val_loss: 1.9832 - val_acc: 0.3334\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.3394 - acc: 0.1578 - val_loss: 1.9197 - val_acc: 0.3478\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 2.3327 - acc: 0.1388 - val_loss: 1.9167 - val_acc: 0.3430\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.3124 - acc: 0.1530 - val_loss: 1.8873 - val_acc: 0.3540\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.3160 - acc: 0.1505 - val_loss: 1.9486 - val_acc: 0.3464\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 2.2718 - acc: 0.1510 - val_loss: 1.8406 - val_acc: 0.3594\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 2.2734 - acc: 0.1530 - val_loss: 1.9373 - val_acc: 0.3432\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 2.2716 - acc: 0.1517 - val_loss: 1.8598 - val_acc: 0.3636\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 2.2543 - acc: 0.1557 - val_loss: 1.8915 - val_acc: 0.3590\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 2.2375 - acc: 0.1515 - val_loss: 1.8106 - val_acc: 0.3644\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 2.2589 - acc: 0.1455 - val_loss: 1.7951 - val_acc: 0.3700\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 2.2408 - acc: 0.1645 - val_loss: 1.8590 - val_acc: 0.3522\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.2526 - acc: 0.1633 - val_loss: 1.7815 - val_acc: 0.3698\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 2.2293 - acc: 0.1608 - val_loss: 1.8076 - val_acc: 0.3624\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.2359 - acc: 0.1568 - val_loss: 1.8014 - val_acc: 0.3622\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 2.2206 - acc: 0.1692 - val_loss: 1.7831 - val_acc: 0.3788\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.2197 - acc: 0.1620 - val_loss: 1.7816 - val_acc: 0.3796\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.2113 - acc: 0.1602 - val_loss: 1.7701 - val_acc: 0.3788\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.2126 - acc: 0.1605 - val_loss: 1.7597 - val_acc: 0.3814\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.2034 - acc: 0.1652 - val_loss: 1.8223 - val_acc: 0.3584\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.2052 - acc: 0.1683 - val_loss: 1.7902 - val_acc: 0.3640\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.2090 - acc: 0.1585 - val_loss: 1.7787 - val_acc: 0.3646\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.2031 - acc: 0.1633 - val_loss: 1.7751 - val_acc: 0.3628\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.2019 - acc: 0.1630 - val_loss: 1.7716 - val_acc: 0.3666\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.1848 - acc: 0.1775 - val_loss: 1.7786 - val_acc: 0.3706\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.2036 - acc: 0.1577 - val_loss: 1.7348 - val_acc: 0.3906\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 2.1801 - acc: 0.1632 - val_loss: 1.7236 - val_acc: 0.3846\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1935 - acc: 0.1645 - val_loss: 1.7269 - val_acc: 0.3814\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.1911 - acc: 0.1615 - val_loss: 1.7209 - val_acc: 0.3922\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1811 - acc: 0.1738 - val_loss: 1.7397 - val_acc: 0.3890\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1823 - acc: 0.1765 - val_loss: 1.7083 - val_acc: 0.3978\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.1947 - acc: 0.1653 - val_loss: 1.7242 - val_acc: 0.3978\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1736 - acc: 0.1740 - val_loss: 1.7309 - val_acc: 0.3850\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.1889 - acc: 0.1618 - val_loss: 1.6931 - val_acc: 0.4060\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 2.1583 - acc: 0.1733 - val_loss: 1.6989 - val_acc: 0.4052\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1899 - acc: 0.1688 - val_loss: 1.6938 - val_acc: 0.4064\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.1736 - acc: 0.1738 - val_loss: 1.7195 - val_acc: 0.3922\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.1507 - acc: 0.1833 - val_loss: 1.6693 - val_acc: 0.4128\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1532 - acc: 0.1770 - val_loss: 1.6598 - val_acc: 0.4216\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1587 - acc: 0.1725 - val_loss: 1.6830 - val_acc: 0.4086\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.1455 - acc: 0.1940 - val_loss: 1.6924 - val_acc: 0.3928\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.1425 - acc: 0.1810 - val_loss: 1.6437 - val_acc: 0.4190\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.1325 - acc: 0.1882 - val_loss: 1.6542 - val_acc: 0.4122\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.1602 - acc: 0.1748 - val_loss: 1.6604 - val_acc: 0.4054\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 2.1450 - acc: 0.1732 - val_loss: 1.6593 - val_acc: 0.4082\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1611 - acc: 0.1777 - val_loss: 1.6742 - val_acc: 0.3998\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.1640 - acc: 0.1690 - val_loss: 1.6456 - val_acc: 0.4138\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.1494 - acc: 0.1738 - val_loss: 1.6722 - val_acc: 0.4022\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.1431 - acc: 0.1895 - val_loss: 1.6432 - val_acc: 0.4198\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 2.1513 - acc: 0.1855 - val_loss: 1.6683 - val_acc: 0.4088\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1497 - acc: 0.1775 - val_loss: 1.6621 - val_acc: 0.4056\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.1214 - acc: 0.1830 - val_loss: 1.6338 - val_acc: 0.4198\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.1301 - acc: 0.1845 - val_loss: 1.6646 - val_acc: 0.4026\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 2.1225 - acc: 0.1830 - val_loss: 1.6247 - val_acc: 0.4210\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1255 - acc: 0.1835 - val_loss: 1.6340 - val_acc: 0.4180\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.1266 - acc: 0.1863 - val_loss: 1.6130 - val_acc: 0.4340\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 2.1371 - acc: 0.1817 - val_loss: 1.6466 - val_acc: 0.4096\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.1247 - acc: 0.1898 - val_loss: 1.6297 - val_acc: 0.4242\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.1200 - acc: 0.1945 - val_loss: 1.6163 - val_acc: 0.4204\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.1128 - acc: 0.1868 - val_loss: 1.6005 - val_acc: 0.4276\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.1125 - acc: 0.1905 - val_loss: 1.6019 - val_acc: 0.4290\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.1228 - acc: 0.1815 - val_loss: 1.6318 - val_acc: 0.4228\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 2.1052 - acc: 0.1915 - val_loss: 1.6607 - val_acc: 0.4194\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.1173 - acc: 0.1995 - val_loss: 1.5805 - val_acc: 0.4338\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.1008 - acc: 0.2010 - val_loss: 1.5943 - val_acc: 0.4238\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 2.0984 - acc: 0.2007 - val_loss: 1.5863 - val_acc: 0.4384\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.0999 - acc: 0.1945 - val_loss: 1.6080 - val_acc: 0.4210\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 2.1186 - acc: 0.1962 - val_loss: 1.5706 - val_acc: 0.4396\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.1131 - acc: 0.1875 - val_loss: 1.5727 - val_acc: 0.4380\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.0891 - acc: 0.2030 - val_loss: 1.5845 - val_acc: 0.4358\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.1123 - acc: 0.1853 - val_loss: 1.5952 - val_acc: 0.4364\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.1160 - acc: 0.1820 - val_loss: 1.5991 - val_acc: 0.4302\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.1131 - acc: 0.1943 - val_loss: 1.5803 - val_acc: 0.4346\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.1145 - acc: 0.2008 - val_loss: 1.5670 - val_acc: 0.4400\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.1005 - acc: 0.1993 - val_loss: 1.5788 - val_acc: 0.4374\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.0804 - acc: 0.2025 - val_loss: 1.5769 - val_acc: 0.4334\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 2.0831 - acc: 0.2062 - val_loss: 1.5879 - val_acc: 0.4344\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.0875 - acc: 0.2083 - val_loss: 1.5801 - val_acc: 0.4416\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.0850 - acc: 0.2048 - val_loss: 1.5617 - val_acc: 0.4428\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0801 - acc: 0.2093 - val_loss: 1.5568 - val_acc: 0.4516\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.1131 - acc: 0.1875 - val_loss: 1.5511 - val_acc: 0.4460\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.0689 - acc: 0.2067 - val_loss: 1.5605 - val_acc: 0.4448\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0899 - acc: 0.1985 - val_loss: 1.5671 - val_acc: 0.4454\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0845 - acc: 0.2043 - val_loss: 1.5762 - val_acc: 0.4448\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.0981 - acc: 0.2000 - val_loss: 1.6238 - val_acc: 0.4296\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.0529 - acc: 0.2210 - val_loss: 1.5756 - val_acc: 0.4420\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0882 - acc: 0.2032 - val_loss: 1.5433 - val_acc: 0.4542\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 2.0709 - acc: 0.2150 - val_loss: 1.5488 - val_acc: 0.4486\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0813 - acc: 0.1975 - val_loss: 1.5631 - val_acc: 0.4486\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 2.0835 - acc: 0.2080 - val_loss: 1.5648 - val_acc: 0.4538\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.0849 - acc: 0.1995 - val_loss: 1.5537 - val_acc: 0.4504\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0776 - acc: 0.2145 - val_loss: 1.5895 - val_acc: 0.4334\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.0816 - acc: 0.2167 - val_loss: 1.5610 - val_acc: 0.4498\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 2.0731 - acc: 0.2148 - val_loss: 1.5505 - val_acc: 0.4478\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0265 - acc: 0.2205 - val_loss: 1.5441 - val_acc: 0.4512\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 2.0631 - acc: 0.2083 - val_loss: 1.5698 - val_acc: 0.4442\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.0473 - acc: 0.2198 - val_loss: 1.5322 - val_acc: 0.4600\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.0334 - acc: 0.2308 - val_loss: 1.6383 - val_acc: 0.4406\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0595 - acc: 0.2138 - val_loss: 1.5641 - val_acc: 0.4562\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0555 - acc: 0.2170 - val_loss: 1.5503 - val_acc: 0.4506\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0484 - acc: 0.2098 - val_loss: 1.5395 - val_acc: 0.4496\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0524 - acc: 0.2153 - val_loss: 1.5203 - val_acc: 0.4542\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0286 - acc: 0.2255 - val_loss: 1.5622 - val_acc: 0.4484\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0456 - acc: 0.2210 - val_loss: 1.5336 - val_acc: 0.4526\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 2.0632 - acc: 0.2160 - val_loss: 1.5263 - val_acc: 0.4570\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.0424 - acc: 0.2233 - val_loss: 1.5258 - val_acc: 0.4608\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.0501 - acc: 0.2220 - val_loss: 1.5192 - val_acc: 0.4590\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.0173 - acc: 0.2297 - val_loss: 1.5145 - val_acc: 0.4564\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.0389 - acc: 0.2282 - val_loss: 1.5979 - val_acc: 0.4514\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 2.0440 - acc: 0.2282 - val_loss: 1.5380 - val_acc: 0.4632\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0400 - acc: 0.2182 - val_loss: 1.5347 - val_acc: 0.4646\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.0188 - acc: 0.2325 - val_loss: 1.5396 - val_acc: 0.4628\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 2.0519 - acc: 0.2182 - val_loss: 1.5252 - val_acc: 0.4672\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 2.0457 - acc: 0.2212 - val_loss: 1.5284 - val_acc: 0.4670\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.0265 - acc: 0.2240 - val_loss: 1.5446 - val_acc: 0.4564\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0336 - acc: 0.2412 - val_loss: 1.5598 - val_acc: 0.4614\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0350 - acc: 0.2193 - val_loss: 1.6037 - val_acc: 0.4556\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 2.0119 - acc: 0.2370 - val_loss: 1.5373 - val_acc: 0.4626\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.0227 - acc: 0.2365 - val_loss: 1.5412 - val_acc: 0.4550\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.0139 - acc: 0.2368 - val_loss: 1.5307 - val_acc: 0.4616\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.0489 - acc: 0.2187 - val_loss: 1.5382 - val_acc: 0.4592\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.0448 - acc: 0.2133 - val_loss: 1.5487 - val_acc: 0.4584\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.9951 - acc: 0.2345 - val_loss: 1.5430 - val_acc: 0.4650\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 2.0193 - acc: 0.2310 - val_loss: 1.5454 - val_acc: 0.4572\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.9992 - acc: 0.2430 - val_loss: 1.5468 - val_acc: 0.4586\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 2.0239 - acc: 0.2253 - val_loss: 1.5135 - val_acc: 0.4694\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 2.0390 - acc: 0.2257 - val_loss: 1.5233 - val_acc: 0.4688\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.0089 - acc: 0.2338 - val_loss: 1.5381 - val_acc: 0.4696\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.0098 - acc: 0.2350 - val_loss: 1.5079 - val_acc: 0.4714\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.9951 - acc: 0.2320 - val_loss: 1.5188 - val_acc: 0.4698\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 2.0320 - acc: 0.2265 - val_loss: 1.5503 - val_acc: 0.4566\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 2.0166 - acc: 0.2278 - val_loss: 1.5320 - val_acc: 0.4648\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 2.0229 - acc: 0.2310 - val_loss: 1.5002 - val_acc: 0.4712\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.9915 - acc: 0.2288 - val_loss: 1.5043 - val_acc: 0.4688\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9999 - acc: 0.2450 - val_loss: 1.5282 - val_acc: 0.4682\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 2.0161 - acc: 0.2325 - val_loss: 1.5692 - val_acc: 0.4554\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9834 - acc: 0.2485 - val_loss: 1.5298 - val_acc: 0.4718\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.9990 - acc: 0.2418 - val_loss: 1.5637 - val_acc: 0.4566\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.9835 - acc: 0.2522 - val_loss: 1.5593 - val_acc: 0.4726\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9883 - acc: 0.2475 - val_loss: 1.5618 - val_acc: 0.4738\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 2.0025 - acc: 0.2408 - val_loss: 1.5394 - val_acc: 0.4704\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9609 - acc: 0.2488 - val_loss: 1.5353 - val_acc: 0.4702\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0028 - acc: 0.2400 - val_loss: 1.5639 - val_acc: 0.4644\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.9999 - acc: 0.2388 - val_loss: 1.5191 - val_acc: 0.4802\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9794 - acc: 0.2520 - val_loss: 1.5528 - val_acc: 0.4708\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.9700 - acc: 0.2573 - val_loss: 1.5562 - val_acc: 0.4632\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.9892 - acc: 0.2443 - val_loss: 1.6250 - val_acc: 0.4634\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.9721 - acc: 0.2535 - val_loss: 1.5396 - val_acc: 0.4772\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.9631 - acc: 0.2543 - val_loss: 1.6107 - val_acc: 0.4676\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.0027 - acc: 0.2408 - val_loss: 1.5599 - val_acc: 0.4782\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9891 - acc: 0.2510 - val_loss: 1.5573 - val_acc: 0.4642\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 2.0061 - acc: 0.2345 - val_loss: 1.5432 - val_acc: 0.4688\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.9770 - acc: 0.2528 - val_loss: 1.5035 - val_acc: 0.4850\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.9837 - acc: 0.2497 - val_loss: 1.5381 - val_acc: 0.4742\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.9679 - acc: 0.2608 - val_loss: 1.5074 - val_acc: 0.4780\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9647 - acc: 0.2530 - val_loss: 1.5365 - val_acc: 0.4760\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9590 - acc: 0.2582 - val_loss: 1.5522 - val_acc: 0.4676\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.9711 - acc: 0.2513 - val_loss: 1.5413 - val_acc: 0.4744\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.9848 - acc: 0.2535 - val_loss: 1.5612 - val_acc: 0.4670\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9704 - acc: 0.2470 - val_loss: 1.5332 - val_acc: 0.4758\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.9590 - acc: 0.2608 - val_loss: 1.5787 - val_acc: 0.4628\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.9669 - acc: 0.2620 - val_loss: 1.5916 - val_acc: 0.4554\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.9520 - acc: 0.2592 - val_loss: 1.5507 - val_acc: 0.4638\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.9689 - acc: 0.2585 - val_loss: 1.5239 - val_acc: 0.4844\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9671 - acc: 0.2572 - val_loss: 1.5377 - val_acc: 0.4800\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.9641 - acc: 0.2535 - val_loss: 1.5741 - val_acc: 0.4706\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.9418 - acc: 0.2795 - val_loss: 1.6164 - val_acc: 0.4656\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.9560 - acc: 0.2593 - val_loss: 1.5430 - val_acc: 0.4828\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9820 - acc: 0.2460 - val_loss: 1.5337 - val_acc: 0.4804\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.9490 - acc: 0.2640 - val_loss: 1.5149 - val_acc: 0.4854\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9710 - acc: 0.2548 - val_loss: 1.5290 - val_acc: 0.4704\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9535 - acc: 0.2568 - val_loss: 1.5005 - val_acc: 0.4836\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.9699 - acc: 0.2580 - val_loss: 1.4964 - val_acc: 0.4880\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9737 - acc: 0.2545 - val_loss: 1.4961 - val_acc: 0.4872\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 1.9277 - acc: 0.2725 - val_loss: 1.5682 - val_acc: 0.4826\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.9479 - acc: 0.2743 - val_loss: 1.5344 - val_acc: 0.4750\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9246 - acc: 0.2775 - val_loss: 1.5450 - val_acc: 0.4772\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9440 - acc: 0.2710 - val_loss: 1.5413 - val_acc: 0.4868\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.9214 - acc: 0.2868 - val_loss: 1.5675 - val_acc: 0.4772\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.9686 - acc: 0.2528 - val_loss: 1.5718 - val_acc: 0.4650\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9440 - acc: 0.2713 - val_loss: 1.5274 - val_acc: 0.4828\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.9370 - acc: 0.2820 - val_loss: 1.5260 - val_acc: 0.4828\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.9189 - acc: 0.2800 - val_loss: 1.5063 - val_acc: 0.4858\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.9085 - acc: 0.2852 - val_loss: 1.5113 - val_acc: 0.4856\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9210 - acc: 0.2770 - val_loss: 1.5203 - val_acc: 0.4830\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.9194 - acc: 0.2845 - val_loss: 1.5665 - val_acc: 0.4782\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.9388 - acc: 0.2793 - val_loss: 1.5281 - val_acc: 0.4912\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.9412 - acc: 0.2703 - val_loss: 1.5467 - val_acc: 0.4882\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.9154 - acc: 0.2838 - val_loss: 1.5689 - val_acc: 0.4776\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.9123 - acc: 0.2790 - val_loss: 1.5474 - val_acc: 0.4746\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.8985 - acc: 0.2913 - val_loss: 1.5293 - val_acc: 0.4906\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8963 - acc: 0.2800 - val_loss: 1.6488 - val_acc: 0.4832\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9097 - acc: 0.2965 - val_loss: 1.5529 - val_acc: 0.4860\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.9199 - acc: 0.2885 - val_loss: 1.5652 - val_acc: 0.4832\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.9066 - acc: 0.2932 - val_loss: 1.5292 - val_acc: 0.4806\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.9159 - acc: 0.2870 - val_loss: 1.5778 - val_acc: 0.4826\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9217 - acc: 0.2903 - val_loss: 1.6034 - val_acc: 0.4668\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9100 - acc: 0.2843 - val_loss: 1.5731 - val_acc: 0.4852\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.9089 - acc: 0.2790 - val_loss: 1.5680 - val_acc: 0.4856\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.9174 - acc: 0.2853 - val_loss: 1.5646 - val_acc: 0.4874\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9207 - acc: 0.2858 - val_loss: 1.5352 - val_acc: 0.4814\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.8879 - acc: 0.2983 - val_loss: 1.5640 - val_acc: 0.4816\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.9041 - acc: 0.2915 - val_loss: 1.5483 - val_acc: 0.4948\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.8908 - acc: 0.2942 - val_loss: 1.5235 - val_acc: 0.4936\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8995 - acc: 0.2912 - val_loss: 1.5531 - val_acc: 0.4858\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.8994 - acc: 0.2950 - val_loss: 1.5345 - val_acc: 0.4940\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8957 - acc: 0.2860 - val_loss: 1.5255 - val_acc: 0.4852\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8896 - acc: 0.2928 - val_loss: 1.5312 - val_acc: 0.4874\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.9101 - acc: 0.2940 - val_loss: 1.5478 - val_acc: 0.4862\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8835 - acc: 0.3023 - val_loss: 1.5448 - val_acc: 0.4810\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8762 - acc: 0.2972 - val_loss: 1.5610 - val_acc: 0.4924\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.8822 - acc: 0.2917 - val_loss: 1.5703 - val_acc: 0.4902\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8775 - acc: 0.3032 - val_loss: 1.5824 - val_acc: 0.4844\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.8862 - acc: 0.3017 - val_loss: 1.5255 - val_acc: 0.4844\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.8720 - acc: 0.3073 - val_loss: 1.5378 - val_acc: 0.4904\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8699 - acc: 0.3013 - val_loss: 1.5734 - val_acc: 0.4896\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.8550 - acc: 0.3128 - val_loss: 1.5487 - val_acc: 0.4900\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.8660 - acc: 0.3050 - val_loss: 1.5425 - val_acc: 0.4882\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8515 - acc: 0.3117 - val_loss: 1.5324 - val_acc: 0.4952\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.8700 - acc: 0.3028 - val_loss: 1.5971 - val_acc: 0.4904\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.8521 - acc: 0.3188 - val_loss: 1.5590 - val_acc: 0.4870\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.8919 - acc: 0.2950 - val_loss: 1.5789 - val_acc: 0.4872\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.8828 - acc: 0.2993 - val_loss: 1.5489 - val_acc: 0.4886\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8601 - acc: 0.3072 - val_loss: 1.5754 - val_acc: 0.4926\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.8745 - acc: 0.3015 - val_loss: 1.5829 - val_acc: 0.4896\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.8640 - acc: 0.3020 - val_loss: 1.5829 - val_acc: 0.4926\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.8468 - acc: 0.3155 - val_loss: 1.5797 - val_acc: 0.4858\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.8599 - acc: 0.3115 - val_loss: 1.5647 - val_acc: 0.4876\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.8603 - acc: 0.3060 - val_loss: 1.5647 - val_acc: 0.4958\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.8676 - acc: 0.3105 - val_loss: 1.6057 - val_acc: 0.4978\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.8816 - acc: 0.3125 - val_loss: 1.5535 - val_acc: 0.4948\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.8710 - acc: 0.3100 - val_loss: 1.5763 - val_acc: 0.4956\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.8775 - acc: 0.2978 - val_loss: 1.6012 - val_acc: 0.4884\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.8619 - acc: 0.3152 - val_loss: 1.5831 - val_acc: 0.4886\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.8326 - acc: 0.3255 - val_loss: 1.5732 - val_acc: 0.4850\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.8256 - acc: 0.3293 - val_loss: 1.5615 - val_acc: 0.4934\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.8594 - acc: 0.3175 - val_loss: 1.6248 - val_acc: 0.4966\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.8291 - acc: 0.3375 - val_loss: 1.5859 - val_acc: 0.4958\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8388 - acc: 0.3223 - val_loss: 1.5396 - val_acc: 0.5018\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.8522 - acc: 0.3223 - val_loss: 1.5497 - val_acc: 0.4978\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.8184 - acc: 0.3302 - val_loss: 1.5818 - val_acc: 0.4916\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.8319 - acc: 0.3150 - val_loss: 1.5883 - val_acc: 0.4936\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 1.8199 - acc: 0.3310 - val_loss: 1.6033 - val_acc: 0.4822\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.8470 - acc: 0.3242 - val_loss: 1.5862 - val_acc: 0.4960\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.8279 - acc: 0.3230 - val_loss: 1.5508 - val_acc: 0.5012\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.8194 - acc: 0.3323 - val_loss: 1.6057 - val_acc: 0.4846\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8239 - acc: 0.3248 - val_loss: 1.5825 - val_acc: 0.4838\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.8197 - acc: 0.3365 - val_loss: 1.5495 - val_acc: 0.5034\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.8043 - acc: 0.3357 - val_loss: 1.5813 - val_acc: 0.4936\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.8247 - acc: 0.3262 - val_loss: 1.5739 - val_acc: 0.4986\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8161 - acc: 0.3442 - val_loss: 1.5572 - val_acc: 0.4978\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.8340 - acc: 0.3265 - val_loss: 1.6090 - val_acc: 0.4990\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.8346 - acc: 0.3255 - val_loss: 1.5742 - val_acc: 0.5064\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.8184 - acc: 0.3448 - val_loss: 1.5396 - val_acc: 0.4988\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.8160 - acc: 0.3395 - val_loss: 1.6146 - val_acc: 0.4934\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 1.7994 - acc: 0.3443 - val_loss: 1.5912 - val_acc: 0.4936\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.7960 - acc: 0.3490 - val_loss: 1.5684 - val_acc: 0.4928\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.8215 - acc: 0.3312 - val_loss: 1.5843 - val_acc: 0.5060\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.7995 - acc: 0.3413 - val_loss: 1.5784 - val_acc: 0.4946\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 1.8251 - acc: 0.3277 - val_loss: 1.5770 - val_acc: 0.4924\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.8048 - acc: 0.3420 - val_loss: 1.6474 - val_acc: 0.4790\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.8150 - acc: 0.3282 - val_loss: 1.5671 - val_acc: 0.5014\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.8131 - acc: 0.3360 - val_loss: 1.5727 - val_acc: 0.4854\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 1.7995 - acc: 0.3523 - val_loss: 1.5400 - val_acc: 0.5006\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.7951 - acc: 0.3505 - val_loss: 1.5485 - val_acc: 0.5018\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.8050 - acc: 0.3430 - val_loss: 1.6139 - val_acc: 0.4936\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.7891 - acc: 0.3565 - val_loss: 1.5856 - val_acc: 0.4950\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 1.7883 - acc: 0.3430 - val_loss: 1.6158 - val_acc: 0.4866\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.7960 - acc: 0.3442 - val_loss: 1.6134 - val_acc: 0.4840\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.8082 - acc: 0.3380 - val_loss: 1.6147 - val_acc: 0.4986\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.7905 - acc: 0.3558 - val_loss: 1.5806 - val_acc: 0.4982\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.7868 - acc: 0.3447 - val_loss: 1.5988 - val_acc: 0.5010\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.7841 - acc: 0.3420 - val_loss: 1.5792 - val_acc: 0.5030\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.7820 - acc: 0.3578 - val_loss: 1.6367 - val_acc: 0.4814\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.7837 - acc: 0.3510 - val_loss: 1.5997 - val_acc: 0.4998\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 1.7855 - acc: 0.3495 - val_loss: 1.5781 - val_acc: 0.4970\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.7808 - acc: 0.3445 - val_loss: 1.5911 - val_acc: 0.4992\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.7650 - acc: 0.3550 - val_loss: 1.6002 - val_acc: 0.4972\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.7876 - acc: 0.3513 - val_loss: 1.6044 - val_acc: 0.4942\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.7942 - acc: 0.3465 - val_loss: 1.6407 - val_acc: 0.5002\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.7623 - acc: 0.3507 - val_loss: 1.6513 - val_acc: 0.4972\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.7901 - acc: 0.3478 - val_loss: 1.5730 - val_acc: 0.5080\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.7785 - acc: 0.3530 - val_loss: 1.6227 - val_acc: 0.4906\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.7646 - acc: 0.3537 - val_loss: 1.6062 - val_acc: 0.5040\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.7732 - acc: 0.3553 - val_loss: 1.5843 - val_acc: 0.4968\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.7541 - acc: 0.3645 - val_loss: 1.5992 - val_acc: 0.4912\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.7488 - acc: 0.3660 - val_loss: 1.6166 - val_acc: 0.5030\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.7654 - acc: 0.3655 - val_loss: 1.5701 - val_acc: 0.5080\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.7626 - acc: 0.3565 - val_loss: 1.6609 - val_acc: 0.5034\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.7769 - acc: 0.3555 - val_loss: 1.6115 - val_acc: 0.4918\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.7691 - acc: 0.3590 - val_loss: 1.5957 - val_acc: 0.4958\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.7672 - acc: 0.3598 - val_loss: 1.5936 - val_acc: 0.4974\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.7457 - acc: 0.3660 - val_loss: 1.6335 - val_acc: 0.4978\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.7827 - acc: 0.3533 - val_loss: 1.5601 - val_acc: 0.5068\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.7237 - acc: 0.3745 - val_loss: 1.5882 - val_acc: 0.4940\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.7714 - acc: 0.3597 - val_loss: 1.6161 - val_acc: 0.4994\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.7313 - acc: 0.3678 - val_loss: 1.5940 - val_acc: 0.5032\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 1.7590 - acc: 0.3585 - val_loss: 1.5488 - val_acc: 0.5014\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.7616 - acc: 0.3668 - val_loss: 1.6166 - val_acc: 0.4980\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 1.7642 - acc: 0.3623 - val_loss: 1.5789 - val_acc: 0.5060\n",
            "Test accuracy: 0.505 (elaspsed time: 487s)\n",
            "Accuracy\n",
            "airplane 0.598\n",
            "auto 0.729\n",
            "bird 0.266\n",
            "cat 0.291\n",
            "deer 0.447\n",
            "dog 0.365\n",
            "frog 0.684\n",
            "horse 0.65\n",
            "ship 0.522\n",
            "truck 0.501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3nvLu9C-_u5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "7bd9d95d-923b-48bf-ea83-67206426cb3e"
      },
      "cell_type": "code",
      "source": [
        "# Did autoaug decrease accuracy because of saturation (too many policies for reduced dataset)? Try a non-concat policy\n",
        "def mk_op2(op1, p1, v1, op2, p2, v2):\n",
        "  ops = [Operation(([op1] * 10, v1), p1), Operation(([op2] * 10, v2), p2)]\n",
        "  return Transform(*ops)\n",
        "\n",
        "# Duplicate the AutoAugment CIFAR-10 policy selected by concatenations of AutoAugment\n",
        "pol_autoaug0_0 = [\n",
        "    #0_0\n",
        "    mk_op2(Invert, 0.1, 7, Contrast, 0.2, 6),\n",
        "    mk_op2(Rotate, 0.7, 2, TranslateX, 0.3, 9),\n",
        "    mk_op2(Sharpness, 0.8, 1, Sharpness, 0.9, 3),\n",
        "    mk_op2(ShearY, 0.5, 8, TranslateY, 0.7, 9),\n",
        "    mk_op2(AutoContrast, 0.5, 8, Equalize, 0.9, 2)]\n",
        "\n",
        "aug_autoaug0_0 = autoaugment(pol_autoaug0_0, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_autoaug0_0= create_model(X_reduced, 10)\n",
        "model_autoaug0_0.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_autoaug0_0, aug_autoaug0_0, 300)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 9s 575ms/step - loss: 2.4314 - acc: 0.1408 - val_loss: 2.0595 - val_acc: 0.3290\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 2.3442 - acc: 0.1442 - val_loss: 1.9516 - val_acc: 0.3540\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 2.3558 - acc: 0.1455 - val_loss: 1.9852 - val_acc: 0.3268\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.3465 - acc: 0.1345 - val_loss: 2.0392 - val_acc: 0.3436\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 2.3202 - acc: 0.1400 - val_loss: 2.1978 - val_acc: 0.3274\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 8s 486ms/step - loss: 2.3661 - acc: 0.1333 - val_loss: 2.0790 - val_acc: 0.3394\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 2.3082 - acc: 0.1503 - val_loss: 2.1158 - val_acc: 0.3292\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 2.3126 - acc: 0.1495 - val_loss: 1.8826 - val_acc: 0.3528\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 8s 525ms/step - loss: 2.3781 - acc: 0.1173 - val_loss: 1.9271 - val_acc: 0.3422\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 2.2414 - acc: 0.1728 - val_loss: 1.8682 - val_acc: 0.3558\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 2.2632 - acc: 0.1578 - val_loss: 1.8285 - val_acc: 0.3638\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 2.2625 - acc: 0.1603 - val_loss: 1.8555 - val_acc: 0.3532\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 7s 449ms/step - loss: 2.3053 - acc: 0.1355 - val_loss: 1.8305 - val_acc: 0.3584\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 8s 495ms/step - loss: 2.3096 - acc: 0.1510 - val_loss: 1.8474 - val_acc: 0.3492\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 2.2836 - acc: 0.1558 - val_loss: 1.8842 - val_acc: 0.3390\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 7s 466ms/step - loss: 2.2754 - acc: 0.1595 - val_loss: 1.8523 - val_acc: 0.3550\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 7s 424ms/step - loss: 2.2674 - acc: 0.1573 - val_loss: 1.8606 - val_acc: 0.3424\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 2.2866 - acc: 0.1447 - val_loss: 1.8618 - val_acc: 0.3434\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 2.1971 - acc: 0.1725 - val_loss: 1.8498 - val_acc: 0.3500\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 7s 463ms/step - loss: 2.3109 - acc: 0.1348 - val_loss: 1.8375 - val_acc: 0.3478\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 2.2453 - acc: 0.1650 - val_loss: 1.8709 - val_acc: 0.3416\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 2.2714 - acc: 0.1460 - val_loss: 1.8477 - val_acc: 0.3518\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 2.2556 - acc: 0.1500 - val_loss: 1.8419 - val_acc: 0.3410\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 8s 477ms/step - loss: 2.2704 - acc: 0.1387 - val_loss: 1.8504 - val_acc: 0.3490\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 8s 490ms/step - loss: 2.2778 - acc: 0.1357 - val_loss: 1.8969 - val_acc: 0.3388\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 7s 463ms/step - loss: 2.2507 - acc: 0.1530 - val_loss: 1.8049 - val_acc: 0.3750\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 8s 469ms/step - loss: 2.2754 - acc: 0.1355 - val_loss: 1.8421 - val_acc: 0.3610\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.1757 - acc: 0.1855 - val_loss: 1.8696 - val_acc: 0.3478\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 2.2022 - acc: 0.1737 - val_loss: 1.7984 - val_acc: 0.3676\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 2.2828 - acc: 0.1450 - val_loss: 1.8303 - val_acc: 0.3558\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 2.2221 - acc: 0.1550 - val_loss: 1.8197 - val_acc: 0.3510\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 2.2230 - acc: 0.1640 - val_loss: 1.7857 - val_acc: 0.3814\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 2.1425 - acc: 0.1983 - val_loss: 1.7923 - val_acc: 0.3704\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 2.2293 - acc: 0.1615 - val_loss: 1.8279 - val_acc: 0.3412\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 2.1989 - acc: 0.1700 - val_loss: 1.8153 - val_acc: 0.3620\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 2.2317 - acc: 0.1615 - val_loss: 1.8470 - val_acc: 0.3338\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 2.1621 - acc: 0.1790 - val_loss: 1.7826 - val_acc: 0.3648\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 2.2147 - acc: 0.1700 - val_loss: 1.7757 - val_acc: 0.3778\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 2.1783 - acc: 0.1870 - val_loss: 1.7666 - val_acc: 0.3772\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 2.1746 - acc: 0.1783 - val_loss: 1.7893 - val_acc: 0.3606\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 2.1950 - acc: 0.1770 - val_loss: 1.7749 - val_acc: 0.3748\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 2.2248 - acc: 0.1575 - val_loss: 1.7778 - val_acc: 0.3656\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 7s 465ms/step - loss: 2.2057 - acc: 0.1742 - val_loss: 1.7888 - val_acc: 0.3620\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 2.2050 - acc: 0.1695 - val_loss: 1.7838 - val_acc: 0.3726\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 2.1445 - acc: 0.1920 - val_loss: 1.7699 - val_acc: 0.3840\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 2.1969 - acc: 0.1757 - val_loss: 1.8019 - val_acc: 0.3608\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 2.1690 - acc: 0.1870 - val_loss: 1.7582 - val_acc: 0.3876\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 2.1035 - acc: 0.2248 - val_loss: 1.7744 - val_acc: 0.3718\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 2.1626 - acc: 0.1915 - val_loss: 1.7652 - val_acc: 0.3938\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 2.1999 - acc: 0.1728 - val_loss: 1.7419 - val_acc: 0.3884\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 2.1353 - acc: 0.1938 - val_loss: 1.7329 - val_acc: 0.3858\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 8s 485ms/step - loss: 2.2209 - acc: 0.1558 - val_loss: 1.7556 - val_acc: 0.3780\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 2.1097 - acc: 0.2178 - val_loss: 1.7373 - val_acc: 0.3924\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 8s 480ms/step - loss: 2.2257 - acc: 0.1712 - val_loss: 1.7511 - val_acc: 0.3808\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 2.0998 - acc: 0.2152 - val_loss: 1.7496 - val_acc: 0.3728\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 2.1542 - acc: 0.1925 - val_loss: 1.7510 - val_acc: 0.3820\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 7s 446ms/step - loss: 2.1738 - acc: 0.1950 - val_loss: 1.7359 - val_acc: 0.3906\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 8s 488ms/step - loss: 2.2178 - acc: 0.1725 - val_loss: 1.7136 - val_acc: 0.3982\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 2.1325 - acc: 0.2002 - val_loss: 1.7187 - val_acc: 0.3890\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 2.0871 - acc: 0.2238 - val_loss: 1.7306 - val_acc: 0.3912\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 2.1945 - acc: 0.1818 - val_loss: 1.7358 - val_acc: 0.4030\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 2.1843 - acc: 0.1743 - val_loss: 1.7388 - val_acc: 0.3902\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 2.1461 - acc: 0.1890 - val_loss: 1.7051 - val_acc: 0.4006\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 8s 519ms/step - loss: 2.2008 - acc: 0.1718 - val_loss: 1.7197 - val_acc: 0.3956\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 7s 407ms/step - loss: 2.1129 - acc: 0.2092 - val_loss: 1.7204 - val_acc: 0.3850\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 2.1506 - acc: 0.1977 - val_loss: 1.7481 - val_acc: 0.3860\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 2.0949 - acc: 0.2220 - val_loss: 1.7183 - val_acc: 0.3948\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 2.1459 - acc: 0.2053 - val_loss: 1.7120 - val_acc: 0.3898\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 7s 441ms/step - loss: 2.1540 - acc: 0.1945 - val_loss: 1.7033 - val_acc: 0.3920\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 2.1548 - acc: 0.1960 - val_loss: 1.6905 - val_acc: 0.4028\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 2.1340 - acc: 0.2078 - val_loss: 1.7113 - val_acc: 0.3842\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 2.1086 - acc: 0.2155 - val_loss: 1.6795 - val_acc: 0.4096\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 2.1281 - acc: 0.2058 - val_loss: 1.7064 - val_acc: 0.4000\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 2.0922 - acc: 0.2355 - val_loss: 1.7100 - val_acc: 0.4038\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 2.1185 - acc: 0.2147 - val_loss: 1.7125 - val_acc: 0.4032\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 2.1244 - acc: 0.2058 - val_loss: 1.7082 - val_acc: 0.3950\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 2.1229 - acc: 0.2037 - val_loss: 1.6777 - val_acc: 0.4060\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 2.1454 - acc: 0.1968 - val_loss: 1.6747 - val_acc: 0.4020\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 8s 470ms/step - loss: 2.1475 - acc: 0.1985 - val_loss: 1.6859 - val_acc: 0.4008\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 2.1237 - acc: 0.1993 - val_loss: 1.6640 - val_acc: 0.4104\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 2.1353 - acc: 0.2045 - val_loss: 1.6862 - val_acc: 0.3912\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 7s 412ms/step - loss: 2.1072 - acc: 0.2150 - val_loss: 1.6686 - val_acc: 0.4108\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 2.0419 - acc: 0.2465 - val_loss: 1.6528 - val_acc: 0.4152\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 7s 441ms/step - loss: 2.1339 - acc: 0.2108 - val_loss: 1.6720 - val_acc: 0.4054\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 2.0561 - acc: 0.2305 - val_loss: 1.6572 - val_acc: 0.4146\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 8s 476ms/step - loss: 2.1279 - acc: 0.2173 - val_loss: 1.6513 - val_acc: 0.4188\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 7s 460ms/step - loss: 2.1400 - acc: 0.2035 - val_loss: 1.6899 - val_acc: 0.3992\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 2.0649 - acc: 0.2478 - val_loss: 1.6665 - val_acc: 0.4128\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 7s 424ms/step - loss: 2.1445 - acc: 0.1933 - val_loss: 1.6849 - val_acc: 0.4016\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 2.0812 - acc: 0.2425 - val_loss: 1.6729 - val_acc: 0.4070\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 7s 465ms/step - loss: 2.1123 - acc: 0.2233 - val_loss: 1.6453 - val_acc: 0.4232\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.9671 - acc: 0.2818 - val_loss: 1.6618 - val_acc: 0.4118\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 2.0965 - acc: 0.2307 - val_loss: 1.6434 - val_acc: 0.4150\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 8s 476ms/step - loss: 2.1590 - acc: 0.2020 - val_loss: 1.6709 - val_acc: 0.4078\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 8s 488ms/step - loss: 2.1595 - acc: 0.2045 - val_loss: 1.6864 - val_acc: 0.4014\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 2.1080 - acc: 0.2170 - val_loss: 1.6674 - val_acc: 0.4046\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 8s 492ms/step - loss: 2.0859 - acc: 0.2317 - val_loss: 1.6553 - val_acc: 0.4232\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 2.0692 - acc: 0.2483 - val_loss: 1.6530 - val_acc: 0.4188\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 7s 417ms/step - loss: 2.0477 - acc: 0.2495 - val_loss: 1.6569 - val_acc: 0.4138\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 8s 491ms/step - loss: 2.1315 - acc: 0.2258 - val_loss: 1.6506 - val_acc: 0.4202\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 2.1074 - acc: 0.2283 - val_loss: 1.6542 - val_acc: 0.4214\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 2.0491 - acc: 0.2503 - val_loss: 1.6421 - val_acc: 0.4194\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 2.0239 - acc: 0.2483 - val_loss: 1.6214 - val_acc: 0.4240\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 2.0049 - acc: 0.2680 - val_loss: 1.6374 - val_acc: 0.4200\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.9882 - acc: 0.2690 - val_loss: 1.6241 - val_acc: 0.4240\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 8s 482ms/step - loss: 2.0990 - acc: 0.2315 - val_loss: 1.6062 - val_acc: 0.4272\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 8s 472ms/step - loss: 2.1096 - acc: 0.2263 - val_loss: 1.6208 - val_acc: 0.4218\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 2.0617 - acc: 0.2538 - val_loss: 1.6175 - val_acc: 0.4380\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 2.0104 - acc: 0.2743 - val_loss: 1.6256 - val_acc: 0.4294\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 8s 473ms/step - loss: 2.0855 - acc: 0.2460 - val_loss: 1.6226 - val_acc: 0.4298\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 8s 487ms/step - loss: 2.0922 - acc: 0.2460 - val_loss: 1.6207 - val_acc: 0.4282\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 8s 498ms/step - loss: 2.0533 - acc: 0.2540 - val_loss: 1.6256 - val_acc: 0.4278\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 8s 484ms/step - loss: 2.0986 - acc: 0.2405 - val_loss: 1.6289 - val_acc: 0.4224\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 2.0016 - acc: 0.2815 - val_loss: 1.6213 - val_acc: 0.4204\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 8s 480ms/step - loss: 2.0755 - acc: 0.2568 - val_loss: 1.6237 - val_acc: 0.4226\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 7s 463ms/step - loss: 2.0595 - acc: 0.2495 - val_loss: 1.6198 - val_acc: 0.4268\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 2.0386 - acc: 0.2525 - val_loss: 1.6110 - val_acc: 0.4326\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 1.9778 - acc: 0.2878 - val_loss: 1.6303 - val_acc: 0.4298\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 7s 424ms/step - loss: 2.0012 - acc: 0.2738 - val_loss: 1.5954 - val_acc: 0.4364\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 2.0579 - acc: 0.2495 - val_loss: 1.6571 - val_acc: 0.4212\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 8s 486ms/step - loss: 2.0572 - acc: 0.2690 - val_loss: 1.6549 - val_acc: 0.4158\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 2.0046 - acc: 0.2845 - val_loss: 1.6152 - val_acc: 0.4272\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.9519 - acc: 0.2942 - val_loss: 1.6294 - val_acc: 0.4210\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 2.0173 - acc: 0.2665 - val_loss: 1.6814 - val_acc: 0.4032\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.9847 - acc: 0.2915 - val_loss: 1.5893 - val_acc: 0.4360\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 1.9869 - acc: 0.2763 - val_loss: 1.6161 - val_acc: 0.4290\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 7s 421ms/step - loss: 1.9885 - acc: 0.2823 - val_loss: 1.5956 - val_acc: 0.4342\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 1.9640 - acc: 0.3033 - val_loss: 1.5879 - val_acc: 0.4424\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 8s 472ms/step - loss: 2.0150 - acc: 0.2742 - val_loss: 1.6354 - val_acc: 0.4306\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.9000 - acc: 0.3203 - val_loss: 1.5893 - val_acc: 0.4352\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 1.9689 - acc: 0.3048 - val_loss: 1.5990 - val_acc: 0.4338\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 1.9031 - acc: 0.3293 - val_loss: 1.6003 - val_acc: 0.4206\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 7s 430ms/step - loss: 1.9286 - acc: 0.3208 - val_loss: 1.6098 - val_acc: 0.4270\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 7s 451ms/step - loss: 2.0338 - acc: 0.2623 - val_loss: 1.5934 - val_acc: 0.4440\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 1.9538 - acc: 0.3033 - val_loss: 1.5838 - val_acc: 0.4416\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 2.0254 - acc: 0.2685 - val_loss: 1.5908 - val_acc: 0.4296\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 8s 476ms/step - loss: 1.9921 - acc: 0.3015 - val_loss: 1.5824 - val_acc: 0.4370\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.9546 - acc: 0.3085 - val_loss: 1.5770 - val_acc: 0.4430\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 8s 498ms/step - loss: 1.9426 - acc: 0.3195 - val_loss: 1.5939 - val_acc: 0.4358\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 7s 414ms/step - loss: 1.9580 - acc: 0.2990 - val_loss: 1.5726 - val_acc: 0.4420\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.9735 - acc: 0.2838 - val_loss: 1.5699 - val_acc: 0.4416\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 1.9530 - acc: 0.3115 - val_loss: 1.5892 - val_acc: 0.4366\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 1.9043 - acc: 0.3198 - val_loss: 1.5910 - val_acc: 0.4302\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.9054 - acc: 0.3057 - val_loss: 1.5677 - val_acc: 0.4400\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 8s 505ms/step - loss: 2.0331 - acc: 0.2833 - val_loss: 1.6252 - val_acc: 0.4196\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 7s 451ms/step - loss: 2.0030 - acc: 0.2818 - val_loss: 1.5934 - val_acc: 0.4294\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 8s 472ms/step - loss: 1.9605 - acc: 0.3080 - val_loss: 1.5761 - val_acc: 0.4462\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.8834 - acc: 0.3280 - val_loss: 1.5924 - val_acc: 0.4294\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.8669 - acc: 0.3358 - val_loss: 1.6003 - val_acc: 0.4308\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 8s 485ms/step - loss: 1.9657 - acc: 0.3102 - val_loss: 1.5870 - val_acc: 0.4392\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 7s 460ms/step - loss: 1.8959 - acc: 0.3397 - val_loss: 1.6044 - val_acc: 0.4292\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 1.8597 - acc: 0.3560 - val_loss: 1.5772 - val_acc: 0.4358\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 1.8651 - acc: 0.3522 - val_loss: 1.6204 - val_acc: 0.4288\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 2.0091 - acc: 0.2750 - val_loss: 1.6048 - val_acc: 0.4384\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 7s 420ms/step - loss: 1.8520 - acc: 0.3417 - val_loss: 1.5858 - val_acc: 0.4416\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 8s 475ms/step - loss: 1.8972 - acc: 0.3453 - val_loss: 1.5777 - val_acc: 0.4404\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 8s 490ms/step - loss: 1.8752 - acc: 0.3595 - val_loss: 1.5712 - val_acc: 0.4480\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 7s 418ms/step - loss: 1.8539 - acc: 0.3468 - val_loss: 1.5676 - val_acc: 0.4474\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 1.8924 - acc: 0.3370 - val_loss: 1.5615 - val_acc: 0.4546\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 1.8018 - acc: 0.3740 - val_loss: 1.5677 - val_acc: 0.4508\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.9207 - acc: 0.3263 - val_loss: 1.5590 - val_acc: 0.4520\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 1.8806 - acc: 0.3460 - val_loss: 1.5526 - val_acc: 0.4548\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 7s 406ms/step - loss: 1.8515 - acc: 0.3455 - val_loss: 1.5730 - val_acc: 0.4542\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 1.8277 - acc: 0.3642 - val_loss: 1.5678 - val_acc: 0.4492\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.8598 - acc: 0.3465 - val_loss: 1.5431 - val_acc: 0.4524\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 1.8973 - acc: 0.3383 - val_loss: 1.5651 - val_acc: 0.4440\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 1.8541 - acc: 0.3392 - val_loss: 1.5694 - val_acc: 0.4412\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 1.8662 - acc: 0.3425 - val_loss: 1.5741 - val_acc: 0.4440\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 1.7767 - acc: 0.3785 - val_loss: 1.5484 - val_acc: 0.4526\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.7606 - acc: 0.3835 - val_loss: 1.5623 - val_acc: 0.4538\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.8323 - acc: 0.3470 - val_loss: 1.5432 - val_acc: 0.4440\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 1.8186 - acc: 0.3773 - val_loss: 1.5540 - val_acc: 0.4502\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 8s 477ms/step - loss: 1.7962 - acc: 0.3873 - val_loss: 1.5820 - val_acc: 0.4354\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 1.8627 - acc: 0.3388 - val_loss: 1.5635 - val_acc: 0.4434\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 1.7637 - acc: 0.3877 - val_loss: 1.5639 - val_acc: 0.4434\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.8727 - acc: 0.3422 - val_loss: 1.6018 - val_acc: 0.4416\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 7s 462ms/step - loss: 1.7715 - acc: 0.3930 - val_loss: 1.5665 - val_acc: 0.4476\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 1.8470 - acc: 0.3622 - val_loss: 1.5400 - val_acc: 0.4632\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 8s 504ms/step - loss: 1.8561 - acc: 0.3652 - val_loss: 1.5801 - val_acc: 0.4536\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.6828 - acc: 0.4218 - val_loss: 1.5606 - val_acc: 0.4506\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 1.9042 - acc: 0.3333 - val_loss: 1.5503 - val_acc: 0.4472\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 2.0055 - acc: 0.2763 - val_loss: 1.5621 - val_acc: 0.4538\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.7433 - acc: 0.4020 - val_loss: 1.5493 - val_acc: 0.4490\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 1.8254 - acc: 0.3665 - val_loss: 1.5426 - val_acc: 0.4552\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.8742 - acc: 0.3320 - val_loss: 1.5713 - val_acc: 0.4392\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 7s 454ms/step - loss: 1.8174 - acc: 0.3763 - val_loss: 1.5427 - val_acc: 0.4538\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 1.8248 - acc: 0.3653 - val_loss: 1.5399 - val_acc: 0.4506\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 8s 488ms/step - loss: 1.7716 - acc: 0.4108 - val_loss: 1.6064 - val_acc: 0.4306\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 8s 479ms/step - loss: 1.7227 - acc: 0.4145 - val_loss: 1.5570 - val_acc: 0.4534\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 1.8109 - acc: 0.3665 - val_loss: 1.5302 - val_acc: 0.4560\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 1.8082 - acc: 0.3698 - val_loss: 1.5758 - val_acc: 0.4494\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 8s 473ms/step - loss: 1.8728 - acc: 0.3617 - val_loss: 1.5531 - val_acc: 0.4536\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 7s 411ms/step - loss: 1.7262 - acc: 0.4060 - val_loss: 1.5367 - val_acc: 0.4556\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 7s 448ms/step - loss: 1.7677 - acc: 0.4093 - val_loss: 1.5394 - val_acc: 0.4514\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 1.8359 - acc: 0.3682 - val_loss: 1.5480 - val_acc: 0.4446\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 1.6610 - acc: 0.4467 - val_loss: 1.5302 - val_acc: 0.4538\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 6s 398ms/step - loss: 1.7145 - acc: 0.4145 - val_loss: 1.5804 - val_acc: 0.4418\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 8s 485ms/step - loss: 1.7570 - acc: 0.4118 - val_loss: 1.5351 - val_acc: 0.4522\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.7407 - acc: 0.3980 - val_loss: 1.5371 - val_acc: 0.4532\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 1.7171 - acc: 0.4198 - val_loss: 1.5652 - val_acc: 0.4478\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 7s 456ms/step - loss: 1.8595 - acc: 0.3463 - val_loss: 1.5383 - val_acc: 0.4470\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 1.7037 - acc: 0.4315 - val_loss: 1.5310 - val_acc: 0.4570\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.6973 - acc: 0.4225 - val_loss: 1.5274 - val_acc: 0.4660\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 1.6283 - acc: 0.4493 - val_loss: 1.6299 - val_acc: 0.4212\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 8s 484ms/step - loss: 1.6660 - acc: 0.4538 - val_loss: 1.5783 - val_acc: 0.4422\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 7s 408ms/step - loss: 1.8348 - acc: 0.3718 - val_loss: 1.5332 - val_acc: 0.4554\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 1.7116 - acc: 0.4140 - val_loss: 1.5378 - val_acc: 0.4546\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 1.6600 - acc: 0.4275 - val_loss: 1.6165 - val_acc: 0.4328\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 7s 426ms/step - loss: 1.5923 - acc: 0.4748 - val_loss: 1.5730 - val_acc: 0.4500\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 7s 468ms/step - loss: 1.6698 - acc: 0.4382 - val_loss: 1.5573 - val_acc: 0.4472\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 6s 400ms/step - loss: 1.6842 - acc: 0.4235 - val_loss: 1.5221 - val_acc: 0.4548\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 1.6657 - acc: 0.4398 - val_loss: 1.5357 - val_acc: 0.4626\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 6s 401ms/step - loss: 1.5758 - acc: 0.4755 - val_loss: 1.5298 - val_acc: 0.4574\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5846 - acc: 0.4728 - val_loss: 1.5326 - val_acc: 0.4632\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.6135 - acc: 0.4423 - val_loss: 1.5072 - val_acc: 0.4700\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 1.6886 - acc: 0.4448 - val_loss: 1.5643 - val_acc: 0.4502\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 8s 469ms/step - loss: 1.8210 - acc: 0.3740 - val_loss: 1.5653 - val_acc: 0.4504\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 7s 424ms/step - loss: 1.7323 - acc: 0.4120 - val_loss: 1.5386 - val_acc: 0.4578\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 7s 462ms/step - loss: 1.7308 - acc: 0.4205 - val_loss: 1.5696 - val_acc: 0.4522\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 6s 405ms/step - loss: 1.6095 - acc: 0.4598 - val_loss: 1.5298 - val_acc: 0.4632\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.6477 - acc: 0.4370 - val_loss: 1.5640 - val_acc: 0.4464\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 7s 413ms/step - loss: 1.6690 - acc: 0.4325 - val_loss: 1.5077 - val_acc: 0.4620\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 1.6402 - acc: 0.4472 - val_loss: 1.5167 - val_acc: 0.4574\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 1.6425 - acc: 0.4455 - val_loss: 1.5014 - val_acc: 0.4662\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 1.6799 - acc: 0.4510 - val_loss: 1.5419 - val_acc: 0.4542\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 8s 527ms/step - loss: 1.5596 - acc: 0.4845 - val_loss: 1.5427 - val_acc: 0.4580\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 1.4846 - acc: 0.5248 - val_loss: 1.5430 - val_acc: 0.4588\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.8148 - acc: 0.3745 - val_loss: 1.5211 - val_acc: 0.4718\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.6273 - acc: 0.4707 - val_loss: 1.5113 - val_acc: 0.4656\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 7s 458ms/step - loss: 1.6664 - acc: 0.4395 - val_loss: 1.5155 - val_acc: 0.4656\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 7s 449ms/step - loss: 1.5992 - acc: 0.4705 - val_loss: 1.5172 - val_acc: 0.4676\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.5529 - acc: 0.4838 - val_loss: 1.5215 - val_acc: 0.4714\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 7s 444ms/step - loss: 1.6112 - acc: 0.4510 - val_loss: 1.5377 - val_acc: 0.4668\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 1.6386 - acc: 0.4532 - val_loss: 1.5197 - val_acc: 0.4680\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 7s 416ms/step - loss: 1.5013 - acc: 0.5098 - val_loss: 1.5162 - val_acc: 0.4728\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 7s 455ms/step - loss: 1.5700 - acc: 0.4868 - val_loss: 1.5020 - val_acc: 0.4728\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 7s 461ms/step - loss: 1.3798 - acc: 0.5537 - val_loss: 1.5128 - val_acc: 0.4672\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 7s 448ms/step - loss: 1.5619 - acc: 0.4743 - val_loss: 1.5095 - val_acc: 0.4674\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 1.6429 - acc: 0.4518 - val_loss: 1.5033 - val_acc: 0.4730\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.5511 - acc: 0.4963 - val_loss: 1.5124 - val_acc: 0.4692\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 1.4517 - acc: 0.5310 - val_loss: 1.5209 - val_acc: 0.4694\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 1.5524 - acc: 0.4768 - val_loss: 1.5014 - val_acc: 0.4772\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 7s 457ms/step - loss: 1.6343 - acc: 0.4575 - val_loss: 1.5265 - val_acc: 0.4622\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 1.6444 - acc: 0.4438 - val_loss: 1.5493 - val_acc: 0.4602\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 8s 525ms/step - loss: 1.5962 - acc: 0.4765 - val_loss: 1.5388 - val_acc: 0.4626\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 8s 507ms/step - loss: 1.4890 - acc: 0.5150 - val_loss: 1.5210 - val_acc: 0.4598\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 1.6491 - acc: 0.4425 - val_loss: 1.5619 - val_acc: 0.4568\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 1.5945 - acc: 0.4657 - val_loss: 1.5482 - val_acc: 0.4642\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.6633 - acc: 0.4418 - val_loss: 1.5439 - val_acc: 0.4630\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.4140 - acc: 0.5413 - val_loss: 1.5026 - val_acc: 0.4646\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.6475 - acc: 0.4400 - val_loss: 1.5153 - val_acc: 0.4748\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 7s 419ms/step - loss: 1.6707 - acc: 0.4498 - val_loss: 1.5501 - val_acc: 0.4532\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 7s 454ms/step - loss: 1.3795 - acc: 0.5605 - val_loss: 1.5363 - val_acc: 0.4582\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.5144 - acc: 0.4992 - val_loss: 1.5023 - val_acc: 0.4722\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 1.5660 - acc: 0.4780 - val_loss: 1.5655 - val_acc: 0.4562\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 8s 488ms/step - loss: 1.4489 - acc: 0.5395 - val_loss: 1.5332 - val_acc: 0.4628\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 7s 464ms/step - loss: 1.5323 - acc: 0.5027 - val_loss: 1.5431 - val_acc: 0.4630\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 7s 461ms/step - loss: 1.5850 - acc: 0.4795 - val_loss: 1.5146 - val_acc: 0.4692\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 1.5631 - acc: 0.4850 - val_loss: 1.5161 - val_acc: 0.4670\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 1.5765 - acc: 0.4720 - val_loss: 1.5389 - val_acc: 0.4592\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 8s 486ms/step - loss: 1.3499 - acc: 0.5853 - val_loss: 1.5184 - val_acc: 0.4660\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 8s 482ms/step - loss: 1.4579 - acc: 0.5235 - val_loss: 1.5939 - val_acc: 0.4530\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 7s 459ms/step - loss: 1.5879 - acc: 0.4715 - val_loss: 1.5362 - val_acc: 0.4690\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 1.4407 - acc: 0.5342 - val_loss: 1.5298 - val_acc: 0.4586\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 7s 415ms/step - loss: 1.4878 - acc: 0.5223 - val_loss: 1.5454 - val_acc: 0.4664\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 7s 447ms/step - loss: 1.3617 - acc: 0.5753 - val_loss: 1.5164 - val_acc: 0.4710\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.3965 - acc: 0.5390 - val_loss: 1.5196 - val_acc: 0.4666\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 6s 403ms/step - loss: 1.4612 - acc: 0.5275 - val_loss: 1.5424 - val_acc: 0.4636\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.5909 - acc: 0.4695 - val_loss: 1.5345 - val_acc: 0.4618\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 1.6028 - acc: 0.4713 - val_loss: 1.5223 - val_acc: 0.4720\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 1.5040 - acc: 0.5145 - val_loss: 1.5470 - val_acc: 0.4658\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 8s 477ms/step - loss: 1.4722 - acc: 0.5265 - val_loss: 1.5264 - val_acc: 0.4658\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 7s 442ms/step - loss: 1.5316 - acc: 0.4980 - val_loss: 1.5378 - val_acc: 0.4620\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.6820 - acc: 0.4332 - val_loss: 1.5412 - val_acc: 0.4694\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 6s 399ms/step - loss: 1.6519 - acc: 0.4392 - val_loss: 1.5398 - val_acc: 0.4746\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 7s 423ms/step - loss: 1.5741 - acc: 0.4793 - val_loss: 1.5851 - val_acc: 0.4654\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 1.6824 - acc: 0.4180 - val_loss: 1.5262 - val_acc: 0.4740\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 1.3605 - acc: 0.5625 - val_loss: 1.5237 - val_acc: 0.4702\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.5798 - acc: 0.4723 - val_loss: 1.5230 - val_acc: 0.4734\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 8s 471ms/step - loss: 1.3715 - acc: 0.5642 - val_loss: 1.5355 - val_acc: 0.4584\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 8s 482ms/step - loss: 1.3523 - acc: 0.5667 - val_loss: 1.5146 - val_acc: 0.4650\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.5192 - acc: 0.4965 - val_loss: 1.5328 - val_acc: 0.4710\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 7s 455ms/step - loss: 1.3939 - acc: 0.5632 - val_loss: 1.6211 - val_acc: 0.4540\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 7s 467ms/step - loss: 1.3799 - acc: 0.5593 - val_loss: 1.5352 - val_acc: 0.4748\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 7s 451ms/step - loss: 1.4451 - acc: 0.5268 - val_loss: 1.5270 - val_acc: 0.4626\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 9s 532ms/step - loss: 1.4088 - acc: 0.5555 - val_loss: 1.5802 - val_acc: 0.4508\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.3974 - acc: 0.5412 - val_loss: 1.5467 - val_acc: 0.4714\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 1.4792 - acc: 0.5140 - val_loss: 1.5497 - val_acc: 0.4618\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 7s 453ms/step - loss: 1.3567 - acc: 0.5722 - val_loss: 1.5314 - val_acc: 0.4734\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 1.5203 - acc: 0.4825 - val_loss: 1.5502 - val_acc: 0.4682\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.3355 - acc: 0.5808 - val_loss: 1.5288 - val_acc: 0.4684\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 1.2754 - acc: 0.5912 - val_loss: 1.5149 - val_acc: 0.4732\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 7s 410ms/step - loss: 1.4657 - acc: 0.5185 - val_loss: 1.4990 - val_acc: 0.4826\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 7s 422ms/step - loss: 1.3565 - acc: 0.5645 - val_loss: 1.5290 - val_acc: 0.4772\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 8s 472ms/step - loss: 1.5381 - acc: 0.4983 - val_loss: 1.5411 - val_acc: 0.4682\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 8s 509ms/step - loss: 1.2586 - acc: 0.6050 - val_loss: 1.5342 - val_acc: 0.4712\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 6s 406ms/step - loss: 1.6074 - acc: 0.4595 - val_loss: 1.5559 - val_acc: 0.4718\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 8s 477ms/step - loss: 1.2163 - acc: 0.6195 - val_loss: 1.5282 - val_acc: 0.4766\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 7s 452ms/step - loss: 1.1878 - acc: 0.6217 - val_loss: 1.5403 - val_acc: 0.4702\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 8s 479ms/step - loss: 1.2641 - acc: 0.6075 - val_loss: 1.5336 - val_acc: 0.4704\n",
            "Test accuracy: 0.456 (elaspsed time: 490s)\n",
            "Accuracy\n",
            "airplane 0.523\n",
            "auto 0.613\n",
            "bird 0.376\n",
            "cat 0.299\n",
            "deer 0.357\n",
            "dog 0.371\n",
            "frog 0.553\n",
            "horse 0.447\n",
            "ship 0.608\n",
            "truck 0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vLOn8G-cLDrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10421
        },
        "outputId": "854973fa-2847-4dfa-8ddc-08eaf2dd34a1"
      },
      "cell_type": "code",
      "source": [
        "# How about combining two transforms that increased accuracy (OR)?\n",
        "op1 = opmap['TranslateY']\n",
        "op2 = opmap['Flip_LR']\n",
        "# 50% prob of transform\n",
        "op1 = [Operation(([op1] * 10, 5), 0.5)]\n",
        "op2 = [Operation(([op2] * 10, 5), 0.5)]\n",
        "\n",
        "transform = [Transform(*op1), Transform(*op2)]\n",
        "\n",
        "aug_2_tform_or = autoaugment(transform, X_reduced, y_reduced, batch_size) \n",
        "\n",
        "model_2_tform_or= create_model(X_reduced, 10)\n",
        "model_2_tform_or.set_weights(base.get_weights())\n",
        "\n",
        "history = train_model(X_reduced, model_2_tform_or, aug_2_tform_or, 300)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 7s 428ms/step - loss: 2.3154 - acc: 0.1968 - val_loss: 1.8639 - val_acc: 0.3566\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 3s 180ms/step - loss: 2.2101 - acc: 0.1987 - val_loss: 1.8430 - val_acc: 0.3560\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 2.1784 - acc: 0.2108 - val_loss: 1.8609 - val_acc: 0.3542\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1575 - acc: 0.2172 - val_loss: 1.7907 - val_acc: 0.3688\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.1830 - acc: 0.2005 - val_loss: 1.8772 - val_acc: 0.3516\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 2.1532 - acc: 0.2113 - val_loss: 1.7609 - val_acc: 0.3766\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.1089 - acc: 0.2195 - val_loss: 1.7774 - val_acc: 0.3818\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.1069 - acc: 0.2230 - val_loss: 1.7238 - val_acc: 0.3894\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0725 - acc: 0.2317 - val_loss: 1.7305 - val_acc: 0.3888\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.0910 - acc: 0.2210 - val_loss: 1.7401 - val_acc: 0.3850\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 2.0706 - acc: 0.2333 - val_loss: 1.7321 - val_acc: 0.3828\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0564 - acc: 0.2430 - val_loss: 1.7310 - val_acc: 0.3900\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 2.0352 - acc: 0.2400 - val_loss: 1.7146 - val_acc: 0.3984\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0389 - acc: 0.2452 - val_loss: 1.7012 - val_acc: 0.3978\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0438 - acc: 0.2368 - val_loss: 1.6902 - val_acc: 0.4054\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0230 - acc: 0.2483 - val_loss: 1.6689 - val_acc: 0.4108\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 2.0481 - acc: 0.2438 - val_loss: 1.6636 - val_acc: 0.4102\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9896 - acc: 0.2615 - val_loss: 1.6668 - val_acc: 0.4120\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.9928 - acc: 0.2575 - val_loss: 1.6496 - val_acc: 0.4176\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 2.0046 - acc: 0.2502 - val_loss: 1.6407 - val_acc: 0.4182\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9752 - acc: 0.2610 - val_loss: 1.6675 - val_acc: 0.4150\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.9550 - acc: 0.2620 - val_loss: 1.6295 - val_acc: 0.4216\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.9435 - acc: 0.2763 - val_loss: 1.6395 - val_acc: 0.4210\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.9552 - acc: 0.2678 - val_loss: 1.6210 - val_acc: 0.4240\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.9417 - acc: 0.2770 - val_loss: 1.6043 - val_acc: 0.4368\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.9508 - acc: 0.2760 - val_loss: 1.6432 - val_acc: 0.4176\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.9519 - acc: 0.2685 - val_loss: 1.6254 - val_acc: 0.4296\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.9098 - acc: 0.2870 - val_loss: 1.5906 - val_acc: 0.4382\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.9281 - acc: 0.2822 - val_loss: 1.5836 - val_acc: 0.4380\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8858 - acc: 0.2843 - val_loss: 1.5879 - val_acc: 0.4322\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8987 - acc: 0.2893 - val_loss: 1.5904 - val_acc: 0.4336\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8984 - acc: 0.2790 - val_loss: 1.5975 - val_acc: 0.4386\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.9063 - acc: 0.2873 - val_loss: 1.6092 - val_acc: 0.4296\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8717 - acc: 0.3057 - val_loss: 1.5742 - val_acc: 0.4388\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.8549 - acc: 0.3047 - val_loss: 1.5652 - val_acc: 0.4432\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8387 - acc: 0.3048 - val_loss: 1.5861 - val_acc: 0.4294\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8644 - acc: 0.3113 - val_loss: 1.5976 - val_acc: 0.4360\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8426 - acc: 0.3015 - val_loss: 1.5715 - val_acc: 0.4488\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8279 - acc: 0.3118 - val_loss: 1.5508 - val_acc: 0.4516\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.8252 - acc: 0.3167 - val_loss: 1.5519 - val_acc: 0.4540\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.8380 - acc: 0.3023 - val_loss: 1.5656 - val_acc: 0.4482\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.8378 - acc: 0.3077 - val_loss: 1.5571 - val_acc: 0.4590\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.8111 - acc: 0.3225 - val_loss: 1.5466 - val_acc: 0.4540\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.8415 - acc: 0.3068 - val_loss: 1.5356 - val_acc: 0.4544\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7937 - acc: 0.3292 - val_loss: 1.6206 - val_acc: 0.4428\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.8125 - acc: 0.3175 - val_loss: 1.5778 - val_acc: 0.4558\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.8194 - acc: 0.3170 - val_loss: 1.5678 - val_acc: 0.4362\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.7953 - acc: 0.3243 - val_loss: 1.5298 - val_acc: 0.4576\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.7933 - acc: 0.3283 - val_loss: 1.5434 - val_acc: 0.4556\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.7783 - acc: 0.3308 - val_loss: 1.5300 - val_acc: 0.4656\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7739 - acc: 0.3328 - val_loss: 1.5267 - val_acc: 0.4626\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.7541 - acc: 0.3360 - val_loss: 1.5241 - val_acc: 0.4610\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.7498 - acc: 0.3465 - val_loss: 1.5189 - val_acc: 0.4692\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.7453 - acc: 0.3373 - val_loss: 1.5266 - val_acc: 0.4614\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.7458 - acc: 0.3413 - val_loss: 1.5194 - val_acc: 0.4578\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7556 - acc: 0.3380 - val_loss: 1.5155 - val_acc: 0.4616\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.7323 - acc: 0.3455 - val_loss: 1.5755 - val_acc: 0.4554\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.7520 - acc: 0.3395 - val_loss: 1.5219 - val_acc: 0.4664\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.7197 - acc: 0.3465 - val_loss: 1.5403 - val_acc: 0.4510\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.7295 - acc: 0.3468 - val_loss: 1.5084 - val_acc: 0.4652\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.7279 - acc: 0.3515 - val_loss: 1.5173 - val_acc: 0.4670\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6810 - acc: 0.3660 - val_loss: 1.5128 - val_acc: 0.4714\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6937 - acc: 0.3690 - val_loss: 1.4911 - val_acc: 0.4744\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.7337 - acc: 0.3440 - val_loss: 1.5155 - val_acc: 0.4724\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.6680 - acc: 0.3700 - val_loss: 1.5194 - val_acc: 0.4720\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6773 - acc: 0.3757 - val_loss: 1.5036 - val_acc: 0.4746\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6659 - acc: 0.3738 - val_loss: 1.5142 - val_acc: 0.4772\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6834 - acc: 0.3632 - val_loss: 1.5112 - val_acc: 0.4710\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6766 - acc: 0.3600 - val_loss: 1.4900 - val_acc: 0.4856\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6882 - acc: 0.3652 - val_loss: 1.5291 - val_acc: 0.4664\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6758 - acc: 0.3655 - val_loss: 1.5188 - val_acc: 0.4770\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.6484 - acc: 0.3808 - val_loss: 1.5199 - val_acc: 0.4714\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6543 - acc: 0.3807 - val_loss: 1.5107 - val_acc: 0.4844\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6508 - acc: 0.3800 - val_loss: 1.5210 - val_acc: 0.4698\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6599 - acc: 0.3775 - val_loss: 1.5526 - val_acc: 0.4704\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.6400 - acc: 0.3800 - val_loss: 1.5424 - val_acc: 0.4758\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6349 - acc: 0.3905 - val_loss: 1.4968 - val_acc: 0.4826\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6436 - acc: 0.3755 - val_loss: 1.5026 - val_acc: 0.4710\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6399 - acc: 0.3798 - val_loss: 1.5225 - val_acc: 0.4854\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6023 - acc: 0.4012 - val_loss: 1.4705 - val_acc: 0.4888\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.6110 - acc: 0.3895 - val_loss: 1.4891 - val_acc: 0.4860\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6175 - acc: 0.3975 - val_loss: 1.4914 - val_acc: 0.4900\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.6285 - acc: 0.3945 - val_loss: 1.5062 - val_acc: 0.4894\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.6291 - acc: 0.3930 - val_loss: 1.5013 - val_acc: 0.4906\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.6051 - acc: 0.3968 - val_loss: 1.5296 - val_acc: 0.4888\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.6088 - acc: 0.3885 - val_loss: 1.5112 - val_acc: 0.4824\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.5993 - acc: 0.3970 - val_loss: 1.5378 - val_acc: 0.4854\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.6089 - acc: 0.4033 - val_loss: 1.5101 - val_acc: 0.4930\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.6012 - acc: 0.3963 - val_loss: 1.4882 - val_acc: 0.4890\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5995 - acc: 0.3953 - val_loss: 1.4951 - val_acc: 0.4840\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.5855 - acc: 0.4035 - val_loss: 1.5122 - val_acc: 0.4934\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.5312 - acc: 0.4310 - val_loss: 1.5154 - val_acc: 0.4904\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5506 - acc: 0.4195 - val_loss: 1.5492 - val_acc: 0.4860\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5683 - acc: 0.4157 - val_loss: 1.4913 - val_acc: 0.4922\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5669 - acc: 0.4005 - val_loss: 1.5630 - val_acc: 0.4738\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5592 - acc: 0.4075 - val_loss: 1.4986 - val_acc: 0.4920\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5317 - acc: 0.4217 - val_loss: 1.4761 - val_acc: 0.5014\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5604 - acc: 0.4183 - val_loss: 1.6024 - val_acc: 0.4874\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5369 - acc: 0.4230 - val_loss: 1.4720 - val_acc: 0.5046\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5276 - acc: 0.4250 - val_loss: 1.4984 - val_acc: 0.4920\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5424 - acc: 0.4295 - val_loss: 1.4697 - val_acc: 0.5052\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5347 - acc: 0.4220 - val_loss: 1.5168 - val_acc: 0.5018\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.5111 - acc: 0.4253 - val_loss: 1.5000 - val_acc: 0.5026\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.5277 - acc: 0.4240 - val_loss: 1.4700 - val_acc: 0.5056\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.5295 - acc: 0.4285 - val_loss: 1.5308 - val_acc: 0.5032\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5093 - acc: 0.4315 - val_loss: 1.4896 - val_acc: 0.5032\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.5195 - acc: 0.4253 - val_loss: 1.5286 - val_acc: 0.5028\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5270 - acc: 0.4205 - val_loss: 1.4879 - val_acc: 0.5068\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4971 - acc: 0.4388 - val_loss: 1.4787 - val_acc: 0.5076\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4831 - acc: 0.4480 - val_loss: 1.5365 - val_acc: 0.5038\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4799 - acc: 0.4490 - val_loss: 1.5064 - val_acc: 0.4950\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.5002 - acc: 0.4405 - val_loss: 1.4815 - val_acc: 0.5064\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4668 - acc: 0.4547 - val_loss: 1.5033 - val_acc: 0.5068\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4686 - acc: 0.4503 - val_loss: 1.5143 - val_acc: 0.5140\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4702 - acc: 0.4462 - val_loss: 1.4963 - val_acc: 0.5068\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.4752 - acc: 0.4348 - val_loss: 1.5050 - val_acc: 0.5060\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.4781 - acc: 0.4537 - val_loss: 1.4904 - val_acc: 0.5112\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4563 - acc: 0.4527 - val_loss: 1.5340 - val_acc: 0.5036\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.5007 - acc: 0.4248 - val_loss: 1.4901 - val_acc: 0.5146\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4692 - acc: 0.4428 - val_loss: 1.4820 - val_acc: 0.5144\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4662 - acc: 0.4488 - val_loss: 1.5004 - val_acc: 0.5066\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4536 - acc: 0.4508 - val_loss: 1.4873 - val_acc: 0.5116\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4353 - acc: 0.4570 - val_loss: 1.5713 - val_acc: 0.4982\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4405 - acc: 0.4593 - val_loss: 1.5713 - val_acc: 0.4952\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4557 - acc: 0.4583 - val_loss: 1.5324 - val_acc: 0.5078\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4397 - acc: 0.4585 - val_loss: 1.5047 - val_acc: 0.5180\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.4292 - acc: 0.4630 - val_loss: 1.5480 - val_acc: 0.4934\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.4418 - acc: 0.4570 - val_loss: 1.5063 - val_acc: 0.5046\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4525 - acc: 0.4523 - val_loss: 1.4957 - val_acc: 0.5166\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3982 - acc: 0.4710 - val_loss: 1.5484 - val_acc: 0.5008\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.4368 - acc: 0.4590 - val_loss: 1.5196 - val_acc: 0.5150\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4217 - acc: 0.4740 - val_loss: 1.5065 - val_acc: 0.5076\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.4199 - acc: 0.4720 - val_loss: 1.5599 - val_acc: 0.5094\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.4170 - acc: 0.4683 - val_loss: 1.5344 - val_acc: 0.5138\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4250 - acc: 0.4695 - val_loss: 1.5585 - val_acc: 0.4952\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.4187 - acc: 0.4755 - val_loss: 1.5901 - val_acc: 0.4962\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.4080 - acc: 0.4740 - val_loss: 1.5418 - val_acc: 0.5098\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.4246 - acc: 0.4638 - val_loss: 1.5429 - val_acc: 0.5090\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3961 - acc: 0.4795 - val_loss: 1.5280 - val_acc: 0.5170\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.3814 - acc: 0.4928 - val_loss: 1.5302 - val_acc: 0.5128\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3974 - acc: 0.4708 - val_loss: 1.5638 - val_acc: 0.5150\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3975 - acc: 0.4850 - val_loss: 1.5579 - val_acc: 0.5100\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3859 - acc: 0.4865 - val_loss: 1.5264 - val_acc: 0.5104\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3906 - acc: 0.4863 - val_loss: 1.5495 - val_acc: 0.5108\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3673 - acc: 0.4898 - val_loss: 1.5478 - val_acc: 0.5058\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3747 - acc: 0.4845 - val_loss: 1.5460 - val_acc: 0.5144\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.4140 - acc: 0.4730 - val_loss: 1.4975 - val_acc: 0.5176\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.3965 - acc: 0.4838 - val_loss: 1.5174 - val_acc: 0.5164\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3897 - acc: 0.4773 - val_loss: 1.5216 - val_acc: 0.5216\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3545 - acc: 0.4930 - val_loss: 1.5352 - val_acc: 0.5196\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3582 - acc: 0.5010 - val_loss: 1.5725 - val_acc: 0.5184\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.3835 - acc: 0.4868 - val_loss: 1.5264 - val_acc: 0.5210\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.3648 - acc: 0.4912 - val_loss: 1.5696 - val_acc: 0.5198\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3394 - acc: 0.5008 - val_loss: 1.6071 - val_acc: 0.5146\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3507 - acc: 0.5005 - val_loss: 1.5331 - val_acc: 0.5068\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3519 - acc: 0.4867 - val_loss: 1.5465 - val_acc: 0.5096\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.3130 - acc: 0.5278 - val_loss: 1.5469 - val_acc: 0.5136\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3594 - acc: 0.4920 - val_loss: 1.5495 - val_acc: 0.5218\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3656 - acc: 0.4963 - val_loss: 1.5991 - val_acc: 0.5142\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3457 - acc: 0.5013 - val_loss: 1.5318 - val_acc: 0.5272\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3347 - acc: 0.4965 - val_loss: 1.5513 - val_acc: 0.5218\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3417 - acc: 0.5030 - val_loss: 1.5698 - val_acc: 0.5196\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3338 - acc: 0.5025 - val_loss: 1.5691 - val_acc: 0.5236\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3325 - acc: 0.5047 - val_loss: 1.5283 - val_acc: 0.5244\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.3280 - acc: 0.5112 - val_loss: 1.5490 - val_acc: 0.5232\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3168 - acc: 0.5010 - val_loss: 1.5490 - val_acc: 0.5166\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3327 - acc: 0.5100 - val_loss: 1.5722 - val_acc: 0.5230\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3495 - acc: 0.4990 - val_loss: 1.6002 - val_acc: 0.5154\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3320 - acc: 0.5045 - val_loss: 1.5689 - val_acc: 0.5264\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3178 - acc: 0.5155 - val_loss: 1.5829 - val_acc: 0.5226\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3044 - acc: 0.5200 - val_loss: 1.6197 - val_acc: 0.5248\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3302 - acc: 0.5030 - val_loss: 1.5598 - val_acc: 0.5234\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 3s 204ms/step - loss: 1.3216 - acc: 0.5130 - val_loss: 1.5712 - val_acc: 0.5250\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.3185 - acc: 0.5070 - val_loss: 1.6979 - val_acc: 0.5130\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3144 - acc: 0.5103 - val_loss: 1.5760 - val_acc: 0.5304\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3357 - acc: 0.5040 - val_loss: 1.5332 - val_acc: 0.5268\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3035 - acc: 0.5270 - val_loss: 1.5680 - val_acc: 0.5226\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2945 - acc: 0.5208 - val_loss: 1.5813 - val_acc: 0.5208\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3487 - acc: 0.5007 - val_loss: 1.6434 - val_acc: 0.5194\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.3051 - acc: 0.5180 - val_loss: 1.5744 - val_acc: 0.5170\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2998 - acc: 0.5238 - val_loss: 1.5615 - val_acc: 0.5276\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3275 - acc: 0.5098 - val_loss: 1.5872 - val_acc: 0.5252\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2942 - acc: 0.5220 - val_loss: 1.5536 - val_acc: 0.5208\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2983 - acc: 0.5232 - val_loss: 1.5690 - val_acc: 0.5316\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.3029 - acc: 0.5267 - val_loss: 1.5572 - val_acc: 0.5178\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.3000 - acc: 0.5195 - val_loss: 1.5769 - val_acc: 0.5212\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.3173 - acc: 0.5055 - val_loss: 1.5961 - val_acc: 0.5320\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.2896 - acc: 0.5293 - val_loss: 1.6721 - val_acc: 0.5266\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.3076 - acc: 0.5128 - val_loss: 1.5615 - val_acc: 0.5256\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2949 - acc: 0.5332 - val_loss: 1.6153 - val_acc: 0.5180\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2854 - acc: 0.5257 - val_loss: 1.5754 - val_acc: 0.5280\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2824 - acc: 0.5338 - val_loss: 1.6115 - val_acc: 0.5280\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3182 - acc: 0.5200 - val_loss: 1.5886 - val_acc: 0.5246\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2740 - acc: 0.5318 - val_loss: 1.5763 - val_acc: 0.5312\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2955 - acc: 0.5312 - val_loss: 1.5413 - val_acc: 0.5224\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2776 - acc: 0.5298 - val_loss: 1.5880 - val_acc: 0.5264\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2736 - acc: 0.5360 - val_loss: 1.6756 - val_acc: 0.5202\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 1.2335 - acc: 0.5458 - val_loss: 1.6067 - val_acc: 0.5226\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2775 - acc: 0.5280 - val_loss: 1.5750 - val_acc: 0.5218\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.3106 - acc: 0.5100 - val_loss: 1.6087 - val_acc: 0.5344\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2811 - acc: 0.5265 - val_loss: 1.6287 - val_acc: 0.5262\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.3053 - acc: 0.5213 - val_loss: 1.6186 - val_acc: 0.5288\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2580 - acc: 0.5500 - val_loss: 1.6446 - val_acc: 0.5252\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2802 - acc: 0.5330 - val_loss: 1.6138 - val_acc: 0.5340\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2876 - acc: 0.5300 - val_loss: 1.6313 - val_acc: 0.5308\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2971 - acc: 0.5245 - val_loss: 1.6047 - val_acc: 0.5286\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2618 - acc: 0.5395 - val_loss: 1.6999 - val_acc: 0.5250\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2621 - acc: 0.5425 - val_loss: 1.6425 - val_acc: 0.5224\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2730 - acc: 0.5388 - val_loss: 1.6356 - val_acc: 0.5176\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2527 - acc: 0.5438 - val_loss: 1.6462 - val_acc: 0.5290\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2263 - acc: 0.5590 - val_loss: 1.5751 - val_acc: 0.5358\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.2121 - acc: 0.5590 - val_loss: 1.5814 - val_acc: 0.5310\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2583 - acc: 0.5323 - val_loss: 1.6567 - val_acc: 0.5268\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.2526 - acc: 0.5472 - val_loss: 1.5996 - val_acc: 0.5338\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 3s 203ms/step - loss: 1.2286 - acc: 0.5618 - val_loss: 1.6899 - val_acc: 0.5276\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2433 - acc: 0.5455 - val_loss: 1.6397 - val_acc: 0.5312\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.2518 - acc: 0.5365 - val_loss: 1.6379 - val_acc: 0.5342\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2257 - acc: 0.5590 - val_loss: 1.6652 - val_acc: 0.5306\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2608 - acc: 0.5403 - val_loss: 1.6023 - val_acc: 0.5328\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.2320 - acc: 0.5522 - val_loss: 1.6613 - val_acc: 0.5272\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2586 - acc: 0.5447 - val_loss: 1.6281 - val_acc: 0.5328\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2623 - acc: 0.5460 - val_loss: 1.7261 - val_acc: 0.5170\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2358 - acc: 0.5452 - val_loss: 1.6328 - val_acc: 0.5316\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2477 - acc: 0.5515 - val_loss: 1.6685 - val_acc: 0.5352\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2232 - acc: 0.5527 - val_loss: 1.6717 - val_acc: 0.5310\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 1.2505 - acc: 0.5463 - val_loss: 1.6551 - val_acc: 0.5322\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.2373 - acc: 0.5480 - val_loss: 1.6492 - val_acc: 0.5338\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2320 - acc: 0.5555 - val_loss: 1.6712 - val_acc: 0.5318\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.2549 - acc: 0.5458 - val_loss: 1.6537 - val_acc: 0.5240\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2076 - acc: 0.5575 - val_loss: 1.6280 - val_acc: 0.5278\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2294 - acc: 0.5478 - val_loss: 1.6602 - val_acc: 0.5316\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2106 - acc: 0.5643 - val_loss: 1.6894 - val_acc: 0.5318\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2490 - acc: 0.5425 - val_loss: 1.6564 - val_acc: 0.5328\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.2236 - acc: 0.5543 - val_loss: 1.6724 - val_acc: 0.5296\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2439 - acc: 0.5448 - val_loss: 1.8188 - val_acc: 0.5268\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.2256 - acc: 0.5530 - val_loss: 1.6490 - val_acc: 0.5420\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2183 - acc: 0.5610 - val_loss: 1.7041 - val_acc: 0.5362\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2028 - acc: 0.5660 - val_loss: 1.7478 - val_acc: 0.5220\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 1.2085 - acc: 0.5645 - val_loss: 1.6354 - val_acc: 0.5270\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 4s 257ms/step - loss: 1.2341 - acc: 0.5540 - val_loss: 1.6286 - val_acc: 0.5294\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 1.2371 - acc: 0.5508 - val_loss: 1.5967 - val_acc: 0.5378\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2402 - acc: 0.5493 - val_loss: 1.6473 - val_acc: 0.5330\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 1.2065 - acc: 0.5688 - val_loss: 1.7432 - val_acc: 0.5186\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.2141 - acc: 0.5667 - val_loss: 1.6310 - val_acc: 0.5328\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2164 - acc: 0.5618 - val_loss: 1.6379 - val_acc: 0.5282\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2253 - acc: 0.5550 - val_loss: 1.6373 - val_acc: 0.5316\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1994 - acc: 0.5655 - val_loss: 1.6464 - val_acc: 0.5276\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2242 - acc: 0.5553 - val_loss: 1.6577 - val_acc: 0.5306\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1959 - acc: 0.5713 - val_loss: 1.6647 - val_acc: 0.5324\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1915 - acc: 0.5675 - val_loss: 1.6971 - val_acc: 0.5268\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1899 - acc: 0.5658 - val_loss: 1.6457 - val_acc: 0.5400\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1855 - acc: 0.5690 - val_loss: 1.6980 - val_acc: 0.5330\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1965 - acc: 0.5685 - val_loss: 1.7620 - val_acc: 0.5308\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1739 - acc: 0.5795 - val_loss: 1.6948 - val_acc: 0.5354\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2220 - acc: 0.5543 - val_loss: 1.7918 - val_acc: 0.5108\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1811 - acc: 0.5767 - val_loss: 1.6813 - val_acc: 0.5308\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.1895 - acc: 0.5760 - val_loss: 1.6763 - val_acc: 0.5368\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1590 - acc: 0.5862 - val_loss: 1.7183 - val_acc: 0.5220\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1973 - acc: 0.5690 - val_loss: 1.7774 - val_acc: 0.5288\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1963 - acc: 0.5695 - val_loss: 1.6562 - val_acc: 0.5312\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.2197 - acc: 0.5587 - val_loss: 1.6940 - val_acc: 0.5326\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.2049 - acc: 0.5662 - val_loss: 1.6955 - val_acc: 0.5316\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.2119 - acc: 0.5600 - val_loss: 1.6607 - val_acc: 0.5330\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1856 - acc: 0.5763 - val_loss: 1.7163 - val_acc: 0.5380\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1858 - acc: 0.5758 - val_loss: 1.7273 - val_acc: 0.5280\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1895 - acc: 0.5813 - val_loss: 1.6153 - val_acc: 0.5404\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2224 - acc: 0.5580 - val_loss: 1.6556 - val_acc: 0.5368\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1858 - acc: 0.5715 - val_loss: 1.6795 - val_acc: 0.5364\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1740 - acc: 0.5768 - val_loss: 1.7630 - val_acc: 0.5284\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1691 - acc: 0.5925 - val_loss: 1.7166 - val_acc: 0.5368\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.2039 - acc: 0.5690 - val_loss: 1.7395 - val_acc: 0.5252\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1948 - acc: 0.5697 - val_loss: 1.6855 - val_acc: 0.5252\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1689 - acc: 0.5778 - val_loss: 1.6548 - val_acc: 0.5298\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 3s 208ms/step - loss: 1.1755 - acc: 0.5743 - val_loss: 1.7355 - val_acc: 0.5152\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1865 - acc: 0.5735 - val_loss: 1.6100 - val_acc: 0.5384\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.2041 - acc: 0.5695 - val_loss: 1.6843 - val_acc: 0.5390\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.1788 - acc: 0.5828 - val_loss: 1.6779 - val_acc: 0.5366\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1595 - acc: 0.5922 - val_loss: 1.7288 - val_acc: 0.5194\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1636 - acc: 0.5823 - val_loss: 1.7474 - val_acc: 0.5320\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1681 - acc: 0.5885 - val_loss: 1.7133 - val_acc: 0.5316\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.2140 - acc: 0.5633 - val_loss: 1.7002 - val_acc: 0.5326\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1707 - acc: 0.5848 - val_loss: 1.7411 - val_acc: 0.5308\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1605 - acc: 0.5850 - val_loss: 1.7329 - val_acc: 0.5298\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1646 - acc: 0.5830 - val_loss: 1.7175 - val_acc: 0.5312\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1994 - acc: 0.5630 - val_loss: 1.7009 - val_acc: 0.5278\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1704 - acc: 0.5720 - val_loss: 1.6609 - val_acc: 0.5370\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 3s 207ms/step - loss: 1.1621 - acc: 0.5820 - val_loss: 1.8519 - val_acc: 0.5080\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1828 - acc: 0.5765 - val_loss: 1.7304 - val_acc: 0.5332\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1393 - acc: 0.5947 - val_loss: 1.6791 - val_acc: 0.5346\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 3s 211ms/step - loss: 1.1669 - acc: 0.5822 - val_loss: 1.7057 - val_acc: 0.5398\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 3s 210ms/step - loss: 1.1760 - acc: 0.5780 - val_loss: 1.6923 - val_acc: 0.5410\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1630 - acc: 0.5833 - val_loss: 1.6840 - val_acc: 0.5340\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1589 - acc: 0.5917 - val_loss: 1.7565 - val_acc: 0.5360\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 3s 206ms/step - loss: 1.1548 - acc: 0.5873 - val_loss: 1.7232 - val_acc: 0.5450\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1335 - acc: 0.5975 - val_loss: 1.7697 - val_acc: 0.5284\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 3s 205ms/step - loss: 1.1337 - acc: 0.5940 - val_loss: 1.7010 - val_acc: 0.5328\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 1.1009 - acc: 0.6157 - val_loss: 1.7223 - val_acc: 0.5380\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 1.1621 - acc: 0.5855 - val_loss: 1.8676 - val_acc: 0.5206\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 3s 212ms/step - loss: 1.1673 - acc: 0.5880 - val_loss: 1.6632 - val_acc: 0.5362\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 3s 209ms/step - loss: 1.1571 - acc: 0.5828 - val_loss: 1.7473 - val_acc: 0.5212\n",
            "Test accuracy: 0.524 (elaspsed time: 485s)\n",
            "Accuracy\n",
            "airplane 0.633\n",
            "auto 0.645\n",
            "bird 0.328\n",
            "cat 0.377\n",
            "deer 0.432\n",
            "dog 0.538\n",
            "frog 0.556\n",
            "horse 0.63\n",
            "ship 0.592\n",
            "truck 0.508\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}