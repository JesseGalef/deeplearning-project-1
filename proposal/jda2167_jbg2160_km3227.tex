\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{COMS W4995 Project Proposal: Automatic Data Augmentation Policy Selection}

\author{Jonathan D. Armstrong\\
{\tt\small jda2160@columbia.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Jesse Galef\\
{\tt\small jbg2160@columbia.edu}
\and
Kyle Matoba\\
{\tt\small km3227@columbia.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
% \begin{abstract}
% \end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

For this project, we plan to expand upon the approach used in ``AutoAugment: Learning Augmentation Policies from Data'', \cite{Cubuk2018}. This paper demonstrates success using reinforcement learning to search over a set of possible image transformation policies, finding better ways to augment training data for image classification models. Data augmented according to each combination of transformations explored is used to train a ``child model'', whose performance on a validation set acts as the reward signal for the reinforcement learner. When this data augmentation is combined with state of the art convolutional neural networks (CNNs), such as \cite{Yamada2018} it achieves state of the art results on the CIFAR 10 dataset,\footnote{\url{https://en.wikipedia.org/wiki/CIFAR-10\#Research\_Papers\_Claiming\_State-of-the-Art\_Results\_on\_CIFAR-10}} and several other canonical test problems in image classification. The background in applying CNNs to classify images has been widely discussed in class and is intuitive enough from first principles, so we will skip any further discussion of the background to save space for the proposed innovations.

We will explore different ways to improve automatic data augmentation using the above paper as a starting point. Here is where we intend to begin our search for improvements to the AutoAugment procedure:% The authors acknowledge that they used one of many possible search algorithms and that others may improve on their results. 

\begin{itemize}
\item % Genetic Search Algorithm 
While the authors of the paper used reinforcement learning to select the best image transformation policies, they suggest that other discrete search algorithms, such as genetic programming, might improve the results. Genetic programming has yielded promising results compared to reinforcement learning in the context of CNN architecture design \cite{Real2018} and may also work well in data augmentation.
\item % Object invariants are a characteristic of images, not models.
Different image categories do not need to share the same symmetries. Rather than searching for an optimal policy over the entire dataset, we may be able to improve accuracy by learning which sub-policies to apply to which image categories. 

We may be able to reduce the search time to identify an optimal policy by using a simple model. Once a set of optimal policies is found for this simple model, the same optimal policy should transfer to a state of the art model (trained on the same base dataset).

\item A better base set of augmentations to consider -- \cite{Cubuk2018} used primarily the image $\mapsto$ image functions in the `Pillow' Python library, along with a few ``promising'' others, such as \cite{Devries2017}. Some transformation were never chosen (across data sets) and intuitively would not be great candidates for increasing the stability of a model, whilst possibly other transformations not considered would be.
\item A smarter search space: The authors use only a two-parameter characterisation of augmentation (probability of application, and ‘intensity’ when there was such a notion), which can possibly be bettered by a more careful understanding of the relevant transforms.
\end{itemize}

As we explore different approaches and the project matures, we expect to converge towards one or two main ideas. We will focus on improving CIFAR-10 models but may explore models for different standard datasets if time permits (e.g. CIFAR-100 or SVHN). We will evaluate algorithm performance by the change in accuracy that results from using the data augmentation policy selected by our algorithm and attempt to compare our accuracy to those reported in the paper. Happily, we have already worked with the CIFAR 10 dataset in the first homework, and we have seen that obtaining and loading the data is trivial. In reading \cite{Cubuk2018}, we learned as well about the recent dataset presented in \cite{Recht2018} (which is quite a cool idea!), and so we plan to use that data as well, truly leaving it until all fitting and validation has been done, right before submission (only using it once).

It is natural to propose accuracy improvment over the initial paper as our assessment criterion, however it is equally natural to expect that five Google Brain engineers achieving what appears to be the best published classification error on CIFAR 10 have not left any low hanging fruit. Thus, we would suggest that the thoroughness and quality of our methodological innovations should be primary, albeit with a component of quantitative accuracy improvement, if we are successful in presenting a credible, substantive improvement.

% \begin{table}
% \begin{center}
% \begin{tabular}{|l|c|}
% \hline
% Method & Frobnability \\
% \hline\hline
% Theirs & Frumpy \\
% Yours & Frobbly \\
% Ours & Makes one's heart Frob\\
% \hline
% \end{tabular}
% \end{center}
% \caption{Results.   Ours is better.}
% \end{table}

{\small
\bibliographystyle{ieee}
\bibliography{biblio}
}

\end{document}

